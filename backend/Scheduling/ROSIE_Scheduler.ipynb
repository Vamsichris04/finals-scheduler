{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT Help Desk Scheduling - ROSIE Supercomputer Edition\n",
    "\n",
    "This notebook consolidates the entire scheduling system for running on ROSIE.\n",
    "It includes:\n",
    "- Extended search parameters for supercomputer-scale optimization\n",
    "- Parallel execution support for multi-core utilization\n",
    "- Hyperparameter grid search\n",
    "- Comprehensive visualization and comparison\n",
    "\n",
    "## Quick Start\n",
    "1. Run cells 1-4 to set up the environment and load data\n",
    "2. Run cell 5 to configure hyperparameters (adjust for your compute budget)\n",
    "3. Run cells 6-8 for individual algorithms OR cell 9 for parallel comparison\n",
    "4. Run cell 10 for results visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Core imports\nimport numpy as np\nimport random\nimport math\nimport time\nimport json\nimport os\nfrom datetime import datetime, timedelta\nfrom typing import List, Dict, Tuple, Optional\nfrom dataclasses import dataclass\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Parallel processing\nfrom concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\nfrom multiprocessing import cpu_count, Manager\nimport threading\n\n# GPU Acceleration with PyTorch\nimport torch\nimport torch.nn.functional as F\n\n# MongoDB\nfrom pymongo import MongoClient\n\n# Visualization - Seaborn for better plots\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\n\n# Set Seaborn style for all plots\nsns.set_theme(style=\"whitegrid\", palette=\"husl\")\nsns.set_context(\"notebook\", font_scale=1.1)\n\n# ============================================================================\n# GPU/CUDA SETUP\n# ============================================================================\nNUM_CORES = cpu_count()\nprint(f\"Available CPU cores: {NUM_CORES}\")\n\n# Check for GPU availability\nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda:0')\n    GPU_NAME = torch.cuda.get_device_name(0)\n    GPU_COUNT = torch.cuda.device_count()\n    GPU_MEMORY = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n    print(f\"GPU ACCELERATION ENABLED!\")\n    print(f\"  Device: {GPU_NAME}\")\n    print(f\"  GPU Count: {GPU_COUNT}\")\n    print(f\"  Memory: {GPU_MEMORY:.1f} GB\")\n    USE_GPU = True\nelse:\n    DEVICE = torch.device('cpu')\n    print(\"No GPU available - using CPU (will be slower)\")\n    USE_GPU = False\n\nprint(f\"PyTorch device: {DEVICE}\")\n\n# Quick GPU benchmark\nif USE_GPU:\n    a = torch.randn((1000, 1000), device=DEVICE)\n    b = torch.randn((1000, 1000), device=DEVICE)\n    torch.cuda.synchronize()\n    t0 = time.time()\n    for _ in range(100):\n        c = torch.matmul(a, b)\n    torch.cuda.synchronize()\n    t1 = time.time()\n    print(f\"GPU benchmark: 100x 1000x1000 matmul in {t1-t0:.3f}s\")\n    del a, b, c\n    torch.cuda.empty_cache()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Core Classes (Worker, ShiftSlot, SchedulingEnvironment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class Worker:\n    \"\"\"Represents a student worker with their attributes\"\"\"\n    def __init__(self, worker_id: int, name: str, tier: int, is_commuter: bool, \n                 desired_hours: float, busy_times: List[Tuple[int, int, int]]):\n        self.worker_id = worker_id\n        self.name = name\n        self.tier = tier  # 1-4 (4 = manager, 3 = inventory tech)\n        self.is_commuter = is_commuter\n        self.desired_hours = desired_hours\n        self.busy_times = busy_times\n        \n    def is_available(self, day: int, hour: int) -> bool:\n        \"\"\"Check if worker is available at given day and hour\"\"\"\n        if self.is_commuter and hour < 9:\n            return False\n        for busy_day, busy_start, busy_end in self.busy_times:\n            if day == busy_day and busy_start <= hour < busy_end:\n                return False\n        return True\n\n\nclass ShiftSlot:\n    \"\"\"Represents a time slot that needs coverage\"\"\"\n    def __init__(self, day: int, hour: int, shift_type: str):\n        self.day = day\n        self.hour = hour\n        self.shift_type = shift_type\n        self.assigned_worker = None\n\n\nclass SchedulingEnvironment:\n    \"\"\"Main environment for IT scheduling problem with GPU-accelerated batch evaluation\"\"\"\n    \n    SHIFT_TYPES = ['Window', 'Remote']\n    \n    HOURS_CONFIG = {\n        'finals': {\n            0: (7.5, 20), 1: (7.5, 20), 2: (7.5, 20), 3: (7.5, 20),\n            4: (7.5, 17), 5: (10, 18),\n        },\n        'regular': {\n            0: (7.5, 20), 1: (7.5, 20), 2: (7.5, 20), 3: (7.5, 20),\n            4: (7.5, 17), 5: (10, 18),\n        }\n    }\n\n    MIN_HOURS_PER_WORKER = 14\n    MAX_HOURS_PER_WORKER = 20\n\n    COVERAGE_REQUIREMENTS = {\n        'Window': {'min': 2, 'max': 2},\n        'Remote': {'min': 2, 'max': 4}\n    }\n    \n    def __init__(self, workers: List[Worker], schedule_type: str = 'finals'):\n        self.workers = workers\n        self.schedule_type = schedule_type\n        self.hours_config = self.HOURS_CONFIG[schedule_type]\n        self.shift_slots = self._generate_shift_slots()\n        self.num_slots = len(self.shift_slots)\n        \n        # Pre-compute lookup tables for GPU acceleration\n        self._build_gpu_lookup_tables()\n        \n    def _generate_shift_slots(self) -> List[ShiftSlot]:\n        \"\"\"Generate all shift slots\"\"\"\n        slots = []\n        for day, (start_hour, end_hour) in self.hours_config.items():\n            start_int = int(np.ceil(start_hour))\n            end_int = int(end_hour)\n            for hour in range(start_int, end_int):\n                for _ in range(self.COVERAGE_REQUIREMENTS['Window']['max']):\n                    slots.append(ShiftSlot(day, hour, 'Window'))\n                for _ in range(self.COVERAGE_REQUIREMENTS['Remote']['max']):\n                    slots.append(ShiftSlot(day, hour, 'Remote'))\n        return slots\n    \n    def _build_gpu_lookup_tables(self):\n        \"\"\"Pre-compute lookup tables for fast GPU evaluation\"\"\"\n        # Worker ID to index mapping\n        self.worker_id_to_idx = {w.worker_id: i for i, w in enumerate(self.workers)}\n        self.idx_to_worker_id = {i: w.worker_id for i, w in enumerate(self.workers)}\n        self.num_workers = len(self.workers)\n        \n        # Slot properties as tensors\n        self.slot_days = torch.tensor([s.day for s in self.shift_slots], device=DEVICE, dtype=torch.int32)\n        self.slot_hours = torch.tensor([s.hour for s in self.shift_slots], device=DEVICE, dtype=torch.int32)\n        self.slot_is_window = torch.tensor([1 if s.shift_type == 'Window' else 0 \n                                            for s in self.shift_slots], device=DEVICE, dtype=torch.int32)\n        \n        # Worker properties as tensors\n        self.worker_tiers = torch.tensor([w.tier for w in self.workers], device=DEVICE, dtype=torch.int32)\n        self.worker_is_commuter = torch.tensor([1 if w.is_commuter else 0 \n                                                 for w in self.workers], device=DEVICE, dtype=torch.int32)\n        \n        # Availability matrix: (num_workers, num_slots) - 1 if available, 0 if not\n        availability = np.zeros((self.num_workers, self.num_slots), dtype=np.float32)\n        for w_idx, worker in enumerate(self.workers):\n            for s_idx, slot in enumerate(self.shift_slots):\n                if worker.is_available(slot.day, slot.hour):\n                    availability[w_idx, s_idx] = 1.0\n        self.availability_matrix = torch.tensor(availability, device=DEVICE)\n        \n        # Coverage group indices - which slots belong to same (day, hour) group\n        self.coverage_groups = {}\n        for i, slot in enumerate(self.shift_slots):\n            key = (slot.day, slot.hour)\n            if key not in self.coverage_groups:\n                self.coverage_groups[key] = {'Window': [], 'Remote': []}\n            self.coverage_groups[key][slot.shift_type].append(i)\n        \n        print(f\"GPU lookup tables built: {self.num_slots} slots, {self.num_workers} workers\")\n    \n    def evaluate_schedule(self, schedule: np.ndarray) -> Tuple[float, Dict]:\n        \"\"\"Evaluate a single schedule (CPU version for compatibility)\"\"\"\n        penalty = 0\n        details = {\n            'coverage_violations': 0, 'tier_mismatches': 0, 'worker_conflicts': 0,\n            'hour_violations': 0, 'min_hour_violations': 0, \n            'morning_shift_violations': 0, 'shift_length_violations': 0\n        }\n\n        # Coverage check\n        for key, shifts in self.coverage_groups.items():\n            window_count = sum(1 for i in shifts['Window'] if schedule[i] != -1)\n            remote_count = sum(1 for i in shifts['Remote'] if schedule[i] != -1)\n            \n            if window_count < 2:\n                penalty += 100 * (2 - window_count)\n                details['coverage_violations'] += 1\n            if remote_count < 2:\n                penalty += 100 * (2 - remote_count)\n                details['coverage_violations'] += 1\n\n        # Worker stats\n        worker_hours = {w.worker_id: 0 for w in self.workers}\n        worker_morning = {w.worker_id: 0 for w in self.workers}\n        worker_assignments = {w.worker_id: [] for w in self.workers}\n        \n        for i, worker_id in enumerate(schedule):\n            if worker_id == -1:\n                continue\n            slot = self.shift_slots[i]\n            worker_hours[worker_id] += 1\n            worker_assignments[worker_id].append(i)\n            if slot.hour < 12:\n                worker_morning[worker_id] += 1\n            \n            worker = next((w for w in self.workers if w.worker_id == worker_id), None)\n            if worker and not worker.is_available(slot.day, slot.hour):\n                penalty += 200\n                details['worker_conflicts'] += 1\n            if worker and worker.tier >= 3 and slot.shift_type == 'Window':\n                penalty += 10\n                details['tier_mismatches'] += 1\n\n        # Hour constraints\n        for worker in self.workers:\n            hours = worker_hours[worker.worker_id]\n            if hours < self.MIN_HOURS_PER_WORKER:\n                penalty += (self.MIN_HOURS_PER_WORKER - hours) * 75\n                details['min_hour_violations'] += 1\n            if hours > self.MAX_HOURS_PER_WORKER:\n                penalty += (hours - self.MAX_HOURS_PER_WORKER) * 50\n                details['hour_violations'] += 1\n            if worker_morning[worker.worker_id] > 2:\n                penalty += (worker_morning[worker.worker_id] - 2) * 30\n                details['morning_shift_violations'] += 1\n\n        # Shift length constraints\n        for worker_id, assignments in worker_assignments.items():\n            if not assignments:\n                continue\n            day_hours = {}\n            for idx in assignments:\n                slot = self.shift_slots[idx]\n                if slot.day not in day_hours:\n                    day_hours[slot.day] = set()\n                day_hours[slot.day].add(slot.hour)\n            \n            for day, hours in day_hours.items():\n                sorted_hours = sorted(hours)\n                blocks = [[sorted_hours[0]]]\n                for h in sorted_hours[1:]:\n                    if h == blocks[-1][-1] + 1:\n                        blocks[-1].append(h)\n                    else:\n                        blocks.append([h])\n                for block in blocks:\n                    if len(block) < 2:\n                        penalty += 500\n                        details['shift_length_violations'] += 1\n                    elif len(block) > 6:\n                        penalty += (len(block) - 6) * 100\n                        details['shift_length_violations'] += 1\n\n        return penalty, details\n    \n    def batch_evaluate_gpu(self, population: List[np.ndarray]) -> torch.Tensor:\n        \"\"\"\n        GPU-accelerated batch evaluation of multiple schedules.\n        Returns tensor of penalties for each schedule.\n        \"\"\"\n        batch_size = len(population)\n        \n        # Convert population to GPU tensor\n        # Shape: (batch_size, num_slots)\n        pop_np = np.array(population, dtype=np.int64)\n        pop_tensor = torch.tensor(pop_np, device=DEVICE, dtype=torch.int64)\n        \n        penalties = torch.zeros(batch_size, device=DEVICE)\n        \n        # 1. Coverage violations (vectorized)\n        for key, shifts in self.coverage_groups.items():\n            window_indices = torch.tensor(shifts['Window'], device=DEVICE, dtype=torch.int64)\n            remote_indices = torch.tensor(shifts['Remote'], device=DEVICE, dtype=torch.int64)\n            \n            # Count assigned workers per slot type\n            window_assigned = pop_tensor[:, window_indices]  # (batch, num_window_slots)\n            remote_assigned = pop_tensor[:, remote_indices]\n            \n            window_count = (window_assigned != -1).sum(dim=1).float()\n            remote_count = (remote_assigned != -1).sum(dim=1).float()\n            \n            # Penalty for under-coverage\n            penalties += torch.clamp(2 - window_count, min=0) * 100\n            penalties += torch.clamp(2 - remote_count, min=0) * 100\n        \n        # 2. Worker hour violations (need to count per worker)\n        # Create one-hot encoding of assignments\n        for b in range(batch_size):\n            schedule = pop_tensor[b]\n            worker_hours = torch.zeros(self.num_workers, device=DEVICE)\n            worker_morning = torch.zeros(self.num_workers, device=DEVICE)\n            \n            for s_idx in range(self.num_slots):\n                worker_id = schedule[s_idx].item()\n                if worker_id != -1 and worker_id in self.worker_id_to_idx:\n                    w_idx = self.worker_id_to_idx[worker_id]\n                    worker_hours[w_idx] += 1\n                    if self.slot_hours[s_idx] < 12:\n                        worker_morning[w_idx] += 1\n                    \n                    # Availability violation\n                    if self.availability_matrix[w_idx, s_idx] == 0:\n                        penalties[b] += 200\n                    \n                    # Tier mismatch\n                    if self.worker_tiers[w_idx] >= 3 and self.slot_is_window[s_idx] == 1:\n                        penalties[b] += 10\n            \n            # Min/max hour violations\n            under_hours = torch.clamp(self.MIN_HOURS_PER_WORKER - worker_hours, min=0)\n            over_hours = torch.clamp(worker_hours - self.MAX_HOURS_PER_WORKER, min=0)\n            penalties[b] += under_hours.sum() * 75\n            penalties[b] += over_hours.sum() * 50\n            \n            # Morning shift violations\n            over_morning = torch.clamp(worker_morning - 2, min=0)\n            penalties[b] += over_morning.sum() * 30\n        \n        return penalties\n    \n    def get_available_workers(self, day: int, hour: int) -> List[int]:\n        \"\"\"Get list of worker IDs available for a given day and hour\"\"\"\n        return [w.worker_id for w in self.workers if w.is_available(day, hour)]\n\nprint(\"GPU-accelerated SchedulingEnvironment defined!\")\nprint(f\"Using device: {DEVICE}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: MongoDB Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoDBLoader:\n",
    "    \"\"\"Load scheduling data from MongoDB\"\"\"\n",
    "    \n",
    "    def __init__(self, connection_string: str = \"mongodb://localhost:27017/\", \n",
    "                 database: str = \"finals_scheduler\"):\n",
    "        self.client = MongoClient(connection_string)\n",
    "        self.db = self.client[database]\n",
    "        self.users_collection = self.db['Users']\n",
    "        self.finals_collection = self.db['Finals']\n",
    "    \n",
    "    def parse_tier(self, position: str) -> int:\n",
    "        \"\"\"Convert position string to tier number\"\"\"\n",
    "        tier_map = {'Tier 1': 1, 'Tier 2': 2, 'Tier 3': 3, 'Tier 4': 4}\n",
    "        return tier_map.get(position, 1)\n",
    "    \n",
    "    def get_day_from_date(self, date_str: str) -> tuple:\n",
    "        \"\"\"Convert date string to day of week\"\"\"\n",
    "        date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "        if date.year == 2024:\n",
    "            date = date.replace(year=2025)\n",
    "        return date.weekday(), date\n",
    "    \n",
    "    def parse_time(self, time_str: str) -> int:\n",
    "        \"\"\"Convert time string (HH:MM) to hour integer\"\"\"\n",
    "        hours, minutes = time_str.split(':')\n",
    "        hour = int(hours)\n",
    "        if int(minutes) >= 30:\n",
    "            return hour + 0.5\n",
    "        return hour\n",
    "    \n",
    "    def load_workers(self) -> List[Worker]:\n",
    "        \"\"\"Load all active workers from MongoDB\"\"\"\n",
    "        users = list(self.users_collection.find({'isActive': True}))\n",
    "        workers = []\n",
    "        \n",
    "        for user in users:\n",
    "            user_id = user['userId']\n",
    "            finals = list(self.finals_collection.find({'userId': str(user_id)}))\n",
    "            \n",
    "            busy_times = []\n",
    "            for final in finals:\n",
    "                day, date_obj = self.get_day_from_date(final['date'])\n",
    "                start_hour = self.parse_time(final['startTime'])\n",
    "                end_hour = self.parse_time(final['endTime'])\n",
    "\n",
    "                if day == 6:  # Skip Sunday\n",
    "                    continue\n",
    "                busy_times.append((day, int(start_hour), int(end_hour)))\n",
    "            \n",
    "            worker = Worker(\n",
    "                worker_id=user_id,\n",
    "                name=user['name'],\n",
    "                tier=self.parse_tier(user.get('position', 'Tier 1')),\n",
    "                is_commuter=user.get('isCommuter', False),\n",
    "                desired_hours=user.get('desiredHours', 15),\n",
    "                busy_times=busy_times\n",
    "            )\n",
    "            workers.append(worker)\n",
    "        \n",
    "        return workers\n",
    "    \n",
    "    def print_loaded_data(self, workers: List[Worker]):\n",
    "        \"\"\"Print summary of loaded data\"\"\"\n",
    "        day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"LOADED {len(workers)} WORKERS FROM MONGODB\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        for worker in workers:\n",
    "            print(f\"\\n{worker.name} (ID: {worker.worker_id})\")\n",
    "            print(f\"  Tier: {worker.tier}, Commuter: {'Yes' if worker.is_commuter else 'No'}\")\n",
    "            print(f\"  Desired Hours: {worker.desired_hours}, Busy Times: {len(worker.busy_times)}\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close MongoDB connection\"\"\"\n",
    "        self.client.close()\n",
    "\n",
    "print(\"MongoDB loader defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Load Data (Local Files, MongoDB, or JSON Export)\n",
    "\n",
    "**Data Source Options:**\n",
    "\n",
    "1. **`local_files`** (Default): Loads directly from `Users.json` and `Finals.json` in the Data directory\n",
    "   - Set `DATA_DIRECTORY` to the path containing your JSON files\n",
    "   - Default path is `../../Data` (relative to notebook location)\n",
    "\n",
    "2. **`json_export`**: Loads from a pre-exported `workers_data.json` file\n",
    "   - Run `export_workers_for_rosie.py` locally to create this file\n",
    "   - Useful for ROSIE where direct file access may be limited\n",
    "\n",
    "3. **`mongodb`**: Direct MongoDB connection\n",
    "   - Requires network access to MongoDB Atlas\n",
    "   - May have SSL/firewall issues on HPC clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHOOSE DATA SOURCE: \"mongodb\", \"json_export\", or \"local_files\"\n",
    "# ============================================================================\n",
    "DATA_SOURCE = \"local_files\"  # Change to \"mongodb\" or \"json_export\" if needed\n",
    "\n",
    "# MongoDB settings (only used if DATA_SOURCE = \"mongodb\")\n",
    "MONGODB_CONNECTION = \"mongodb+srv://vamsi123:d32rm2786@cluster1.lnpslid.mongodb.net/\"\n",
    "DATABASE_NAME = \"Scheduler\"\n",
    "\n",
    "# JSON export file settings (only used if DATA_SOURCE = \"json_export\")\n",
    "# Generate this file by running export_workers_for_rosie.py locally\n",
    "JSON_EXPORT_FILE = \"workers_data.json\"\n",
    "\n",
    "# Local files settings (only used if DATA_SOURCE = \"local_files\")\n",
    "# Path to the Data directory containing Users.json and Finals.json\n",
    "DATA_DIRECTORY = \"\"\n",
    "\n",
    "def parse_tier(position: str) -> int:\n",
    "    \"\"\"Convert position string to tier number\"\"\"\n",
    "    tier_map = {'Tier 1': 1, 'Tier 2': 2, 'Tier 3': 3, 'Tier 4': 4}\n",
    "    return tier_map.get(position, 1)\n",
    "\n",
    "def get_day_from_date(date_str: str) -> tuple:\n",
    "    \"\"\"Convert date string to day of week\"\"\"\n",
    "    date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "    if date.year == 2024:\n",
    "        date = date.replace(year=2025)\n",
    "    return date.weekday(), date\n",
    "\n",
    "def parse_time(time_str: str) -> int:\n",
    "    \"\"\"Convert time string (HH:MM) to hour integer\"\"\"\n",
    "    hours, minutes = time_str.split(':')\n",
    "    hour = int(hours)\n",
    "    if int(minutes) >= 30:\n",
    "        return hour + 0.5\n",
    "    return hour\n",
    "\n",
    "def load_workers_from_local_files(data_dir: str) -> List[Worker]:\n",
    "    \"\"\"Load workers from local Users.json and Finals.json files\"\"\"\n",
    "    users_path = os.path.join(data_dir, 'Users.json')\n",
    "    finals_path = os.path.join(data_dir, 'Finals.json')\n",
    "    \n",
    "    # Load Users.json\n",
    "    with open(users_path, 'r', encoding='utf-8') as f:\n",
    "        users = json.load(f)\n",
    "    \n",
    "    # Load Finals.json\n",
    "    with open(finals_path, 'r', encoding='utf-8') as f:\n",
    "        finals = json.load(f)\n",
    "    \n",
    "    # Create a mapping of userId to their finals (busy times)\n",
    "    finals_by_user = {}\n",
    "    for final in finals:\n",
    "        user_id = str(final['userId'])\n",
    "        if user_id not in finals_by_user:\n",
    "            finals_by_user[user_id] = []\n",
    "        finals_by_user[user_id].append(final)\n",
    "    \n",
    "    workers = []\n",
    "    for user in users:\n",
    "        # Skip inactive users\n",
    "        if not user.get('isActive', True):\n",
    "            continue\n",
    "        \n",
    "        user_id = user['userId']\n",
    "        user_finals = finals_by_user.get(str(user_id), [])\n",
    "        \n",
    "        busy_times = []\n",
    "        for final in user_finals:\n",
    "            day, date_obj = get_day_from_date(final['date'])\n",
    "            start_hour = parse_time(final['startTime'])\n",
    "            end_hour = parse_time(final['endTime'])\n",
    "            \n",
    "            if day == 6:  # Skip Sunday\n",
    "                continue\n",
    "            busy_times.append((day, int(start_hour), int(end_hour)))\n",
    "        \n",
    "        worker = Worker(\n",
    "            worker_id=user_id,\n",
    "            name=user['name'],\n",
    "            tier=parse_tier(user.get('position', 'Tier 1')),\n",
    "            is_commuter=user.get('isCommuter', False),\n",
    "            desired_hours=user.get('desiredHours', 15),\n",
    "            busy_times=busy_times\n",
    "        )\n",
    "        workers.append(worker)\n",
    "    \n",
    "    return workers\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "if DATA_SOURCE == \"local_files\":\n",
    "    print(f\"Loading workers from local files in: {DATA_DIRECTORY}\")\n",
    "    \n",
    "    workers = load_workers_from_local_files(DATA_DIRECTORY)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LOADED {len(workers)} ACTIVE WORKERS FROM LOCAL FILES\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for worker in workers:\n",
    "        print(f\"\\n{worker.name} (ID: {worker.worker_id})\")\n",
    "        print(f\"  Tier: {worker.tier}, Commuter: {'Yes' if worker.is_commuter else 'No'}\")\n",
    "        print(f\"  Desired Hours: {worker.desired_hours}, Busy Times: {len(worker.busy_times)}\")\n",
    "\n",
    "elif DATA_SOURCE == \"json_export\":\n",
    "    print(f\"Loading workers from exported JSON file: {JSON_EXPORT_FILE}\")\n",
    "    \n",
    "    with open(JSON_EXPORT_FILE, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    workers = []\n",
    "    for w in data['workers']:\n",
    "        worker = Worker(\n",
    "            worker_id=w['worker_id'],\n",
    "            name=w['name'],\n",
    "            tier=w['tier'],\n",
    "            is_commuter=w['is_commuter'],\n",
    "            desired_hours=w['desired_hours'],\n",
    "            busy_times=[tuple(bt) for bt in w['busy_times']]\n",
    "        )\n",
    "        workers.append(worker)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LOADED {len(workers)} WORKERS FROM JSON EXPORT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Exported at: {data.get('exported_at', 'Unknown')}\")\n",
    "    \n",
    "    for worker in workers:\n",
    "        print(f\"\\n{worker.name} (ID: {worker.worker_id})\")\n",
    "        print(f\"  Tier: {worker.tier}, Commuter: {'Yes' if worker.is_commuter else 'No'}\")\n",
    "        print(f\"  Desired Hours: {worker.desired_hours}, Busy Times: {len(worker.busy_times)}\")\n",
    "\n",
    "elif DATA_SOURCE == \"mongodb\":\n",
    "    print(\"Connecting to MongoDB...\")\n",
    "    loader = MongoDBLoader(MONGODB_CONNECTION, DATABASE_NAME)\n",
    "    workers = loader.load_workers()\n",
    "    loader.print_loaded_data(workers)\n",
    "    loader.close()\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Invalid DATA_SOURCE: {DATA_SOURCE}. Use 'mongodb', 'json_export', or 'local_files'\")\n",
    "\n",
    "# Create scheduling environment\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CREATING SCHEDULING ENVIRONMENT\")\n",
    "print(f\"{'='*60}\")\n",
    "env = SchedulingEnvironment(workers, schedule_type='finals')\n",
    "print(f\"Total shift slots: {env.num_slots}\")\n",
    "print(f\"Number of workers: {len(env.workers)}\")\n",
    "print(f\"Schedule type: {env.schedule_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Extended Hyperparameter Configuration for ROSIE\n",
    "\n",
    "These parameters are significantly extended compared to local execution.\n",
    "Adjust based on your compute time allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# ROSIE HYPERPARAMETER CONFIGURATION - Extended for ~2 Hour Runs\n# ============================================================================\n\nCOMPUTE_PROFILE = \"rosie_2hr\"  # Options: \"quick\", \"standard\", \"rosie_2hr\"\n\nPROFILES = {\n    \"quick\": {  # ~15-30 minutes total\n        \"GA\": {\n            \"population_size\": 200,\n            \"generations\": 5000,\n            \"crossover_rate\": 0.85,\n            \"mutation_rate\": 0.35,\n            \"elitism_count\": 10,\n            \"max_time\": 600.0  # 10 min max\n        },\n        \"SA\": {\n            \"initial_temp\": 5000.0,\n            \"final_temp\": 0.1,\n            \"cooling_rate\": 0.9995,\n            \"iterations_per_temp\": 150,\n            \"max_iterations\": 100000,\n            \"max_time\": 600.0,  # 10 min max\n            \"max_reheats\": 10\n        },\n        \"CSP\": {\n            \"max_time\": 600.0,  # 10 min max\n            \"local_search_iterations\": 100000,\n            \"num_restarts\": 5\n        }\n    },\n    \"standard\": {  # ~30-60 minutes total\n        \"GA\": {\n            \"population_size\": 400,\n            \"generations\": 15000,\n            \"crossover_rate\": 0.87,\n            \"mutation_rate\": 0.40,\n            \"elitism_count\": 20,\n            \"max_time\": 1800.0  # 30 min max\n        },\n        \"SA\": {\n            \"initial_temp\": 8000.0,\n            \"final_temp\": 0.01,\n            \"cooling_rate\": 0.99985,\n            \"iterations_per_temp\": 200,\n            \"max_iterations\": 300000,\n            \"max_time\": 1800.0,  # 30 min max\n            \"max_reheats\": 20\n        },\n        \"CSP\": {\n            \"max_time\": 1800.0,  # 30 min max\n            \"local_search_iterations\": 300000,\n            \"num_restarts\": 10\n        }\n    },\n    \"rosie_2hr\": {  # ~2 hours per algorithm - RECOMMENDED FOR ROSIE\n        \"GA\": {\n            \"population_size\": 800,\n            \"generations\": 50000,          # Large generation count\n            \"crossover_rate\": 0.88,\n            \"mutation_rate\": 0.42,\n            \"elitism_count\": 40,\n            \"max_time\": 7200.0,            # 2 hour hard limit\n            \"checkpoint_interval\": 300     # Checkpoint every 5 min\n        },\n        \"SA\": {\n            # Properly tuned cooling schedule for 2 hours:\n            # With cooling_rate=0.999995 and iterations_per_temp=300,\n            # temp goes from 10000 to 0.01 in ~3M iterations\n            # At ~2000 iter/sec, that's ~25 min of cooling cycles\n            # Plus reheats extends to full 2 hours\n            \"initial_temp\": 10000.0,\n            \"final_temp\": 0.01,\n            \"cooling_rate\": 0.999995,      # Very slow cooling\n            \"iterations_per_temp\": 300,\n            \"max_iterations\": 15000000,    # 15M iterations max\n            \"max_time\": 7200.0,            # 2 hour hard limit\n            \"max_reheats\": 50,             # Allow many reheats\n            \"checkpoint_interval\": 300     # Checkpoint every 5 min\n        },\n        \"CSP\": {\n            \"max_time\": 7200.0,            # 2 hour hard limit\n            \"local_search_iterations\": 5000000,  # 5M iterations\n            \"num_restarts\": 30,            # Many restarts for diversity\n            \"checkpoint_interval\": 300     # Checkpoint every 5 min\n        }\n    }\n}\n\n# Select active configuration\nGA_CONFIG = PROFILES[COMPUTE_PROFILE][\"GA\"]\nSA_CONFIG = PROFILES[COMPUTE_PROFILE][\"SA\"]\nCSP_CONFIG = PROFILES[COMPUTE_PROFILE][\"CSP\"]\n\n# Checkpointing settings\nCHECKPOINT_DIR = \"checkpoints\"\nENABLE_CHECKPOINTING = True\n\n# Create checkpoint directory\nimport os\nif ENABLE_CHECKPOINTING and not os.path.exists(CHECKPOINT_DIR):\n    os.makedirs(CHECKPOINT_DIR)\n\nprint(f\"{'='*70}\")\nprint(f\"PROFILE: {COMPUTE_PROFILE.upper()}\")\nprint(f\"{'='*70}\")\nprint(f\"\nGenetic Algorithm:\")\nprint(f\"  Population: {GA_CONFIG['population_size']}, Generations: {GA_CONFIG['generations']}\")\nprint(f\"  Max time: {GA_CONFIG['max_time']/3600:.1f} hours\")\nprint(f\"\nSimulated Annealing:\")\nprint(f\"  Initial temp: {SA_CONFIG['initial_temp']}, Cooling rate: {SA_CONFIG['cooling_rate']}\")\nprint(f\"  Max iterations: {SA_CONFIG['max_iterations']:,}, Max time: {SA_CONFIG['max_time']/3600:.1f} hours\")\nprint(f\"  Max reheats: {SA_CONFIG['max_reheats']}\")\nprint(f\"\nCSP Solver:\")\nprint(f\"  Max time: {CSP_CONFIG['max_time']/3600:.1f} hours\")\nprint(f\"  Local search iterations: {CSP_CONFIG['local_search_iterations']:,}\")\nprint(f\"  Num restarts: {CSP_CONFIG['num_restarts']}\")\nprint(f\"\nCheckpointing: {'ENABLED' if ENABLE_CHECKPOINTING else 'DISABLED'}\")\nprint(f\"\nExpected runtime: ~2 hours (parallel) or ~6 hours (sequential)\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Enhanced Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class GeneticAlgorithm:\n    \"\"\"GPU-accelerated Genetic Algorithm with batch fitness evaluation\"\"\"\n\n    def __init__(self, environment: SchedulingEnvironment,\n                 population_size: int = 500,\n                 generations: int = 10000,\n                 crossover_rate: float = 0.85,\n                 mutation_rate: float = 0.40,\n                 elitism_count: int = 25,\n                 batch_size: int = 500,\n                 adaptive_mutation: bool = True):\n        \n        self.env = environment\n        self.population_size = population_size\n        self.generations = generations\n        self.crossover_rate = crossover_rate\n        self.mutation_rate = mutation_rate\n        self.base_mutation_rate = mutation_rate\n        self.elitism_count = elitism_count\n        self.batch_size = batch_size\n        self.adaptive_mutation = adaptive_mutation\n        \n        self.chromosome_length = self.env.num_slots\n        self.worker_ids = [w.worker_id for w in self.env.workers]\n        \n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.fitness_history = []\n        self.stagnation_counter = 0\n        \n    def initialize_population(self) -> List[np.ndarray]:\n        \"\"\"Create diverse initial population\"\"\"\n        population = []\n        min_hours = self.env.MIN_HOURS_PER_WORKER\n        min_shift, max_shift = 2, 6\n\n        for pop_idx in range(self.population_size):\n            chromosome = np.full(self.chromosome_length, -1, dtype=int)\n            worker_hours = {w.worker_id: 0 for w in self.env.workers}\n\n            slot_groups = {}\n            for i, slot in enumerate(self.env.shift_slots):\n                key = (slot.day, slot.shift_type)\n                if key not in slot_groups:\n                    slot_groups[key] = []\n                slot_groups[key].append((i, slot.hour))\n\n            for key in slot_groups:\n                slot_groups[key].sort(key=lambda x: x[1])\n\n            keys = list(slot_groups.keys())\n            random.shuffle(keys)\n\n            for key in keys:\n                slots = slot_groups[key]\n                day, shift_type = key\n                i = 0\n                while i < len(slots):\n                    slot_idx, hour = slots[i]\n                    available = self.env.get_available_workers(day, hour)\n                    if not available:\n                        i += 1\n                        continue\n\n                    if pop_idx % 3 == 0:\n                        under_min = [w for w in available if worker_hours[w] < min_hours]\n                        candidates = under_min if under_min else available\n                    elif pop_idx % 3 == 1:\n                        candidates = available\n                    else:\n                        candidates = sorted(available, key=lambda w: worker_hours[w])[:max(1, len(available)//2)]\n\n                    chosen = random.choice(candidates)\n                    block_length = random.randint(min_shift, max_shift)\n\n                    assigned = 0\n                    for j in range(i, min(i + block_length, len(slots))):\n                        next_idx, next_hour = slots[j]\n                        if next_hour == hour + (j - i):\n                            worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n                            if worker and worker.is_available(day, next_hour):\n                                chromosome[next_idx] = chosen\n                                assigned += 1\n                            else:\n                                break\n                        else:\n                            break\n\n                    if assigned > 0:\n                        worker_hours[chosen] += assigned\n                    i += max(1, assigned)\n\n            population.append(chromosome)\n        return population\n    \n    def batch_fitness_gpu(self, population: List[np.ndarray]) -> List[float]:\n        \"\"\"GPU-accelerated batch fitness evaluation\"\"\"\n        if USE_GPU and len(population) >= 10:\n            penalties = self.env.batch_evaluate_gpu(population)\n            return penalties.cpu().numpy().tolist()\n        else:\n            return [self.env.evaluate_schedule(ind)[0] for ind in population]\n    \n    def select_parents(self, population: List[np.ndarray], \n                      fitnesses: List[float]) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Tournament selection\"\"\"\n        tournament_size = 3 if self.stagnation_counter < 100 else 5\n        \n        def tournament_select(k):\n            indices = random.sample(range(len(population)), k)\n            best_idx = min(indices, key=lambda i: fitnesses[i])\n            return population[best_idx].copy()\n        \n        return tournament_select(tournament_size), tournament_select(tournament_size)\n    \n    def crossover(self, parent1: np.ndarray, parent2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Multi-point crossover\"\"\"\n        if random.random() > self.crossover_rate:\n            return parent1.copy(), parent2.copy()\n        \n        num_points = random.randint(2, 4)\n        points = sorted(random.sample(range(1, self.chromosome_length), num_points))\n        points = [0] + points + [self.chromosome_length]\n        \n        offspring1 = np.empty(self.chromosome_length, dtype=int)\n        offspring2 = np.empty(self.chromosome_length, dtype=int)\n        \n        for i in range(len(points) - 1):\n            start, end = points[i], points[i+1]\n            if i % 2 == 0:\n                offspring1[start:end] = parent1[start:end]\n                offspring2[start:end] = parent2[start:end]\n            else:\n                offspring1[start:end] = parent2[start:end]\n                offspring2[start:end] = parent1[start:end]\n        \n        return offspring1, offspring2\n    \n    def mutate(self, chromosome: np.ndarray) -> np.ndarray:\n        \"\"\"Mutation with multiple strategies\"\"\"\n        if random.random() > self.mutation_rate:\n            return chromosome\n\n        min_shift, max_shift = 2, 6\n        min_hours = self.env.MIN_HOURS_PER_WORKER\n        mutation_types = ['extend_block', 'swap_blocks', 'fill_gap', 'reassign']\n        if self.stagnation_counter > 50:\n            mutation_types.append('shuffle_day')\n        \n        mutation_type = random.choice(mutation_types)\n\n        if mutation_type == 'extend_block':\n            assigned = [i for i, w in enumerate(chromosome) if w != -1]\n            if assigned:\n                idx = random.choice(assigned)\n                slot = self.env.shift_slots[idx]\n                worker_id = chromosome[idx]\n                for i, s in enumerate(self.env.shift_slots):\n                    if (s.day == slot.day and s.shift_type == slot.shift_type and\n                        abs(s.hour - slot.hour) == 1 and chromosome[i] == -1):\n                        worker = next((w for w in self.env.workers if w.worker_id == worker_id), None)\n                        if worker and worker.is_available(s.day, s.hour):\n                            hours = sum(1 for w in chromosome if w == worker_id)\n                            if hours < 20:\n                                chromosome[i] = worker_id\n                                break\n\n        elif mutation_type == 'swap_blocks':\n            assigned = [i for i, w in enumerate(chromosome) if w != -1]\n            if len(assigned) >= 2:\n                idx1, idx2 = random.sample(assigned, 2)\n                slot1, slot2 = self.env.shift_slots[idx1], self.env.shift_slots[idx2]\n                w1, w2 = chromosome[idx1], chromosome[idx2]\n                worker1 = next((w for w in self.env.workers if w.worker_id == w1), None)\n                worker2 = next((w for w in self.env.workers if w.worker_id == w2), None)\n                if (worker1 and worker2 and\n                    worker1.is_available(slot2.day, slot2.hour) and\n                    worker2.is_available(slot1.day, slot1.hour)):\n                    chromosome[idx1], chromosome[idx2] = w2, w1\n\n        elif mutation_type == 'fill_gap':\n            empty = [i for i, w in enumerate(chromosome) if w == -1]\n            if empty:\n                idx = random.choice(empty)\n                slot = self.env.shift_slots[idx]\n                available = self.env.get_available_workers(slot.day, slot.hour)\n                if available:\n                    worker_hours = {w.worker_id: sum(1 for x in chromosome if x == w.worker_id)\n                                   for w in self.env.workers}\n                    under_min = [w for w in available if worker_hours.get(w, 0) < min_hours]\n                    chosen = random.choice(under_min) if under_min else random.choice(available)\n                    block_size = random.randint(min_shift, 4)\n                    for i, s in enumerate(self.env.shift_slots):\n                        if (s.day == slot.day and s.shift_type == slot.shift_type and\n                            slot.hour <= s.hour < slot.hour + block_size and chromosome[i] == -1):\n                            worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n                            if worker and worker.is_available(s.day, s.hour):\n                                hours = sum(1 for w in chromosome if w == chosen)\n                                if hours < 20:\n                                    chromosome[i] = chosen\n\n        elif mutation_type == 'reassign':\n            idx = random.randint(0, self.chromosome_length - 1)\n            slot = self.env.shift_slots[idx]\n            available = self.env.get_available_workers(slot.day, slot.hour)\n            if available:\n                current = chromosome[idx]\n                if current in available and len(available) > 1:\n                    available = [w for w in available if w != current]\n                chromosome[idx] = random.choice(available)\n                \n        elif mutation_type == 'shuffle_day':\n            day = random.randint(0, 5)\n            day_slots = [(i, slot) for i, slot in enumerate(self.env.shift_slots) if slot.day == day]\n            if day_slots:\n                assignments = [(i, chromosome[i]) for i, _ in day_slots if chromosome[i] != -1]\n                if len(assignments) >= 2:\n                    random.shuffle(assignments)\n                    orig_slots = [(i, chromosome[i]) for i, _ in day_slots if chromosome[i] != -1]\n                    for (orig_idx, _), (_, new_worker) in zip(orig_slots, assignments):\n                        slot = self.env.shift_slots[orig_idx]\n                        worker = next((w for w in self.env.workers if w.worker_id == new_worker), None)\n                        if worker and worker.is_available(slot.day, slot.hour):\n                            chromosome[orig_idx] = new_worker\n\n        return chromosome\n    \n    def repair_chromosome(self, chromosome: np.ndarray) -> np.ndarray:\n        \"\"\"Repair chromosome to fix availability violations\"\"\"\n        for i, worker_id in enumerate(chromosome):\n            if worker_id == -1:\n                continue\n            slot = self.env.shift_slots[i]\n            worker = next((w for w in self.env.workers if w.worker_id == worker_id), None)\n            if worker and not worker.is_available(slot.day, slot.hour):\n                available = self.env.get_available_workers(slot.day, slot.hour)\n                chromosome[i] = random.choice(available) if available else -1\n        return chromosome\n    \n    def solve(self, verbose: bool = True) -> Tuple[np.ndarray, float, List[float]]:\n        \"\"\"Run GA with GPU-accelerated batch fitness evaluation\"\"\"\n        start_time = time.time()\n        population = self.initialize_population()\n        \n        if verbose:\n            print(f\"GA initialized: pop={self.population_size}, gens={self.generations}\")\n            print(f\"GPU batch evaluation: {'ENABLED' if USE_GPU else 'DISABLED'}\")\n        \n        for generation in range(self.generations):\n            # GPU batch fitness evaluation\n            fitnesses = self.batch_fitness_gpu(population)\n            \n            min_fitness_idx = np.argmin(fitnesses)\n            current_best = fitnesses[min_fitness_idx]\n            \n            if current_best < self.best_fitness:\n                self.best_fitness = current_best\n                self.best_solution = population[min_fitness_idx].copy()\n                self.stagnation_counter = 0\n            else:\n                self.stagnation_counter += 1\n            \n            self.fitness_history.append(self.best_fitness)\n            \n            # Adaptive mutation\n            if self.adaptive_mutation:\n                if self.stagnation_counter > 100:\n                    self.mutation_rate = min(0.8, self.base_mutation_rate * 2)\n                elif self.stagnation_counter > 50:\n                    self.mutation_rate = min(0.6, self.base_mutation_rate * 1.5)\n                else:\n                    self.mutation_rate = self.base_mutation_rate\n            \n            if verbose and generation % 500 == 0:\n                elapsed = time.time() - start_time\n                gens_per_sec = generation / elapsed if elapsed > 0 else 0\n                eta = (self.generations - generation) / gens_per_sec if gens_per_sec > 0 else 0\n                print(f\"Gen {generation}: Best={self.best_fitness:.1f}, \"\n                      f\"Avg={np.mean(fitnesses):.1f}, Rate={gens_per_sec:.1f} gen/s, \"\n                      f\"ETA={eta/60:.1f}min\")\n            \n            if self.best_fitness == 0:\n                if verbose:\n                    print(f\"Perfect solution at generation {generation}!\")\n                break\n            \n            # Create new population\n            new_population = []\n            elite_indices = np.argsort(fitnesses)[:self.elitism_count]\n            for idx in elite_indices:\n                new_population.append(population[idx].copy())\n            \n            while len(new_population) < self.population_size:\n                parent1, parent2 = self.select_parents(population, fitnesses)\n                offspring1, offspring2 = self.crossover(parent1, parent2)\n                offspring1 = self.repair_chromosome(self.mutate(offspring1))\n                offspring2 = self.repair_chromosome(self.mutate(offspring2))\n                new_population.append(offspring1)\n                if len(new_population) < self.population_size:\n                    new_population.append(offspring2)\n            \n            population = new_population\n        \n        total_time = time.time() - start_time\n        if verbose:\n            print(f\"\\nGA completed in {total_time:.1f}s ({total_time/60:.1f} min)\")\n            print(f\"Best fitness: {self.best_fitness:.2f}\")\n            _, details = self.env.evaluate_schedule(self.best_solution)\n            print(f\"Violations: {details}\")\n        \n        return self.best_solution, self.best_fitness, self.fitness_history\n\nprint(\"GPU-accelerated Genetic Algorithm defined!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Enhanced Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class SimulatedAnnealing:\n    \"\"\"\n    Simulated Annealing with properly tuned cooling schedule and checkpointing.\n\n    Cooling Schedule Math:\n    - With cooling_rate=0.999995 and initial_temp=10000, final_temp=0.01:\n    - Number of cooling steps: log(0.01/10000) / log(0.999995) ~ 2.76M\n    - At iterations_per_temp=300, total iterations from cooling ~ 830M\n    - But we use max_iterations and max_time as hard limits\n    - Reheats provide escape from local minima\n    \"\"\"\n\n    def __init__(self, environment,\n                 initial_temp: float = 10000.0,\n                 final_temp: float = 0.01,\n                 cooling_rate: float = 0.999995,\n                 iterations_per_temp: int = 300,\n                 max_iterations: int = 15000000,\n                 max_time: float = 7200.0,\n                 max_reheats: int = 50,\n                 checkpoint_interval: float = 300.0,\n                 checkpoint_dir: str = \"checkpoints\"):\n\n        self.env = environment\n        self.initial_temp = initial_temp\n        self.final_temp = final_temp\n        self.cooling_rate = cooling_rate\n        self.iterations_per_temp = iterations_per_temp\n        self.max_iterations = max_iterations\n        self.max_time = max_time\n        self.max_reheats = max_reheats\n        self.checkpoint_interval = checkpoint_interval\n        self.checkpoint_dir = checkpoint_dir\n\n        self.worker_ids = [w.worker_id for w in self.env.workers]\n        self.best_solution = None\n        self.best_cost = float('inf')\n        self.cost_history = []\n        self.checkpoint_history = []  # Store periodic snapshots for graphing\n\n    def generate_initial_solution(self) -> np.ndarray:\n        \"\"\"Generate initial feasible solution\"\"\"\n        solution = np.full(self.env.num_slots, -1, dtype=int)\n        worker_hours = {w.worker_id: 0 for w in self.env.workers}\n        min_hours = self.env.MIN_HOURS_PER_WORKER\n        min_shift, max_shift = 2, 6\n\n        slot_groups = {}\n        for i, slot in enumerate(self.env.shift_slots):\n            key = (slot.day, slot.shift_type)\n            if key not in slot_groups:\n                slot_groups[key] = []\n            slot_groups[key].append((i, slot.hour))\n\n        for key in slot_groups:\n            slot_groups[key].sort(key=lambda x: x[1])\n\n        for key in slot_groups:\n            slots = slot_groups[key]\n            day, _ = key\n            i = 0\n            while i < len(slots):\n                slot_idx, hour = slots[i]\n                available = self.env.get_available_workers(day, hour)\n                if not available:\n                    i += 1\n                    continue\n\n                available_sorted = sorted(available,\n                    key=lambda w: (0 if worker_hours[w] < min_hours else 1, worker_hours[w]))\n                chosen = available_sorted[0]\n                block_length = random.randint(min_shift, max_shift)\n\n                assigned = 0\n                for j in range(i, min(i + block_length, len(slots))):\n                    next_idx, next_hour = slots[j]\n                    if next_hour == hour + (j - i):\n                        worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n                        if worker and worker.is_available(day, next_hour):\n                            solution[next_idx] = chosen\n                            assigned += 1\n                        else:\n                            break\n                    else:\n                        break\n\n                if assigned > 0:\n                    worker_hours[chosen] += assigned\n                i += max(1, assigned)\n\n        return solution\n\n    def generate_neighbor(self, solution: np.ndarray, temperature: float) -> np.ndarray:\n        \"\"\"Generate neighbor solution with temperature-adaptive moves\"\"\"\n        neighbor = solution.copy()\n        min_shift, max_shift = 2, 6\n        temp_ratio = temperature / self.initial_temp\n\n        # More aggressive moves at higher temps, refined moves at lower temps\n        if temp_ratio > 0.7:\n            strategies = ['swap_blocks', 'extend_block', 'shrink_block', 'reassign_block', 'fill_block', 'shuffle_day']\n        elif temp_ratio > 0.3:\n            strategies = ['swap_blocks', 'extend_block', 'reassign_block', 'fill_block']\n        else:\n            strategies = ['swap_blocks', 'extend_block', 'fill_block', 'fine_tune']\n\n        strategy = random.choice(strategies)\n\n        if strategy == 'swap_blocks':\n            assigned = [i for i, w in enumerate(solution) if w != -1]\n            if len(assigned) >= 2:\n                idx1, idx2 = random.sample(assigned, 2)\n                slot1, slot2 = self.env.shift_slots[idx1], self.env.shift_slots[idx2]\n                w1, w2 = neighbor[idx1], neighbor[idx2]\n                worker1 = next((w for w in self.env.workers if w.worker_id == w1), None)\n                worker2 = next((w for w in self.env.workers if w.worker_id == w2), None)\n                if (worker1 and worker2 and\n                    worker1.is_available(slot2.day, slot2.hour) and\n                    worker2.is_available(slot1.day, slot1.hour)):\n                    neighbor[idx1], neighbor[idx2] = w2, w1\n\n        elif strategy == 'extend_block':\n            assigned = [i for i, w in enumerate(solution) if w != -1]\n            if assigned:\n                idx = random.choice(assigned)\n                slot = self.env.shift_slots[idx]\n                worker_id = neighbor[idx]\n                for i, s in enumerate(self.env.shift_slots):\n                    if (s.day == slot.day and s.shift_type == slot.shift_type and\n                        abs(s.hour - slot.hour) == 1 and neighbor[i] == -1):\n                        worker = next((w for w in self.env.workers if w.worker_id == worker_id), None)\n                        if worker and worker.is_available(s.day, s.hour):\n                            hours = sum(1 for x in neighbor if x == worker_id)\n                            if hours < 20:\n                                neighbor[i] = worker_id\n                                break\n\n        elif strategy == 'shrink_block':\n            assigned = [i for i, w in enumerate(solution) if w != -1]\n            if assigned:\n                idx = random.choice(assigned)\n                slot = self.env.shift_slots[idx]\n                worker_id = neighbor[idx]\n                block_size = sum(1 for i, s in enumerate(self.env.shift_slots)\n                               if s.day == slot.day and s.shift_type == slot.shift_type\n                               and neighbor[i] == worker_id)\n                if block_size > min_shift:\n                    neighbor[idx] = -1\n\n        elif strategy == 'reassign_block':\n            idx = random.randint(0, len(solution) - 1)\n            slot = self.env.shift_slots[idx]\n            available = self.env.get_available_workers(slot.day, slot.hour)\n            if available:\n                current = neighbor[idx]\n                if current in available and len(available) > 1:\n                    available = [w for w in available if w != current]\n                neighbor[idx] = random.choice(available)\n            else:\n                neighbor[idx] = -1\n\n        elif strategy == 'fill_block':\n            empty = [i for i, w in enumerate(solution) if w == -1]\n            if empty:\n                idx = random.choice(empty)\n                slot = self.env.shift_slots[idx]\n                available = self.env.get_available_workers(slot.day, slot.hour)\n                if available:\n                    worker_hours = {w.worker_id: sum(1 for x in neighbor if x == w.worker_id)\n                                   for w in self.env.workers}\n                    under_min = [w for w in available if worker_hours.get(w, 0) < 14]\n                    chosen = random.choice(under_min) if under_min else random.choice(available)\n                    block_length = random.randint(min_shift, max_shift)\n                    for i, s in enumerate(self.env.shift_slots):\n                        if (s.day == slot.day and s.shift_type == slot.shift_type and\n                            slot.hour <= s.hour < slot.hour + block_length and neighbor[i] == -1):\n                            worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n                            if worker and worker.is_available(s.day, s.hour):\n                                hours = sum(1 for x in neighbor if x == chosen)\n                                if hours < 20:\n                                    neighbor[i] = chosen\n\n        elif strategy == 'shuffle_day':\n            day = random.randint(0, 5)\n            day_indices = [i for i, slot in enumerate(self.env.shift_slots)\n                          if slot.day == day and neighbor[i] != -1]\n            if len(day_indices) >= 2:\n                idx1, idx2 = random.sample(day_indices, 2)\n                slot1, slot2 = self.env.shift_slots[idx1], self.env.shift_slots[idx2]\n                w1, w2 = neighbor[idx1], neighbor[idx2]\n                worker1 = next((w for w in self.env.workers if w.worker_id == w1), None)\n                worker2 = next((w for w in self.env.workers if w.worker_id == w2), None)\n                if (worker1 and worker2 and\n                    worker1.is_available(slot2.day, slot2.hour) and\n                    worker2.is_available(slot1.day, slot1.hour)):\n                    neighbor[idx1], neighbor[idx2] = w2, w1\n\n        elif strategy == 'fine_tune':\n            idx = random.randint(0, len(solution) - 1)\n            slot = self.env.shift_slots[idx]\n            current = neighbor[idx]\n            available = self.env.get_available_workers(slot.day, slot.hour)\n            if available and current != -1:\n                worker_hours = {w.worker_id: sum(1 for x in neighbor if x == w.worker_id)\n                               for w in self.env.workers}\n                current_hours = worker_hours.get(current, 0)\n                better = [w for w in available if abs(worker_hours.get(w, 0) - 17) < abs(current_hours - 17)]\n                if better:\n                    neighbor[idx] = random.choice(better)\n\n        return neighbor\n\n    def save_checkpoint(self, iteration: int, elapsed: float, temperature: float):\n        \"\"\"Save checkpoint to file\"\"\"\n        if not hasattr(self, 'checkpoint_dir') or not self.checkpoint_dir:\n            return\n\n        checkpoint = {\n            'algorithm': 'SA',\n            'iteration': iteration,\n            'elapsed_seconds': elapsed,\n            'elapsed_minutes': elapsed / 60,\n            'temperature': temperature,\n            'best_cost': self.best_cost,\n            'cost_history_length': len(self.cost_history),\n            'timestamp': datetime.now().isoformat()\n        }\n\n        self.checkpoint_history.append(checkpoint)\n\n        filename = os.path.join(self.checkpoint_dir, f'sa_checkpoint_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json')\n        try:\n            with open(filename, 'w', encoding='utf-8') as f:\n                json.dump({\n                    'checkpoint': checkpoint,\n                    'best_solution': self.best_solution.tolist() if self.best_solution is not None else None,\n                    'cost_history_sample': self.cost_history[::1000] if len(self.cost_history) > 1000 else self.cost_history\n                }, f, indent=2)\n        except Exception as e:\n            print(f\"  Warning: Could not save checkpoint: {e}\")\n\n    def solve(self, verbose: bool = True) -> Tuple[np.ndarray, float, List[float]]:\n        \"\"\"Run SA with proper cooling schedule and checkpointing\"\"\"\n        start_time = time.time()\n        last_checkpoint_time = start_time\n\n        current_solution = self.generate_initial_solution()\n        current_cost = self.env.evaluate_schedule(current_solution)[0]\n\n        self.best_solution = current_solution.copy()\n        self.best_cost = current_cost\n\n        temperature = self.initial_temp\n        iteration = 0\n        iterations_since_improvement = 0\n        reheat_count = 0\n\n        if verbose:\n            print(f\"SA Configuration:\")\n            print(f\"  Initial temp: {self.initial_temp}, Final temp: {self.final_temp}\")\n            print(f\"  Cooling rate: {self.cooling_rate}\")\n            print(f\"  Iterations per temp: {self.iterations_per_temp}\")\n            print(f\"  Max iterations: {self.max_iterations:,}\")\n            print(f\"  Max time: {self.max_time/60:.0f} min ({self.max_time/3600:.1f} hr)\")\n            print(f\"  Max reheats: {self.max_reheats}\")\n            print(f\"  Checkpoint interval: {self.checkpoint_interval}s\")\n            print(f\"\\nInitial cost: {current_cost:.2f}\")\n\n        while temperature > self.final_temp:\n            elapsed = time.time() - start_time\n\n            if iteration >= self.max_iterations:\n                if verbose:\n                    print(f\"\\n  STOPPING: Max iterations ({self.max_iterations:,}) reached\")\n                break\n            if elapsed >= self.max_time:\n                if verbose:\n                    print(f\"\\n  STOPPING: Max time ({self.max_time/60:.0f} min) reached\")\n                break\n            if reheat_count >= self.max_reheats:\n                if verbose:\n                    print(f\"\\n  STOPPING: Max reheats ({self.max_reheats}) reached\")\n                break\n\n            if elapsed - (last_checkpoint_time - start_time) >= self.checkpoint_interval:\n                if ENABLE_CHECKPOINTING:\n                    self.save_checkpoint(iteration, elapsed, temperature)\n                last_checkpoint_time = time.time()\n                if verbose:\n                    print(f\"  [Checkpoint saved at {elapsed/60:.1f} min]\")\n\n            for _ in range(self.iterations_per_temp):\n                iteration += 1\n                iterations_since_improvement += 1\n\n                if iteration >= self.max_iterations or (time.time() - start_time) >= self.max_time:\n                    break\n\n                new_solution = self.generate_neighbor(current_solution, temperature)\n                new_cost = self.env.evaluate_schedule(new_solution)[0]\n\n                delta = new_cost - current_cost\n\n                if delta < 0:\n                    accept = True\n                else:\n                    accept_prob = math.exp(-delta / max(temperature, 0.001))\n                    accept = random.random() < accept_prob\n\n                if accept:\n                    current_solution = new_solution\n                    current_cost = new_cost\n\n                    if current_cost < self.best_cost:\n                        self.best_solution = current_solution.copy()\n                        self.best_cost = current_cost\n                        iterations_since_improvement = 0\n\n                if iteration % 100 == 0:\n                    self.cost_history.append(self.best_cost)\n\n                if self.best_cost == 0:\n                    if verbose:\n                        print(f\"\\nPerfect solution found at iteration {iteration}!\")\n                    return self.best_solution, self.best_cost, self.cost_history\n\n            if iterations_since_improvement > 50000 and reheat_count < self.max_reheats:\n                reheat_count += 1\n                old_temp = temperature\n                temperature = self.initial_temp * (0.5 ** (reheat_count / 10))\n                iterations_since_improvement = 0\n                if verbose:\n                    print(f\"  Reheat #{reheat_count}: {old_temp:.1f} -> {temperature:.1f} at iter {iteration:,}\")\n\n            temperature *= self.cooling_rate\n\n            if verbose and iteration % 100000 == 0:\n                elapsed = time.time() - start_time\n                rate = iteration / elapsed if elapsed > 0 else 0\n                print(f\"  Iter {iteration:,}: Temp={temperature:.2f}, Best={self.best_cost:.1f}, \"\n                      f\"Time={elapsed/60:.1f}min, Rate={rate:.0f}/s\")\n\n        if ENABLE_CHECKPOINTING:\n            self.save_checkpoint(iteration, time.time() - start_time, temperature)\n\n        total_time = time.time() - start_time\n        if verbose:\n            print(f\"\\n{'='*60}\")\n            print(f\"SA COMPLETED\")\n            print(f\"{'='*60}\")\n            print(f\"Total time: {total_time:.1f}s ({total_time/60:.1f} min)\")\n            print(f\"Total iterations: {iteration:,}\")\n            print(f\"Reheats used: {reheat_count}\")\n            print(f\"Best cost: {self.best_cost:.2f}\")\n            _, details = self.env.evaluate_schedule(self.best_solution)\n            print(f\"Violations: {details}\")\n\n        return self.best_solution, self.best_cost, self.cost_history\n\nprint(\"Enhanced Simulated Annealing with checkpointing defined!\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Enhanced CSP Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class CSPSolver:\n    \"\"\"Optimized CSP solver with time limits\"\"\"\n\n    def __init__(self, environment: SchedulingEnvironment,\n                 max_time: float = 1800.0,\n                 local_search_iterations: int = 100000,\n                 batch_size: int = 200,\n                 num_restarts: int = 3):\n        \n        self.env = environment\n        self.max_time = max_time\n        self.local_search_iterations = local_search_iterations\n        self.batch_size = batch_size\n        self.num_restarts = num_restarts\n\n        self.worker_ids = [w.worker_id for w in self.env.workers]\n        self.nodes_explored = 0\n        self.improvements = 0\n        self.start_time = None\n\n        self.best_solution = None\n        self.best_penalty = float('inf')\n        self.min_shift = 2\n        self.max_shift = 6\n        self.min_hours = self.env.MIN_HOURS_PER_WORKER\n\n    def _get_worker_hours(self, assignment: np.ndarray) -> Dict[int, int]:\n        \"\"\"Count hours assigned to each worker\"\"\"\n        worker_hours = {w.worker_id: 0 for w in self.env.workers}\n        for worker_id in assignment:\n            if worker_id != -1 and worker_id in worker_hours:\n                worker_hours[worker_id] += 1\n        return worker_hours\n\n    def _build_greedy_solution(self, randomize: bool = False) -> np.ndarray:\n        \"\"\"Build initial solution using greedy construction\"\"\"\n        solution = np.full(self.env.num_slots, -1, dtype=int)\n        worker_hours = {w.worker_id: 0 for w in self.env.workers}\n\n        slot_groups = {}\n        for i, slot in enumerate(self.env.shift_slots):\n            key = (slot.day, slot.shift_type)\n            if key not in slot_groups:\n                slot_groups[key] = []\n            slot_groups[key].append((i, slot.hour))\n\n        for key in slot_groups:\n            slot_groups[key].sort(key=lambda x: x[1])\n\n        keys = list(slot_groups.keys())\n        if randomize:\n            random.shuffle(keys)\n\n        for (day, shift_type) in keys:\n            slots = slot_groups[(day, shift_type)]\n            i = 0\n            while i < len(slots):\n                slot_idx, hour = slots[i]\n                available = self.env.get_available_workers(day, hour)\n                if not available:\n                    i += 1\n                    continue\n\n                def worker_score(w_id):\n                    hours = worker_hours[w_id]\n                    base = 0 if hours < self.min_hours else 1000\n                    noise = random.random() * 10 if randomize else 0\n                    return base + hours + noise\n\n                available_sorted = sorted(available, key=worker_score)\n\n                for chosen in available_sorted:\n                    if worker_hours[chosen] >= 20:\n                        continue\n                    max_block = min(self.max_shift, 20 - worker_hours[chosen])\n                    if max_block < self.min_shift:\n                        continue\n\n                    block_length = 0\n                    for j in range(i, len(slots)):\n                        next_idx, next_hour = slots[j]\n                        if next_hour != hour + (j - i):\n                            break\n                        worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n                        if worker and worker.is_available(day, next_hour):\n                            block_length += 1\n                            if block_length >= max_block:\n                                break\n                        else:\n                            break\n\n                    if block_length >= self.min_shift:\n                        for j in range(block_length):\n                            next_idx, _ = slots[i + j]\n                            solution[next_idx] = chosen\n                        worker_hours[chosen] += block_length\n                        i += block_length\n                        break\n                else:\n                    i += 1\n\n        return solution\n\n    def _local_search(self, solution: np.ndarray, iterations: int, verbose: bool = True) -> np.ndarray:\n        \"\"\"Improve solution using local search\"\"\"\n        current = solution.copy()\n        current_penalty = self.env.evaluate_schedule(current)[0]\n\n        best = current.copy()\n        best_penalty = current_penalty\n\n        no_improvement_count = 0\n        max_no_improvement = 300\n\n        for iteration in range(iterations):\n            if time.time() - self.start_time > self.max_time:\n                break\n\n            move_type = random.choice(['swap', 'reassign_block', 'extend', 'fill_gap'])\n            neighbor = current.copy()\n\n            if move_type == 'swap':\n                assigned = [i for i, w in enumerate(current) if w != -1]\n                if len(assigned) >= 2:\n                    idx1, idx2 = random.sample(assigned, 2)\n                    slot1, slot2 = self.env.shift_slots[idx1], self.env.shift_slots[idx2]\n                    w1, w2 = neighbor[idx1], neighbor[idx2]\n                    worker1 = next((w for w in self.env.workers if w.worker_id == w1), None)\n                    worker2 = next((w for w in self.env.workers if w.worker_id == w2), None)\n                    if (worker1 and worker2 and\n                        worker1.is_available(slot2.day, slot2.hour) and\n                        worker2.is_available(slot1.day, slot1.hour)):\n                        neighbor[idx1], neighbor[idx2] = w2, w1\n\n            elif move_type == 'reassign_block':\n                assigned = [i for i, w in enumerate(current) if w != -1]\n                if assigned:\n                    idx = random.choice(assigned)\n                    slot = self.env.shift_slots[idx]\n                    old_worker = neighbor[idx]\n                    available = [w for w in self.env.get_available_workers(slot.day, slot.hour) if w != old_worker]\n                    if available:\n                        new_worker = random.choice(available)\n                        for i, s in enumerate(self.env.shift_slots):\n                            if (s.day == slot.day and s.shift_type == slot.shift_type and neighbor[i] == old_worker):\n                                worker = next((w for w in self.env.workers if w.worker_id == new_worker), None)\n                                if worker and worker.is_available(s.day, s.hour):\n                                    neighbor[i] = new_worker\n\n            elif move_type == 'extend':\n                assigned = [i for i, w in enumerate(current) if w != -1]\n                if assigned:\n                    idx = random.choice(assigned)\n                    slot = self.env.shift_slots[idx]\n                    worker_id = neighbor[idx]\n                    for i, s in enumerate(self.env.shift_slots):\n                        if (s.day == slot.day and s.shift_type == slot.shift_type and\n                            abs(s.hour - slot.hour) == 1 and neighbor[i] == -1):\n                            worker = next((w for w in self.env.workers if w.worker_id == worker_id), None)\n                            if worker and worker.is_available(s.day, s.hour):\n                                hours = sum(1 for w in neighbor if w == worker_id)\n                                if hours < 20:\n                                    neighbor[i] = worker_id\n                                    break\n\n            elif move_type == 'fill_gap':\n                empty = [i for i, w in enumerate(current) if w == -1]\n                if empty:\n                    idx = random.choice(empty)\n                    slot = self.env.shift_slots[idx]\n                    available = self.env.get_available_workers(slot.day, slot.hour)\n                    worker_hours = self._get_worker_hours(neighbor)\n                    under_min = [w for w in available if worker_hours[w] < self.min_hours]\n                    if under_min:\n                        chosen = random.choice(under_min)\n                    elif available:\n                        chosen = random.choice(available)\n                    else:\n                        continue\n                    block_size = random.randint(2, 4)\n                    for i, s in enumerate(self.env.shift_slots):\n                        if (s.day == slot.day and s.shift_type == slot.shift_type and\n                            slot.hour <= s.hour < slot.hour + block_size and neighbor[i] == -1):\n                            worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n                            if worker and worker.is_available(s.day, s.hour):\n                                hours = sum(1 for w in neighbor if w == chosen)\n                                if hours < 20:\n                                    neighbor[i] = chosen\n\n            neighbor_penalty = self.env.evaluate_schedule(neighbor)[0]\n            self.nodes_explored += 1\n\n            if neighbor_penalty < current_penalty:\n                current = neighbor\n                current_penalty = neighbor_penalty\n                no_improvement_count = 0\n                if current_penalty < best_penalty:\n                    best = current.copy()\n                    best_penalty = current_penalty\n                    self.improvements += 1\n            else:\n                no_improvement_count += 1\n                if random.random() < 0.02:\n                    current = neighbor\n                    current_penalty = neighbor_penalty\n\n            if no_improvement_count > max_no_improvement:\n                current = self._build_greedy_solution(randomize=True)\n                current_penalty = self.env.evaluate_schedule(current)[0]\n                no_improvement_count = 0\n\n        return best\n\n    def solve(self, verbose: bool = True) -> Tuple[Optional[np.ndarray], float, Dict]:\n        \"\"\"Solve with multi-restart strategy\"\"\"\n        self.start_time = time.time()\n        self.nodes_explored = 0\n        self.improvements = 0\n\n        if verbose:\n            print(f\"CSP: max_time={self.max_time/60:.0f}min, iterations={self.local_search_iterations:,}\")\n\n        iterations_per_restart = self.local_search_iterations // self.num_restarts\n\n        for restart in range(self.num_restarts):\n            if time.time() - self.start_time > self.max_time:\n                break\n                \n            if verbose:\n                print(f\"  Restart {restart + 1}/{self.num_restarts}\")\n\n            initial_solution = self._build_greedy_solution(randomize=(restart > 0))\n            initial_penalty = self.env.evaluate_schedule(initial_solution)[0]\n\n            best_solution = self._local_search(initial_solution, iterations_per_restart, verbose)\n            best_penalty = self.env.evaluate_schedule(best_solution)[0]\n\n            if best_penalty < self.best_penalty:\n                self.best_penalty = best_penalty\n                self.best_solution = best_solution.copy()\n                if verbose:\n                    print(f\"    New best: {self.best_penalty:.2f}\")\n\n        elapsed_time = time.time() - self.start_time\n        stats = {'nodes_explored': self.nodes_explored, 'improvements': self.improvements, \n                 'time': elapsed_time, 'success': True}\n\n        if verbose:\n            print(f\"\\nCSP completed in {elapsed_time:.1f}s ({elapsed_time/60:.1f} min)\")\n            print(f\"Best penalty: {self.best_penalty:.2f}\")\n            _, details = self.env.evaluate_schedule(self.best_solution)\n            print(f\"Violations: {details}\")\n\n        return self.best_solution, self.best_penalty, stats\n\nprint(\"Optimized CSP Solver defined!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Run Algorithms (Choose Individual or Parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# PARALLEL EXECUTION WITH GPU ACCELERATION\n# ============================================================================\n# Runs all algorithms simultaneously - total time = max(GA, SA, CSP) time\n\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nRUN_GA = True\nRUN_SA = True  \nRUN_CSP = True\n\nresults = {}\n\n# ============================================================================\n# ALGORITHM RUNNER FUNCTIONS\n# ============================================================================\n\ndef run_ga(workers_data, schedule_type, config):\n    \"\"\"Run GA in separate thread\"\"\"\n    local_env = SchedulingEnvironment(workers_data, schedule_type=schedule_type)\n    print(f\"\\n{'='*60}\\nSTARTING GENETIC ALGORITHM\\n{'='*60}\")\n    \n    ga = GeneticAlgorithm(\n        local_env,\n        population_size=config['population_size'],\n        generations=config['generations'],\n        crossover_rate=config['crossover_rate'],\n        mutation_rate=config['mutation_rate'],\n        elitism_count=config['elitism_count'],\n        batch_size=config['batch_size']\n    )\n    \n    start = time.time()\n    solution, fitness, history = ga.solve(verbose=True)\n    elapsed = time.time() - start\n    \n    _, details = local_env.evaluate_schedule(solution)\n    print(f\"\\n*** GA COMPLETE: {fitness:.1f} penalty in {elapsed/60:.1f} min ***\")\n    \n    return {'algo': 'GA', 'solution': solution, 'penalty': fitness, \n            'history': history, 'time': elapsed, 'details': details}\n\ndef run_sa(workers_data, schedule_type, config):\n    \"\"\"Run SA in separate thread\"\"\"\n    local_env = SchedulingEnvironment(workers_data, schedule_type=schedule_type)\n    print(f\"\\n{'='*60}\\nSTARTING SIMULATED ANNEALING\\n{'='*60}\")\n    \n    sa = SimulatedAnnealing(\n        local_env,\n        initial_temp=config['initial_temp'],\n        final_temp=config['final_temp'],\n        cooling_rate=config['cooling_rate'],\n        iterations_per_temp=config['iterations_per_temp'],\n        batch_eval=config['batch_eval']\n    )\n    \n    start = time.time()\n    solution, cost, history = sa.solve(verbose=True)\n    elapsed = time.time() - start\n    \n    _, details = local_env.evaluate_schedule(solution)\n    print(f\"\\n*** SA COMPLETE: {cost:.1f} penalty in {elapsed/60:.1f} min ***\")\n    \n    return {'algo': 'SA', 'solution': solution, 'penalty': cost,\n            'history': history, 'time': elapsed, 'details': details}\n\ndef run_csp(workers_data, schedule_type, config):\n    \"\"\"Run CSP in separate thread\"\"\"\n    local_env = SchedulingEnvironment(workers_data, schedule_type=schedule_type)\n    print(f\"\\n{'='*60}\\nSTARTING CSP SOLVER\\n{'='*60}\")\n    \n    csp = CSPSolver(\n        local_env,\n        max_time=config['max_time'],\n        local_search_iterations=config['local_search_iterations'],\n        batch_size=config['batch_size']\n    )\n    \n    start = time.time()\n    solution, penalty, stats = csp.solve(verbose=True)\n    elapsed = time.time() - start\n    \n    _, details = local_env.evaluate_schedule(solution)\n    print(f\"\\n*** CSP COMPLETE: {penalty:.1f} penalty in {elapsed/60:.1f} min ***\")\n    \n    return {'algo': 'CSP', 'solution': solution, 'penalty': penalty,\n            'history': [], 'time': elapsed, 'details': details}\n\n# ============================================================================\n# EXECUTE IN PARALLEL\n# ============================================================================\n\nprint(\"=\"*70)\nprint(f\"PARALLEL EXECUTION - GPU: {'ENABLED' if USE_GPU else 'DISABLED'}\")\nprint(f\"Profile: {COMPUTE_PROFILE.upper()}\")\nprint(\"=\"*70)\n\nparallel_start = time.time()\n\ntasks = []\nif RUN_GA:\n    tasks.append(('GA', run_ga, GA_CONFIG))\nif RUN_SA:\n    tasks.append(('SA', run_sa, SA_CONFIG))\nif RUN_CSP:\n    tasks.append(('CSP', run_csp, CSP_CONFIG))\n\nprint(f\"Running {len(tasks)} algorithms in parallel...\")\n\nwith ThreadPoolExecutor(max_workers=len(tasks)) as executor:\n    futures = {executor.submit(func, workers, env.schedule_type, cfg): name \n               for name, func, cfg in tasks}\n    \n    for future in as_completed(futures):\n        algo = futures[future]\n        try:\n            result = future.result()\n            results[result['algo']] = {\n                'solution': result['solution'],\n                'penalty': result['penalty'],\n                'history': result['history'],\n                'time': result['time'],\n                'details': result['details']\n            }\n        except Exception as e:\n            print(f\"ERROR in {algo}: {e}\")\n            import traceback\n            traceback.print_exc()\n\nparallel_time = time.time() - parallel_start\n\n# ============================================================================\n# SUMMARY\n# ============================================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"EXECUTION SUMMARY\")\nprint(\"=\"*70)\nprint(f\"Total wall-clock time: {parallel_time/60:.1f} minutes\")\n\nif results:\n    seq_time = sum(r['time'] for r in results.values())\n    speedup = seq_time / parallel_time if parallel_time > 0 else 1\n    print(f\"Sequential time would be: {seq_time/60:.1f} minutes\")\n    print(f\"Parallel speedup: {speedup:.2f}x\")\n    \n    print(f\"\\nResults:\")\n    for algo in ['GA', 'SA', 'CSP']:\n        if algo in results:\n            r = results[algo]\n            print(f\"  {algo}: Penalty={r['penalty']:.1f}, Time={r['time']/60:.1f}min\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Results Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ALGORITHM COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n{'Algorithm':<15} {'Penalty':<15} {'Runtime':<15} {'Status'}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "best_algo = min(results.keys(), key=lambda a: results[a]['penalty'])\n",
    "\n",
    "for algo in ['GA', 'SA', 'CSP']:\n",
    "    if algo in results:\n",
    "        r = results[algo]\n",
    "        runtime_str = f\"{r['time']:.1f}s\" if r['time'] < 60 else f\"{r['time']/60:.1f}min\"\n",
    "        status = \"<-- BEST\" if algo == best_algo else \"\"\n",
    "        print(f\"{algo:<15} {r['penalty']:<15.2f} {runtime_str:<15} {status}\")\n",
    "\n",
    "# Detailed violations\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CONSTRAINT VIOLATIONS BREAKDOWN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "constraints = [\n",
    "    'coverage_violations', 'worker_conflicts', 'hour_violations',\n",
    "    'min_hour_violations', 'shift_length_violations', 'tier_mismatches',\n",
    "    'fairness_violations', 'morning_shift_violations'\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Constraint':<30}\", end=\"\")\n",
    "for algo in ['GA', 'SA', 'CSP']:\n",
    "    if algo in results:\n",
    "        print(f\"{algo:<10}\", end=\"\")\n",
    "print()\n",
    "print(\"-\"*60)\n",
    "\n",
    "for constraint in constraints:\n",
    "    print(f\"{constraint:<30}\", end=\"\")\n",
    "    for algo in ['GA', 'SA', 'CSP']:\n",
    "        if algo in results:\n",
    "            val = results[algo]['details'].get(constraint, 0)\n",
    "            print(f\"{val:<10}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# Best solution details\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BEST SOLUTION: {best_algo} (Penalty: {results[best_algo]['penalty']:.2f})\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# PROFESSIONAL VISUALIZATIONS WITH SEABORN\n# ============================================================================\n\nimport pandas as pd\n\n# Determine best algorithm\nbest_algo = min(results.keys(), key=lambda a: results[a]['penalty'])\n\n# Create figure with publication-quality settings\nfig = plt.figure(figsize=(16, 12))\n\n# Color palette\npalette = sns.color_palette(\"husl\", 3)\nalgo_colors = {'GA': palette[0], 'SA': palette[1], 'CSP': palette[2]}\n\n# ============================================================================\n# Plot 1: Algorithm Performance Comparison (Bar Chart)\n# ============================================================================\nax1 = fig.add_subplot(2, 2, 1)\n\nalgos = list(results.keys())\npenalties = [results[a]['penalty'] for a in algos]\ncolors = [algo_colors[a] for a in algos]\n\nbars = ax1.bar(algos, penalties, color=colors, edgecolor='black', linewidth=1.2)\n\n# Highlight best algorithm\nfor i, (algo, bar) in enumerate(zip(algos, bars)):\n    if algo == best_algo:\n        bar.set_edgecolor('gold')\n        bar.set_linewidth(3)\n        ax1.annotate('BEST', xy=(i, penalties[i]), xytext=(0, 10),\n                    textcoords='offset points', ha='center', fontweight='bold',\n                    color='darkgreen', fontsize=11)\n\n# Add value labels\nfor i, (algo, penalty) in enumerate(zip(algos, penalties)):\n    ax1.text(i, penalty + max(penalties)*0.02, f'{penalty:.0f}', \n             ha='center', va='bottom', fontweight='bold', fontsize=12)\n\nax1.set_ylabel('Penalty Score (lower is better)', fontsize=12)\nax1.set_title('Algorithm Performance Comparison', fontsize=14, fontweight='bold')\nax1.set_ylim(0, max(penalties) * 1.15)\nsns.despine(ax=ax1)\n\n# ============================================================================\n# Plot 2: Runtime Comparison\n# ============================================================================\nax2 = fig.add_subplot(2, 2, 2)\n\nruntimes_min = [results[a]['time'] / 60 for a in algos]\n\nbars2 = ax2.barh(algos, runtimes_min, color=colors, edgecolor='black', linewidth=1.2)\n\nfor i, (algo, rt) in enumerate(zip(algos, runtimes_min)):\n    ax2.text(rt + max(runtimes_min)*0.02, i, f'{rt:.1f} min', \n             va='center', fontweight='bold', fontsize=11)\n\nax2.set_xlabel('Runtime (minutes)', fontsize=12)\nax2.set_title('Algorithm Runtime Comparison', fontsize=14, fontweight='bold')\nax2.set_xlim(0, max(runtimes_min) * 1.2)\nsns.despine(ax=ax2)\n\n# ============================================================================\n# Plot 3: Convergence History\n# ============================================================================\nax3 = fig.add_subplot(2, 2, 3)\n\nfor algo in algos:\n    history = results[algo]['history']\n    if history:\n        # Subsample for cleaner visualization\n        if len(history) > 2000:\n            step = len(history) // 2000\n            history = history[::step]\n            x = list(range(0, len(results[algo]['history']), step))\n        else:\n            x = list(range(len(history)))\n        \n        ax3.plot(x, history, label=f'{algo} (final: {results[algo][\"penalty\"]:.0f})', \n                 color=algo_colors[algo], linewidth=2, alpha=0.9)\n\nax3.set_xlabel('Iteration', fontsize=12)\nax3.set_ylabel('Best Penalty (log scale)', fontsize=12)\nax3.set_title('Optimization Convergence', fontsize=14, fontweight='bold')\nax3.set_yscale('log')\nax3.legend(loc='upper right', frameon=True, fancybox=True, shadow=True)\nax3.grid(True, alpha=0.3)\nsns.despine(ax=ax3)\n\n# ============================================================================\n# Plot 4: Constraint Violations Heatmap\n# ============================================================================\nax4 = fig.add_subplot(2, 2, 4)\n\nconstraints = ['coverage_violations', 'worker_conflicts', 'hour_violations',\n               'min_hour_violations', 'shift_length_violations', 'tier_mismatches',\n               'morning_shift_violations']\n\n# Build data matrix\nviolation_data = []\nfor algo in algos:\n    row = [results[algo]['details'].get(c, 0) for c in constraints]\n    violation_data.append(row)\n\n# Clean constraint names for display\nclean_names = [c.replace('_', ' ').title() for c in constraints]\n\n# Create DataFrame\ndf_violations = pd.DataFrame(violation_data, index=algos, columns=clean_names)\n\n# Create heatmap\nsns.heatmap(df_violations, annot=True, fmt='d', cmap='RdYlGn_r', \n            linewidths=0.5, ax=ax4, cbar_kws={'label': 'Violation Count'},\n            annot_kws={'size': 11, 'weight': 'bold'})\n\nax4.set_title('Constraint Violations by Algorithm', fontsize=14, fontweight='bold')\nax4.set_xticklabels(ax4.get_xticklabels(), rotation=45, ha='right', fontsize=10)\nax4.set_yticklabels(ax4.get_yticklabels(), rotation=0, fontsize=11)\n\nplt.tight_layout()\nplt.savefig('algorithm_comparison.png', dpi=200, bbox_inches='tight', \n            facecolor='white', edgecolor='none')\nplt.show()\n\nprint(f\"\\nVisualization saved to: algorithm_comparison.png\")\n\n# ============================================================================\n# Additional Summary Statistics\n# ============================================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"DETAILED RESULTS SUMMARY\")\nprint(\"=\"*70)\n\nprint(f\"\\n{'Algorithm':<10} {'Penalty':<12} {'Runtime':<12} {'Violations':<15} {'Status'}\")\nprint(\"-\"*60)\n\nfor algo in algos:\n    r = results[algo]\n    total_violations = sum(r['details'].values())\n    status = \"*** BEST ***\" if algo == best_algo else \"\"\n    print(f\"{algo:<10} {r['penalty']:<12.1f} {r['time']/60:<12.1f}min {total_violations:<15} {status}\")\n\nprint(f\"\\nBest Solution: {best_algo} with penalty {results[best_algo]['penalty']:.1f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Export Best Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_schedule(solution, env, filename_prefix='best_schedule'):\n",
    "    \"\"\"Export schedule to JSON format\"\"\"\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "    \n",
    "    # Build schedule structure\n",
    "    schedule_by_day = {day: [] for day in day_names}\n",
    "    \n",
    "    for i, worker_id in enumerate(solution):\n",
    "        if worker_id == -1:\n",
    "            continue\n",
    "        \n",
    "        slot = env.shift_slots[i]\n",
    "        worker = next((w for w in env.workers if w.worker_id == worker_id), None)\n",
    "        \n",
    "        if worker:\n",
    "            schedule_by_day[day_names[slot.day]].append({\n",
    "                'hour': slot.hour,\n",
    "                'shift_type': slot.shift_type,\n",
    "                'worker_id': worker_id,\n",
    "                'worker_name': worker.name,\n",
    "                'tier': worker.tier\n",
    "            })\n",
    "    \n",
    "    # Sort by hour\n",
    "    for day in schedule_by_day:\n",
    "        schedule_by_day[day].sort(key=lambda x: (x['hour'], x['shift_type']))\n",
    "    \n",
    "    # Calculate worker hours\n",
    "    worker_hours = {}\n",
    "    for worker in env.workers:\n",
    "        hours = sum(1 for w in solution if w == worker.worker_id)\n",
    "        worker_hours[worker.name] = {\n",
    "            'assigned': hours,\n",
    "            'desired': worker.desired_hours,\n",
    "            'tier': worker.tier\n",
    "        }\n",
    "    \n",
    "    # Get penalty details\n",
    "    penalty, details = env.evaluate_schedule(solution)\n",
    "    \n",
    "    output = {\n",
    "        'generated': datetime.now().isoformat(),\n",
    "        'penalty': penalty,\n",
    "        'violations': details,\n",
    "        'schedule': schedule_by_day,\n",
    "        'worker_hours': worker_hours\n",
    "    }\n",
    "    \n",
    "    filename = f\"{filename_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "    \n",
    "    print(f\"Schedule exported to: {filename}\")\n",
    "    return filename\n",
    "\n",
    "# Export best solution\n",
    "best_solution = results[best_algo]['solution']\n",
    "export_schedule(best_solution, env, f'best_schedule_{best_algo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Display Human-Readable Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_schedule(solution, env):\n",
    "    \"\"\"Print human-readable schedule\"\"\"\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "    \n",
    "    # Group by day, hour, shift_type\n",
    "    schedule = {}\n",
    "    for i, worker_id in enumerate(solution):\n",
    "        if worker_id == -1:\n",
    "            continue\n",
    "        \n",
    "        slot = env.shift_slots[i]\n",
    "        key = (slot.day, slot.hour, slot.shift_type)\n",
    "        if key not in schedule:\n",
    "            schedule[key] = []\n",
    "        \n",
    "        worker = next((w for w in env.workers if w.worker_id == worker_id), None)\n",
    "        if worker:\n",
    "            schedule[key].append(f\"{worker.name} (T{worker.tier})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BEST SCHEDULE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for day_idx, day_name in enumerate(day_names):\n",
    "        print(f\"\\n{day_name}:\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        day_schedule = {k: v for k, v in schedule.items() if k[0] == day_idx}\n",
    "        hours = sorted(set(k[1] for k in day_schedule.keys()))\n",
    "        \n",
    "        for hour in hours:\n",
    "            window = schedule.get((day_idx, hour, 'Window'), [])\n",
    "            remote = schedule.get((day_idx, hour, 'Remote'), [])\n",
    "            \n",
    "            print(f\"  {hour:02d}:00-{hour+1:02d}:00 | Window: {', '.join(window) if window else '---':<40}\")\n",
    "            print(f\"               | Remote: {', '.join(remote) if remote else '---'}\")\n",
    "    \n",
    "    # Worker summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"WORKER HOURS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Worker':<25} {'Assigned':<10} {'Desired':<10} {'Diff':<10}\")\n",
    "    print(\"-\"*55)\n",
    "    \n",
    "    for worker in env.workers:\n",
    "        assigned = sum(1 for w in solution if w == worker.worker_id)\n",
    "        diff = assigned - worker.desired_hours\n",
    "        diff_str = f\"+{diff:.0f}\" if diff > 0 else f\"{diff:.0f}\"\n",
    "        print(f\"{worker.name:<25} {assigned:<10} {worker.desired_hours:<10.0f} {diff_str:<10}\")\n",
    "\n",
    "print_schedule(best_solution, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14: Hyperparameter Grid Search (Optional - Extended Run)\n",
    "\n",
    "Use this for exhaustive hyperparameter tuning. Warning: This can take a very long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# OPTIONAL: GPU-Accelerated Hyperparameter Grid Search\n# ============================================================================\n# Set to True only if you want to tune hyperparameters (adds significant time)\n\nRUN_GRID_SEARCH = False\n\nif RUN_GRID_SEARCH:\n    print(\"=\"*60)\n    print(\"GPU-ACCELERATED HYPERPARAMETER GRID SEARCH\")\n    print(\"=\"*60)\n    print(f\"GPU: {GPU_NAME if USE_GPU else 'Not available'}\")\n    \n    # Quick grid search - test key parameters\n    ga_grid = {\n        'population_size': [500, 1000],\n        'generations': [5000, 10000],\n        'mutation_rate': [0.35, 0.45]\n    }\n    \n    grid_results = []\n    total_configs = len(ga_grid['population_size']) * len(ga_grid['generations']) * len(ga_grid['mutation_rate'])\n    config_num = 0\n    \n    grid_start = time.time()\n    \n    for pop in ga_grid['population_size']:\n        for gens in ga_grid['generations']:\n            for mut in ga_grid['mutation_rate']:\n                config_num += 1\n                print(f\"\\n[{config_num}/{total_configs}] pop={pop}, gens={gens}, mut={mut}\")\n                \n                test_env = SchedulingEnvironment(workers, schedule_type='finals')\n                ga = GeneticAlgorithm(\n                    test_env,\n                    population_size=pop,\n                    generations=gens,\n                    mutation_rate=mut,\n                    elitism_count=max(10, pop//20),\n                    batch_size=pop\n                )\n                \n                start = time.time()\n                solution, penalty, _ = ga.solve(verbose=False)\n                runtime = time.time() - start\n                \n                grid_results.append({\n                    'population_size': pop,\n                    'generations': gens,\n                    'mutation_rate': mut,\n                    'penalty': penalty,\n                    'runtime': runtime\n                })\n                print(f\"  -> Penalty: {penalty:.1f}, Time: {runtime:.1f}s\")\n    \n    grid_time = time.time() - grid_start\n    \n    # Find best configuration\n    best_config = min(grid_results, key=lambda x: x['penalty'])\n    \n    print(f\"\\n{'='*60}\")\n    print(\"GRID SEARCH RESULTS\")\n    print(f\"{'='*60}\")\n    print(f\"Total time: {grid_time/60:.1f} minutes\")\n    print(f\"\\nBest Configuration:\")\n    print(f\"  Population Size: {best_config['population_size']}\")\n    print(f\"  Generations: {best_config['generations']}\")\n    print(f\"  Mutation Rate: {best_config['mutation_rate']}\")\n    print(f\"  Best Penalty: {best_config['penalty']:.1f}\")\n    print(f\"  Runtime: {best_config['runtime']:.1f}s\")\n    \n    # Visualize results\n    fig, ax = plt.subplots(figsize=(10, 6))\n    \n    df_grid = pd.DataFrame(grid_results)\n    df_grid['config'] = df_grid.apply(\n        lambda r: f\"p{r['population_size']}_g{r['generations']}_m{r['mutation_rate']}\", axis=1)\n    \n    colors = ['green' if r['penalty'] == best_config['penalty'] else 'steelblue' \n              for _, r in df_grid.iterrows()]\n    \n    bars = ax.bar(range(len(df_grid)), df_grid['penalty'], color=colors)\n    ax.set_xticks(range(len(df_grid)))\n    ax.set_xticklabels(df_grid['config'], rotation=45, ha='right')\n    ax.set_ylabel('Penalty')\n    ax.set_title('Hyperparameter Grid Search Results')\n    sns.despine()\n    plt.tight_layout()\n    plt.savefig('grid_search_results.png', dpi=150)\n    plt.show()\n    \nelse:\n    print(\"Grid search disabled. Set RUN_GRID_SEARCH = True to enable.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}