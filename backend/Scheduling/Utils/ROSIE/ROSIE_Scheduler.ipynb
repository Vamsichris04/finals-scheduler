{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT Help Desk Scheduling - ROSIE Supercomputer Edition\n",
    "\n",
    "This notebook consolidates the entire scheduling system for running on ROSIE.\n",
    "It includes:\n",
    "- Extended search parameters for supercomputer-scale optimization\n",
    "- Parallel execution support for multi-core utilization\n",
    "- Hyperparameter grid search\n",
    "- Comprehensive visualization and comparison\n",
    "\n",
    "## Quick Start\n",
    "1. Run cells 1-4 to set up the environment and load data\n",
    "2. Run cell 5 to configure hyperparameters (adjust for your compute budget)\n",
    "3. Run cells 6-8 for individual algorithms OR cell 9 for parallel comparison\n",
    "4. Run cell 10 for results visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Parallel processing\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from multiprocessing import cpu_count, Manager\n",
    "import threading\n",
    "\n",
    "# GPU Acceleration with PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# MongoDB\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Visualization - Seaborn for better plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Seaborn style for all plots\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"husl\")\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "# ============================================================================\n",
    "# GPU/CUDA SETUP\n",
    "# ============================================================================\n",
    "NUM_CORES = cpu_count()\n",
    "print(f\"Available CPU cores: {NUM_CORES}\")\n",
    "\n",
    "# Check for GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda:0')\n",
    "    GPU_NAME = torch.cuda.get_device_name(0)\n",
    "    GPU_COUNT = torch.cuda.device_count()\n",
    "    GPU_MEMORY = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"GPU ACCELERATION ENABLED!\")\n",
    "    print(f\"  Device: {GPU_NAME}\")\n",
    "    print(f\"  GPU Count: {GPU_COUNT}\")\n",
    "    print(f\"  Memory: {GPU_MEMORY:.1f} GB\")\n",
    "    USE_GPU = True\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print(\"No GPU available - using CPU (will be slower)\")\n",
    "    USE_GPU = False\n",
    "\n",
    "print(f\"PyTorch device: {DEVICE}\")\n",
    "\n",
    "# Quick GPU benchmark\n",
    "if USE_GPU:\n",
    "    a = torch.randn((1000, 1000), device=DEVICE)\n",
    "    b = torch.randn((1000, 1000), device=DEVICE)\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    for _ in range(100):\n",
    "        c = torch.matmul(a, b)\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    print(f\"GPU benchmark: 100x 1000x1000 matmul in {t1-t0:.3f}s\")\n",
    "    del a, b, c\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Core Classes (Worker, ShiftSlot, SchedulingEnvironment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker:\n",
    "    \"\"\"Represents a student worker with their attributes\"\"\"\n",
    "    def __init__(self, worker_id: int, name: str, tier: int, is_commuter: bool, \n",
    "                 desired_hours: float, busy_times: List[Tuple[int, int, int]]):\n",
    "        self.worker_id = worker_id\n",
    "        self.name = name\n",
    "        self.tier = tier  # 1-4 (4 = manager, 3 = inventory tech)\n",
    "        self.is_commuter = is_commuter\n",
    "        self.desired_hours = desired_hours\n",
    "        self.busy_times = busy_times\n",
    "        \n",
    "    def is_available(self, day: int, hour: int) -> bool:\n",
    "        \"\"\"Check if worker is available at given day and hour\"\"\"\n",
    "        if self.is_commuter and hour < 9:\n",
    "            return False\n",
    "        for busy_day, busy_start, busy_end in self.busy_times:\n",
    "            if day == busy_day and busy_start <= hour < busy_end:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "class ShiftSlot:\n",
    "    \"\"\"Represents a time slot that needs coverage\"\"\"\n",
    "    def __init__(self, day: int, hour: int, shift_type: str):\n",
    "        self.day = day\n",
    "        self.hour = hour\n",
    "        self.shift_type = shift_type\n",
    "        self.assigned_worker = None\n",
    "\n",
    "\n",
    "class SchedulingEnvironment:\n",
    "    \"\"\"Main environment for IT scheduling problem with GPU-accelerated batch evaluation\"\"\"\n",
    "    \n",
    "    SHIFT_TYPES = ['Window', 'Remote']\n",
    "    \n",
    "    HOURS_CONFIG = {\n",
    "        'finals': {\n",
    "            0: (7.5, 20), 1: (7.5, 20), 2: (7.5, 20), 3: (7.5, 20),\n",
    "            4: (7.5, 17), 5: (10, 18),\n",
    "        },\n",
    "        'regular': {\n",
    "            0: (7.5, 20), 1: (7.5, 20), 2: (7.5, 20), 3: (7.5, 20),\n",
    "            4: (7.5, 17), 5: (10, 18),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    MIN_HOURS_PER_WORKER = 14\n",
    "    MAX_HOURS_PER_WORKER = 20\n",
    "\n",
    "    COVERAGE_REQUIREMENTS = {\n",
    "        'Window': {'min': 2, 'max': 2},\n",
    "        'Remote': {'min': 2, 'max': 4}\n",
    "    }\n",
    "    \n",
    "    def __init__(self, workers: List[Worker], schedule_type: str = 'finals'):\n",
    "        self.workers = workers\n",
    "        self.schedule_type = schedule_type\n",
    "        self.hours_config = self.HOURS_CONFIG[schedule_type]\n",
    "        self.shift_slots = self._generate_shift_slots()\n",
    "        self.num_slots = len(self.shift_slots)\n",
    "        \n",
    "        # Pre-compute lookup tables for GPU acceleration\n",
    "        self._build_gpu_lookup_tables()\n",
    "        \n",
    "    def _generate_shift_slots(self) -> List[ShiftSlot]:\n",
    "        \"\"\"Generate all shift slots\"\"\"\n",
    "        slots = []\n",
    "        for day, (start_hour, end_hour) in self.hours_config.items():\n",
    "            start_int = int(np.ceil(start_hour))\n",
    "            end_int = int(end_hour)\n",
    "            for hour in range(start_int, end_int):\n",
    "                for _ in range(self.COVERAGE_REQUIREMENTS['Window']['max']):\n",
    "                    slots.append(ShiftSlot(day, hour, 'Window'))\n",
    "                for _ in range(self.COVERAGE_REQUIREMENTS['Remote']['max']):\n",
    "                    slots.append(ShiftSlot(day, hour, 'Remote'))\n",
    "        return slots\n",
    "    \n",
    "    def _build_gpu_lookup_tables(self):\n",
    "        \"\"\"Pre-compute lookup tables for fast GPU evaluation\"\"\"\n",
    "        # Worker ID to index mapping\n",
    "        self.worker_id_to_idx = {w.worker_id: i for i, w in enumerate(self.workers)}\n",
    "        self.idx_to_worker_id = {i: w.worker_id for i, w in enumerate(self.workers)}\n",
    "        self.num_workers = len(self.workers)\n",
    "        \n",
    "        # Slot properties as tensors\n",
    "        self.slot_days = torch.tensor([s.day for s in self.shift_slots], device=DEVICE, dtype=torch.int32)\n",
    "        self.slot_hours = torch.tensor([s.hour for s in self.shift_slots], device=DEVICE, dtype=torch.int32)\n",
    "        self.slot_is_window = torch.tensor([1 if s.shift_type == 'Window' else 0 \n",
    "                                            for s in self.shift_slots], device=DEVICE, dtype=torch.int32)\n",
    "        \n",
    "        # Worker properties as tensors\n",
    "        self.worker_tiers = torch.tensor([w.tier for w in self.workers], device=DEVICE, dtype=torch.int32)\n",
    "        self.worker_is_commuter = torch.tensor([1 if w.is_commuter else 0 \n",
    "                                                 for w in self.workers], device=DEVICE, dtype=torch.int32)\n",
    "        \n",
    "        # Availability matrix: (num_workers, num_slots) - 1 if available, 0 if not\n",
    "        availability = np.zeros((self.num_workers, self.num_slots), dtype=np.float32)\n",
    "        for w_idx, worker in enumerate(self.workers):\n",
    "            for s_idx, slot in enumerate(self.shift_slots):\n",
    "                if worker.is_available(slot.day, slot.hour):\n",
    "                    availability[w_idx, s_idx] = 1.0\n",
    "        self.availability_matrix = torch.tensor(availability, device=DEVICE)\n",
    "        \n",
    "        # Coverage group indices - which slots belong to same (day, hour) group\n",
    "        self.coverage_groups = {}\n",
    "        for i, slot in enumerate(self.shift_slots):\n",
    "            key = (slot.day, slot.hour)\n",
    "            if key not in self.coverage_groups:\n",
    "                self.coverage_groups[key] = {'Window': [], 'Remote': []}\n",
    "            self.coverage_groups[key][slot.shift_type].append(i)\n",
    "        \n",
    "        print(f\"GPU lookup tables built: {self.num_slots} slots, {self.num_workers} workers\")\n",
    "    \n",
    "    def evaluate_schedule(self, schedule: np.ndarray) -> Tuple[float, Dict]:\n",
    "        \"\"\"Evaluate a single schedule (CPU version for compatibility)\"\"\"\n",
    "        penalty = 0\n",
    "        details = {\n",
    "            'coverage_violations': 0, 'tier_mismatches': 0, 'worker_conflicts': 0,\n",
    "            'hour_violations': 0, 'min_hour_violations': 0, \n",
    "            'morning_shift_violations': 0, 'shift_length_violations': 0\n",
    "        }\n",
    "\n",
    "        # Coverage check\n",
    "        for key, shifts in self.coverage_groups.items():\n",
    "            window_count = sum(1 for i in shifts['Window'] if schedule[i] != -1)\n",
    "            remote_count = sum(1 for i in shifts['Remote'] if schedule[i] != -1)\n",
    "            \n",
    "            if window_count < 2:\n",
    "                penalty += 100 * (2 - window_count)\n",
    "                details['coverage_violations'] += 1\n",
    "            if remote_count < 2:\n",
    "                penalty += 100 * (2 - remote_count)\n",
    "                details['coverage_violations'] += 1\n",
    "\n",
    "        # Worker stats\n",
    "        worker_hours = {w.worker_id: 0 for w in self.workers}\n",
    "        worker_morning = {w.worker_id: 0 for w in self.workers}\n",
    "        worker_assignments = {w.worker_id: [] for w in self.workers}\n",
    "        \n",
    "        for i, worker_id in enumerate(schedule):\n",
    "            if worker_id == -1:\n",
    "                continue\n",
    "            slot = self.shift_slots[i]\n",
    "            worker_hours[worker_id] += 1\n",
    "            worker_assignments[worker_id].append(i)\n",
    "            if slot.hour < 12:\n",
    "                worker_morning[worker_id] += 1\n",
    "            \n",
    "            worker = next((w for w in self.workers if w.worker_id == worker_id), None)\n",
    "            if worker and not worker.is_available(slot.day, slot.hour):\n",
    "                penalty += 200\n",
    "                details['worker_conflicts'] += 1\n",
    "            if worker and worker.tier >= 3 and slot.shift_type == 'Window':\n",
    "                penalty += 10\n",
    "                details['tier_mismatches'] += 1\n",
    "\n",
    "        # Hour constraints\n",
    "        for worker in self.workers:\n",
    "            hours = worker_hours[worker.worker_id]\n",
    "            if hours < self.MIN_HOURS_PER_WORKER:\n",
    "                penalty += (self.MIN_HOURS_PER_WORKER - hours) * 75\n",
    "                details['min_hour_violations'] += 1\n",
    "            if hours > self.MAX_HOURS_PER_WORKER:\n",
    "                penalty += (hours - self.MAX_HOURS_PER_WORKER) * 50\n",
    "                details['hour_violations'] += 1\n",
    "            if worker_morning[worker.worker_id] > 2:\n",
    "                penalty += (worker_morning[worker.worker_id] - 2) * 30\n",
    "                details['morning_shift_violations'] += 1\n",
    "\n",
    "        # Shift length constraints\n",
    "        for worker_id, assignments in worker_assignments.items():\n",
    "            if not assignments:\n",
    "                continue\n",
    "            day_hours = {}\n",
    "            for idx in assignments:\n",
    "                slot = self.shift_slots[idx]\n",
    "                if slot.day not in day_hours:\n",
    "                    day_hours[slot.day] = set()\n",
    "                day_hours[slot.day].add(slot.hour)\n",
    "            \n",
    "            for day, hours in day_hours.items():\n",
    "                sorted_hours = sorted(hours)\n",
    "                blocks = [[sorted_hours[0]]]\n",
    "                for h in sorted_hours[1:]:\n",
    "                    if h == blocks[-1][-1] + 1:\n",
    "                        blocks[-1].append(h)\n",
    "                    else:\n",
    "                        blocks.append([h])\n",
    "                for block in blocks:\n",
    "                    if len(block) < 2:\n",
    "                        penalty += 500\n",
    "                        details['shift_length_violations'] += 1\n",
    "                    elif len(block) > 6:\n",
    "                        penalty += (len(block) - 6) * 100\n",
    "                        details['shift_length_violations'] += 1\n",
    "\n",
    "        return penalty, details\n",
    "    \n",
    "    def batch_evaluate_gpu(self, population: List[np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        GPU-accelerated batch evaluation of multiple schedules.\n",
    "        Returns tensor of penalties for each schedule.\n",
    "        \"\"\"\n",
    "        batch_size = len(population)\n",
    "        \n",
    "        # Convert population to GPU tensor\n",
    "        # Shape: (batch_size, num_slots)\n",
    "        pop_np = np.array(population, dtype=np.int64)\n",
    "        pop_tensor = torch.tensor(pop_np, device=DEVICE, dtype=torch.int64)\n",
    "        \n",
    "        penalties = torch.zeros(batch_size, device=DEVICE)\n",
    "        \n",
    "        # 1. Coverage violations (vectorized)\n",
    "        for key, shifts in self.coverage_groups.items():\n",
    "            window_indices = torch.tensor(shifts['Window'], device=DEVICE, dtype=torch.int64)\n",
    "            remote_indices = torch.tensor(shifts['Remote'], device=DEVICE, dtype=torch.int64)\n",
    "            \n",
    "            # Count assigned workers per slot type\n",
    "            window_assigned = pop_tensor[:, window_indices]  # (batch, num_window_slots)\n",
    "            remote_assigned = pop_tensor[:, remote_indices]\n",
    "            \n",
    "            window_count = (window_assigned != -1).sum(dim=1).float()\n",
    "            remote_count = (remote_assigned != -1).sum(dim=1).float()\n",
    "            \n",
    "            # Penalty for under-coverage\n",
    "            penalties += torch.clamp(2 - window_count, min=0) * 100\n",
    "            penalties += torch.clamp(2 - remote_count, min=0) * 100\n",
    "        \n",
    "        # 2. Worker hour violations (need to count per worker)\n",
    "        # Create one-hot encoding of assignments\n",
    "        for b in range(batch_size):\n",
    "            schedule = pop_tensor[b]\n",
    "            worker_hours = torch.zeros(self.num_workers, device=DEVICE)\n",
    "            worker_morning = torch.zeros(self.num_workers, device=DEVICE)\n",
    "            \n",
    "            for s_idx in range(self.num_slots):\n",
    "                worker_id = schedule[s_idx].item()\n",
    "                if worker_id != -1 and worker_id in self.worker_id_to_idx:\n",
    "                    w_idx = self.worker_id_to_idx[worker_id]\n",
    "                    worker_hours[w_idx] += 1\n",
    "                    if self.slot_hours[s_idx] < 12:\n",
    "                        worker_morning[w_idx] += 1\n",
    "                    \n",
    "                    # Availability violation\n",
    "                    if self.availability_matrix[w_idx, s_idx] == 0:\n",
    "                        penalties[b] += 200\n",
    "                    \n",
    "                    # Tier mismatch\n",
    "                    if self.worker_tiers[w_idx] >= 3 and self.slot_is_window[s_idx] == 1:\n",
    "                        penalties[b] += 10\n",
    "            \n",
    "            # Min/max hour violations\n",
    "            under_hours = torch.clamp(self.MIN_HOURS_PER_WORKER - worker_hours, min=0)\n",
    "            over_hours = torch.clamp(worker_hours - self.MAX_HOURS_PER_WORKER, min=0)\n",
    "            penalties[b] += under_hours.sum() * 75\n",
    "            penalties[b] += over_hours.sum() * 50\n",
    "            \n",
    "            # Morning shift violations\n",
    "            over_morning = torch.clamp(worker_morning - 2, min=0)\n",
    "            penalties[b] += over_morning.sum() * 30\n",
    "        \n",
    "        return penalties\n",
    "    \n",
    "    def get_available_workers(self, day: int, hour: int) -> List[int]:\n",
    "        \"\"\"Get list of worker IDs available for a given day and hour\"\"\"\n",
    "        return [w.worker_id for w in self.workers if w.is_available(day, hour)]\n",
    "\n",
    "print(\"GPU-accelerated SchedulingEnvironment defined!\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: MongoDB Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoDBLoader:\n",
    "    \"\"\"Load scheduling data from MongoDB\"\"\"\n",
    "    \n",
    "    def __init__(self, connection_string: str = \"mongodb://localhost:27017/\", \n",
    "                 database: str = \"finals_scheduler\"):\n",
    "        self.client = MongoClient(connection_string)\n",
    "        self.db = self.client[database]\n",
    "        self.users_collection = self.db['Users']\n",
    "        self.finals_collection = self.db['Finals']\n",
    "    \n",
    "    def parse_tier(self, position: str) -> int:\n",
    "        \"\"\"Convert position string to tier number\"\"\"\n",
    "        tier_map = {'Tier 1': 1, 'Tier 2': 2, 'Tier 3': 3, 'Tier 4': 4}\n",
    "        return tier_map.get(position, 1)\n",
    "    \n",
    "    def get_day_from_date(self, date_str: str) -> tuple:\n",
    "        \"\"\"Convert date string to day of week\"\"\"\n",
    "        date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "        if date.year == 2024:\n",
    "            date = date.replace(year=2025)\n",
    "        return date.weekday(), date\n",
    "    \n",
    "    def parse_time(self, time_str: str) -> int:\n",
    "        \"\"\"Convert time string (HH:MM) to hour integer\"\"\"\n",
    "        hours, minutes = time_str.split(':')\n",
    "        hour = int(hours)\n",
    "        if int(minutes) >= 30:\n",
    "            return hour + 0.5\n",
    "        return hour\n",
    "    \n",
    "    def load_workers(self) -> List[Worker]:\n",
    "        \"\"\"Load all active workers from MongoDB\"\"\"\n",
    "        users = list(self.users_collection.find({'isActive': True}))\n",
    "        workers = []\n",
    "        \n",
    "        for user in users:\n",
    "            user_id = user['userId']\n",
    "            finals = list(self.finals_collection.find({'userId': str(user_id)}))\n",
    "            \n",
    "            busy_times = []\n",
    "            for final in finals:\n",
    "                day, date_obj = self.get_day_from_date(final['date'])\n",
    "                start_hour = self.parse_time(final['startTime'])\n",
    "                end_hour = self.parse_time(final['endTime'])\n",
    "\n",
    "                if day == 6:  # Skip Sunday\n",
    "                    continue\n",
    "                busy_times.append((day, int(start_hour), int(end_hour)))\n",
    "            \n",
    "            worker = Worker(\n",
    "                worker_id=user_id,\n",
    "                name=user['name'],\n",
    "                tier=self.parse_tier(user.get('position', 'Tier 1')),\n",
    "                is_commuter=user.get('isCommuter', False),\n",
    "                desired_hours=user.get('desiredHours', 15),\n",
    "                busy_times=busy_times\n",
    "            )\n",
    "            workers.append(worker)\n",
    "        \n",
    "        return workers\n",
    "    \n",
    "    def print_loaded_data(self, workers: List[Worker]):\n",
    "        \"\"\"Print summary of loaded data\"\"\"\n",
    "        day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"LOADED {len(workers)} WORKERS FROM MONGODB\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        for worker in workers:\n",
    "            print(f\"\\n{worker.name} (ID: {worker.worker_id})\")\n",
    "            print(f\"  Tier: {worker.tier}, Commuter: {'Yes' if worker.is_commuter else 'No'}\")\n",
    "            print(f\"  Desired Hours: {worker.desired_hours}, Busy Times: {len(worker.busy_times)}\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close MongoDB connection\"\"\"\n",
    "        self.client.close()\n",
    "\n",
    "print(\"MongoDB loader defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Load Data (Local Files, MongoDB, or JSON Export)\n",
    "\n",
    "**Data Source Options:**\n",
    "\n",
    "1. **`local_files`** (Default): Loads directly from `Users.json` and `Finals.json` in the Data directory\n",
    "   - Set `DATA_DIRECTORY` to the path containing your JSON files\n",
    "   - Default path is `../../Data` (relative to notebook location)\n",
    "\n",
    "2. **`json_export`**: Loads from a pre-exported `workers_data.json` file\n",
    "   - Run `export_workers_for_rosie.py` locally to create this file\n",
    "   - Useful for ROSIE where direct file access may be limited\n",
    "\n",
    "3. **`mongodb`**: Direct MongoDB connection\n",
    "   - Requires network access to MongoDB Atlas\n",
    "   - May have SSL/firewall issues on HPC clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHOOSE DATA SOURCE: \"mongodb\", \"json_export\", or \"local_files\"\n",
    "# ============================================================================\n",
    "DATA_SOURCE = \"local_files\"  # Change to \"mongodb\" or \"json_export\" if needed\n",
    "\n",
    "# MongoDB settings (only used if DATA_SOURCE = \"mongodb\")\n",
    "MONGODB_CONNECTION = \"mongodb+srv://vamsi123:d32rm2786@cluster1.lnpslid.mongodb.net/\"\n",
    "DATABASE_NAME = \"Scheduler\"\n",
    "\n",
    "# JSON export file settings (only used if DATA_SOURCE = \"json_export\")\n",
    "# Generate this file by running export_workers_for_rosie.py locally\n",
    "JSON_EXPORT_FILE = \"workers_data.json\"\n",
    "\n",
    "# Local files settings (only used if DATA_SOURCE = \"local_files\")\n",
    "# Path to the Data directory containing Users.json and Finals.json\n",
    "DATA_DIRECTORY = \"\"\n",
    "\n",
    "def parse_tier(position: str) -> int:\n",
    "    \"\"\"Convert position string to tier number\"\"\"\n",
    "    tier_map = {'Tier 1': 1, 'Tier 2': 2, 'Tier 3': 3, 'Tier 4': 4}\n",
    "    return tier_map.get(position, 1)\n",
    "\n",
    "def get_day_from_date(date_str: str) -> tuple:\n",
    "    \"\"\"Convert date string to day of week\"\"\"\n",
    "    date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "    if date.year == 2024:\n",
    "        date = date.replace(year=2025)\n",
    "    return date.weekday(), date\n",
    "\n",
    "def parse_time(time_str: str) -> int:\n",
    "    \"\"\"Convert time string (HH:MM) to hour integer\"\"\"\n",
    "    hours, minutes = time_str.split(':')\n",
    "    hour = int(hours)\n",
    "    if int(minutes) >= 30:\n",
    "        return hour + 0.5\n",
    "    return hour\n",
    "\n",
    "def load_workers_from_local_files(data_dir: str) -> List[Worker]:\n",
    "    \"\"\"Load workers from local Users.json and Finals.json files\"\"\"\n",
    "    users_path = os.path.join(data_dir, 'Users.json')\n",
    "    finals_path = os.path.join(data_dir, 'Finals.json')\n",
    "    \n",
    "    # Load Users.json\n",
    "    with open(users_path, 'r', encoding='utf-8') as f:\n",
    "        users = json.load(f)\n",
    "    \n",
    "    # Load Finals.json\n",
    "    with open(finals_path, 'r', encoding='utf-8') as f:\n",
    "        finals = json.load(f)\n",
    "    \n",
    "    # Create a mapping of userId to their finals (busy times)\n",
    "    finals_by_user = {}\n",
    "    for final in finals:\n",
    "        user_id = str(final['userId'])\n",
    "        if user_id not in finals_by_user:\n",
    "            finals_by_user[user_id] = []\n",
    "        finals_by_user[user_id].append(final)\n",
    "    \n",
    "    workers = []\n",
    "    for user in users:\n",
    "        # Skip inactive users\n",
    "        if not user.get('isActive', True):\n",
    "            continue\n",
    "        \n",
    "        user_id = user['userId']\n",
    "        user_finals = finals_by_user.get(str(user_id), [])\n",
    "        \n",
    "        busy_times = []\n",
    "        for final in user_finals:\n",
    "            day, date_obj = get_day_from_date(final['date'])\n",
    "            start_hour = parse_time(final['startTime'])\n",
    "            end_hour = parse_time(final['endTime'])\n",
    "            \n",
    "            if day == 6:  # Skip Sunday\n",
    "                continue\n",
    "            busy_times.append((day, int(start_hour), int(end_hour)))\n",
    "        \n",
    "        worker = Worker(\n",
    "            worker_id=user_id,\n",
    "            name=user['name'],\n",
    "            tier=parse_tier(user.get('position', 'Tier 1')),\n",
    "            is_commuter=user.get('isCommuter', False),\n",
    "            desired_hours=user.get('desiredHours', 15),\n",
    "            busy_times=busy_times\n",
    "        )\n",
    "        workers.append(worker)\n",
    "    \n",
    "    return workers\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "if DATA_SOURCE == \"local_files\":\n",
    "    print(f\"Loading workers from local files in: {DATA_DIRECTORY}\")\n",
    "    \n",
    "    workers = load_workers_from_local_files(DATA_DIRECTORY)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LOADED {len(workers)} ACTIVE WORKERS FROM LOCAL FILES\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for worker in workers:\n",
    "        print(f\"\\n{worker.name} (ID: {worker.worker_id})\")\n",
    "        print(f\"  Tier: {worker.tier}, Commuter: {'Yes' if worker.is_commuter else 'No'}\")\n",
    "        print(f\"  Desired Hours: {worker.desired_hours}, Busy Times: {len(worker.busy_times)}\")\n",
    "\n",
    "elif DATA_SOURCE == \"json_export\":\n",
    "    print(f\"Loading workers from exported JSON file: {JSON_EXPORT_FILE}\")\n",
    "    \n",
    "    with open(JSON_EXPORT_FILE, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    workers = []\n",
    "    for w in data['workers']:\n",
    "        worker = Worker(\n",
    "            worker_id=w['worker_id'],\n",
    "            name=w['name'],\n",
    "            tier=w['tier'],\n",
    "            is_commuter=w['is_commuter'],\n",
    "            desired_hours=w['desired_hours'],\n",
    "            busy_times=[tuple(bt) for bt in w['busy_times']]\n",
    "        )\n",
    "        workers.append(worker)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LOADED {len(workers)} WORKERS FROM JSON EXPORT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Exported at: {data.get('exported_at', 'Unknown')}\")\n",
    "    \n",
    "    for worker in workers:\n",
    "        print(f\"\\n{worker.name} (ID: {worker.worker_id})\")\n",
    "        print(f\"  Tier: {worker.tier}, Commuter: {'Yes' if worker.is_commuter else 'No'}\")\n",
    "        print(f\"  Desired Hours: {worker.desired_hours}, Busy Times: {len(worker.busy_times)}\")\n",
    "\n",
    "elif DATA_SOURCE == \"mongodb\":\n",
    "    print(\"Connecting to MongoDB...\")\n",
    "    loader = MongoDBLoader(MONGODB_CONNECTION, DATABASE_NAME)\n",
    "    workers = loader.load_workers()\n",
    "    loader.print_loaded_data(workers)\n",
    "    loader.close()\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Invalid DATA_SOURCE: {DATA_SOURCE}. Use 'mongodb', 'json_export', or 'local_files'\")\n",
    "\n",
    "# Create scheduling environment\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CREATING SCHEDULING ENVIRONMENT\")\n",
    "print(f\"{'='*60}\")\n",
    "env = SchedulingEnvironment(workers, schedule_type='finals')\n",
    "print(f\"Total shift slots: {env.num_slots}\")\n",
    "print(f\"Number of workers: {len(env.workers)}\")\n",
    "print(f\"Schedule type: {env.schedule_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Extended Hyperparameter Configuration for ROSIE\n",
    "\n",
    "These parameters are significantly extended compared to local execution.\n",
    "Adjust based on your compute time allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ROSIE HYPERPARAMETER CONFIGURATION - Extended for ~2 Hour Runs\n",
    "# ============================================================================\n",
    "\n",
    "COMPUTE_PROFILE = \"rosie_2hr\"  # Options: \"quick\", \"standard\", \"rosie_2hr\"\n",
    "\n",
    "PROFILES = {\n",
    "    \"quick\": {  # ~15-30 minutes total\n",
    "        \"GA\": {\n",
    "            \"population_size\": 200,\n",
    "            \"generations\": 5000,\n",
    "            \"crossover_rate\": 0.85,\n",
    "            \"mutation_rate\": 0.35,\n",
    "            \"elitism_count\": 10,\n",
    "            \"max_time\": 600.0,  # 10 min max\n",
    "            \"batch_size\": 200\n",
    "        },\n",
    "        \"SA\": {\n",
    "            \"initial_temp\": 5000.0,\n",
    "            \"final_temp\": 0.1,\n",
    "            \"cooling_rate\": 0.9995,\n",
    "            \"iterations_per_temp\": 150,\n",
    "            \"max_iterations\": 100000,\n",
    "            \"max_time\": 600.0,  # 10 min max\n",
    "            \"max_reheats\": 10\n",
    "        },\n",
    "        \"CSP\": {\n",
    "            \"max_time\": 600.0,  # 10 min max\n",
    "            \"local_search_iterations\": 100000,\n",
    "            \"num_restarts\": 5,\n",
    "            \"batch_size\": 200\n",
    "        }\n",
    "    },\n",
    "    \"standard\": {  # ~30-60 minutes total\n",
    "        \"GA\": {\n",
    "            \"population_size\": 400,\n",
    "            \"generations\": 15000,\n",
    "            \"crossover_rate\": 0.87,\n",
    "            \"mutation_rate\": 0.40,\n",
    "            \"elitism_count\": 20,\n",
    "            \"max_time\": 1800.0,  # 30 min max\n",
    "            \"batch_size\": 400\n",
    "        },\n",
    "        \"SA\": {\n",
    "            \"initial_temp\": 8000.0,\n",
    "            \"final_temp\": 0.01,\n",
    "            \"cooling_rate\": 0.99985,\n",
    "            \"iterations_per_temp\": 200,\n",
    "            \"max_iterations\": 300000,\n",
    "            \"max_time\": 1800.0,  # 30 min max\n",
    "            \"max_reheats\": 20\n",
    "        },\n",
    "        \"CSP\": {\n",
    "            \"max_time\": 1800.0,  # 30 min max\n",
    "            \"local_search_iterations\": 300000,\n",
    "            \"num_restarts\": 10,\n",
    "            \"batch_size\": 200\n",
    "        }\n",
    "    },\n",
    "    \"rosie_2hr\": {  # ~2 hours per algorithm - RECOMMENDED FOR ROSIE\n",
    "        \"GA\": {\n",
    "            \"population_size\": 800,\n",
    "            \"generations\": 50000,          # Large generation count\n",
    "            \"crossover_rate\": 0.88,\n",
    "            \"mutation_rate\": 0.42,\n",
    "            \"elitism_count\": 40,\n",
    "            \"max_time\": 7200.0,            # 2 hour hard limit\n",
    "            \"checkpoint_interval\": 300,     # Checkpoint every 5 min\n",
    "            \"batch_size\": 800\n",
    "        },\n",
    "        \"SA\": {\n",
    "            # Properly tuned cooling schedule for 2 hours:\n",
    "            # With cooling_rate=0.999995 and iterations_per_temp=300,\n",
    "            # temp goes from 10000 to 0.01 in ~3M iterations\n",
    "            # At ~2000 iter/sec, that's ~25 min of cooling cycles\n",
    "            # Plus reheats extends to full 2 hours\n",
    "            \"initial_temp\": 10000.0,\n",
    "            \"final_temp\": 0.01,\n",
    "            \"cooling_rate\": 0.999995,      # Very slow cooling\n",
    "            \"iterations_per_temp\": 300,\n",
    "            \"max_iterations\": 15000000,    # 15M iterations max\n",
    "            \"max_time\": 7200.0,            # 2 hour hard limit\n",
    "            \"max_reheats\": 50,             # Allow many reheats\n",
    "            \"checkpoint_interval\": 300     # Checkpoint every 5 min\n",
    "        },\n",
    "        \"CSP\": {\n",
    "            \"max_time\": 7200.0,            # 2 hour hard limit\n",
    "            \"local_search_iterations\": 5000000,  # 5M iterations\n",
    "            \"num_restarts\": 30,            # Many restarts for diversity\n",
    "            \"checkpoint_interval\": 300,     # Checkpoint every 5 min\n",
    "            \"batch_size\": 500\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select active configuration\n",
    "GA_CONFIG = PROFILES[COMPUTE_PROFILE][\"GA\"]\n",
    "SA_CONFIG = PROFILES[COMPUTE_PROFILE][\"SA\"]\n",
    "CSP_CONFIG = PROFILES[COMPUTE_PROFILE][\"CSP\"]\n",
    "\n",
    "# Checkpointing settings\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "ENABLE_CHECKPOINTING = True\n",
    "\n",
    "# Create checkpoint directory\n",
    "import os\n",
    "if ENABLE_CHECKPOINTING and not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"PROFILE: {COMPUTE_PROFILE.upper()}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\n",
    "Genetic Algorithm:\")\n",
    "print(f\"  Population: {GA_CONFIG['population_size']}, Generations: {GA_CONFIG['generations']}\")\n",
    "print(f\"  Max time: {GA_CONFIG['max_time']/3600:.1f} hours\")\n",
    "print(f\"\n",
    "Simulated Annealing:\")\n",
    "print(f\"  Initial temp: {SA_CONFIG['initial_temp']}, Cooling rate: {SA_CONFIG['cooling_rate']}\")\n",
    "print(f\"  Max iterations: {SA_CONFIG['max_iterations']:,}, Max time: {SA_CONFIG['max_time']/3600:.1f} hours\")\n",
    "print(f\"  Max reheats: {SA_CONFIG['max_reheats']}\")\n",
    "print(f\"\n",
    "CSP Solver:\")\n",
    "print(f\"  Max time: {CSP_CONFIG['max_time']/3600:.1f} hours\")\n",
    "print(f\"  Local search iterations: {CSP_CONFIG['local_search_iterations']:,}\")\n",
    "print(f\"  Num restarts: {CSP_CONFIG['num_restarts']}\")\n",
    "print(f\"\n",
    "Checkpointing: {'ENABLED' if ENABLE_CHECKPOINTING else 'DISABLED'}\")\n",
    "print(f\"\n",
    "Expected runtime: ~2 hours (parallel) or ~6 hours (sequential)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Enhanced Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "    \"\"\"GPU-accelerated Genetic Algorithm with batch fitness evaluation\"\"\"\n",
    "\n",
    "    def __init__(self, environment: SchedulingEnvironment,\n",
    "                 population_size: int = 500,\n",
    "                 generations: int = 10000,\n",
    "                 crossover_rate: float = 0.85,\n",
    "                 mutation_rate: float = 0.40,\n",
    "                 elitism_count: int = 25,\n",
    "                 batch_size: int = 500,\n",
    "                 adaptive_mutation: bool = True,\n",
    "                 max_time: float = 7200.0,\n",
    "                 checkpoint_interval: float = 300.0,\n",
    "                 checkpoint_dir: str = \"checkpoints\"):\n",
    "        \n",
    "        self.env = environment\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.base_mutation_rate = mutation_rate\n",
    "        self.elitism_count = elitism_count\n",
    "        self.batch_size = batch_size\n",
    "        self.adaptive_mutation = adaptive_mutation\n",
    "        self.max_time = max_time\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.checkpoint_history = []  # For graphing\n",
    "        \n",
    "        self.chromosome_length = self.env.num_slots\n",
    "        self.worker_ids = [w.worker_id for w in self.env.workers]\n",
    "        \n",
    "        # Pre-build worker lookup for O(1) access\n",
    "        self.worker_lookup = {w.worker_id: w for w in self.env.workers}\n",
    "        \n",
    "        self.best_solution = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.fitness_history = []\n",
    "        self.stagnation_counter = 0\n",
    "        \n",
    "    def initialize_population(self) -> List[np.ndarray]:\n",
    "        \"\"\"Create diverse initial population\"\"\"\n",
    "        population = []\n",
    "        min_hours = self.env.MIN_HOURS_PER_WORKER\n",
    "        min_shift, max_shift = 2, 6\n",
    "\n",
    "        for pop_idx in range(self.population_size):\n",
    "            chromosome = np.full(self.chromosome_length, -1, dtype=int)\n",
    "            worker_hours = {w.worker_id: 0 for w in self.env.workers}\n",
    "\n",
    "            slot_groups = {}\n",
    "            for i, slot in enumerate(self.env.shift_slots):\n",
    "                key = (slot.day, slot.shift_type)\n",
    "                if key not in slot_groups:\n",
    "                    slot_groups[key] = []\n",
    "                slot_groups[key].append((i, slot.hour))\n",
    "\n",
    "            for key in slot_groups:\n",
    "                slot_groups[key].sort(key=lambda x: x[1])\n",
    "\n",
    "            keys = list(slot_groups.keys())\n",
    "            random.shuffle(keys)\n",
    "\n",
    "            for key in keys:\n",
    "                slots = slot_groups[key]\n",
    "                day, shift_type = key\n",
    "                i = 0\n",
    "                while i < len(slots):\n",
    "                    slot_idx, hour = slots[i]\n",
    "                    available = self.env.get_available_workers(day, hour)\n",
    "                    if not available:\n",
    "                        i += 1\n",
    "                        continue\n",
    "\n",
    "                    if pop_idx % 3 == 0:\n",
    "                        under_min = [w for w in available if worker_hours[w] < min_hours]\n",
    "                        candidates = under_min if under_min else available\n",
    "                    elif pop_idx % 3 == 1:\n",
    "                        candidates = available\n",
    "                    else:\n",
    "                        candidates = sorted(available, key=lambda w: worker_hours[w])[:max(1, len(available)//2)]\n",
    "\n",
    "                    chosen = random.choice(candidates)\n",
    "                    block_length = random.randint(min_shift, max_shift)\n",
    "\n",
    "                    assigned = 0\n",
    "                    for j in range(i, min(i + block_length, len(slots))):\n",
    "                        next_idx, next_hour = slots[j]\n",
    "                        if next_hour == hour + (j - i):\n",
    "                            worker = self.worker_lookup.get(chosen)\n",
    "                            if worker and worker.is_available(day, next_hour):\n",
    "                                chromosome[next_idx] = chosen\n",
    "                                assigned += 1\n",
    "                            else:\n",
    "                                break\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    if assigned > 0:\n",
    "                        worker_hours[chosen] += assigned\n",
    "                    i += max(1, assigned)\n",
    "\n",
    "            population.append(chromosome)\n",
    "        return population\n",
    "    \n",
    "    def batch_fitness_gpu(self, population: List[np.ndarray]) -> List[float]:\n",
    "        \"\"\"GPU-accelerated batch fitness evaluation\"\"\"\n",
    "        if USE_GPU and len(population) >= 10:\n",
    "            penalties = self.env.batch_evaluate_gpu(population)\n",
    "            return penalties.cpu().numpy().tolist()\n",
    "        else:\n",
    "            return [self.env.evaluate_schedule(ind)[0] for ind in population]\n",
    "    \n",
    "    def select_parents(self, population: List[np.ndarray], \n",
    "                      fitnesses: List[float]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Tournament selection\"\"\"\n",
    "        tournament_size = 3 if self.stagnation_counter < 100 else 5\n",
    "        \n",
    "        def tournament_select(k):\n",
    "            indices = random.sample(range(len(population)), k)\n",
    "            best_idx = min(indices, key=lambda i: fitnesses[i])\n",
    "            return population[best_idx].copy()\n",
    "        \n",
    "        return tournament_select(tournament_size), tournament_select(tournament_size)\n",
    "    \n",
    "    def crossover(self, parent1: np.ndarray, parent2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Multi-point crossover\"\"\"\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "        \n",
    "        num_points = random.randint(2, 4)\n",
    "        points = sorted(random.sample(range(1, self.chromosome_length), num_points))\n",
    "        points = [0] + points + [self.chromosome_length]\n",
    "        \n",
    "        offspring1 = np.empty(self.chromosome_length, dtype=int)\n",
    "        offspring2 = np.empty(self.chromosome_length, dtype=int)\n",
    "        \n",
    "        for i in range(len(points) - 1):\n",
    "            start, end = points[i], points[i+1]\n",
    "            if i % 2 == 0:\n",
    "                offspring1[start:end] = parent1[start:end]\n",
    "                offspring2[start:end] = parent2[start:end]\n",
    "            else:\n",
    "                offspring1[start:end] = parent2[start:end]\n",
    "                offspring2[start:end] = parent1[start:end]\n",
    "        \n",
    "        return offspring1, offspring2\n",
    "    \n",
    "    def mutate(self, chromosome: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Mutation with multiple strategies\"\"\"\n",
    "        if random.random() > self.mutation_rate:\n",
    "            return chromosome\n",
    "\n",
    "        min_shift, max_shift = 2, 6\n",
    "        min_hours = self.env.MIN_HOURS_PER_WORKER\n",
    "        mutation_types = ['extend_block', 'swap_blocks', 'fill_gap', 'reassign']\n",
    "        if self.stagnation_counter > 50:\n",
    "            mutation_types.append('shuffle_day')\n",
    "        \n",
    "        mutation_type = random.choice(mutation_types)\n",
    "\n",
    "        if mutation_type == 'extend_block':\n",
    "            assigned = [i for i, w in enumerate(chromosome) if w != -1]\n",
    "            if assigned:\n",
    "                idx = random.choice(assigned)\n",
    "                slot = self.env.shift_slots[idx]\n",
    "                worker_id = chromosome[idx]\n",
    "                for i, s in enumerate(self.env.shift_slots):\n",
    "                    if (s.day == slot.day and s.shift_type == slot.shift_type and\n",
    "                        abs(s.hour - slot.hour) == 1 and chromosome[i] == -1):\n",
    "                        worker = self.worker_lookup.get(worker_id)\n",
    "                        if worker and worker.is_available(s.day, s.hour):\n",
    "                            hours = sum(1 for w in chromosome if w == worker_id)\n",
    "                            if hours < 20:\n",
    "                                chromosome[i] = worker_id\n",
    "                                break\n",
    "\n",
    "        elif mutation_type == 'swap_blocks':\n",
    "            assigned = [i for i, w in enumerate(chromosome) if w != -1]\n",
    "            if len(assigned) >= 2:\n",
    "                idx1, idx2 = random.sample(assigned, 2)\n",
    "                slot1, slot2 = self.env.shift_slots[idx1], self.env.shift_slots[idx2]\n",
    "                w1, w2 = chromosome[idx1], chromosome[idx2]\n",
    "                worker1 = self.worker_lookup.get(w1)\n",
    "                worker2 = self.worker_lookup.get(w2)\n",
    "                if (worker1 and worker2 and\n",
    "                    worker1.is_available(slot2.day, slot2.hour) and\n",
    "                    worker2.is_available(slot1.day, slot1.hour)):\n",
    "                    chromosome[idx1], chromosome[idx2] = w2, w1\n",
    "\n",
    "        elif mutation_type == 'fill_gap':\n",
    "            empty = [i for i, w in enumerate(chromosome) if w == -1]\n",
    "            if empty:\n",
    "                idx = random.choice(empty)\n",
    "                slot = self.env.shift_slots[idx]\n",
    "                available = self.env.get_available_workers(slot.day, slot.hour)\n",
    "                if available:\n",
    "                    worker_hours = {w.worker_id: sum(1 for x in chromosome if x == w.worker_id)\n",
    "                                   for w in self.env.workers}\n",
    "                    under_min = [w for w in available if worker_hours.get(w, 0) < min_hours]\n",
    "                    chosen = random.choice(under_min) if under_min else random.choice(available)\n",
    "                    block_size = random.randint(min_shift, 4)\n",
    "                    for i, s in enumerate(self.env.shift_slots):\n",
    "                        if (s.day == slot.day and s.shift_type == slot.shift_type and\n",
    "                            slot.hour <= s.hour < slot.hour + block_size and chromosome[i] == -1):\n",
    "                            worker = self.worker_lookup.get(chosen)\n",
    "                            if worker and worker.is_available(s.day, s.hour):\n",
    "                                hours = sum(1 for w in chromosome if w == chosen)\n",
    "                                if hours < 20:\n",
    "                                    chromosome[i] = chosen\n",
    "\n",
    "        elif mutation_type == 'reassign':\n",
    "            idx = random.randint(0, self.chromosome_length - 1)\n",
    "            slot = self.env.shift_slots[idx]\n",
    "            available = self.env.get_available_workers(slot.day, slot.hour)\n",
    "            if available:\n",
    "                current = chromosome[idx]\n",
    "                if current in available and len(available) > 1:\n",
    "                    available = [w for w in available if w != current]\n",
    "                chromosome[idx] = random.choice(available)\n",
    "                \n",
    "        elif mutation_type == 'shuffle_day':\n",
    "            day = random.randint(0, 5)\n",
    "            day_slots = [(i, slot) for i, slot in enumerate(self.env.shift_slots) if slot.day == day]\n",
    "            if day_slots:\n",
    "                assignments = [(i, chromosome[i]) for i, _ in day_slots if chromosome[i] != -1]\n",
    "                if len(assignments) >= 2:\n",
    "                    random.shuffle(assignments)\n",
    "                    orig_slots = [(i, chromosome[i]) for i, _ in day_slots if chromosome[i] != -1]\n",
    "                    for (orig_idx, _), (_, new_worker) in zip(orig_slots, assignments):\n",
    "                        slot = self.env.shift_slots[orig_idx]\n",
    "                        worker = next((w for w in self.env.workers if w.worker_id == new_worker), None)\n",
    "                        if worker and worker.is_available(slot.day, slot.hour):\n",
    "                            chromosome[orig_idx] = new_worker\n",
    "\n",
    "        return chromosome\n",
    "    \n",
    "    def repair_chromosome(self, chromosome: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Repair chromosome to fix availability violations\"\"\"\n",
    "        for i, worker_id in enumerate(chromosome):\n",
    "            if worker_id == -1:\n",
    "                continue\n",
    "            slot = self.env.shift_slots[i]\n",
    "            worker = self.worker_lookup.get(worker_id)\n",
    "            if worker and not worker.is_available(slot.day, slot.hour):\n",
    "                available = self.env.get_available_workers(slot.day, slot.hour)\n",
    "                chromosome[i] = random.choice(available) if available else -1\n",
    "        return chromosome\n",
    "    \n",
    "    def save_checkpoint(self, generation: int, elapsed: float):\n",
    "        \"\"\"Save checkpoint to file\"\"\"\n",
    "        if not self.checkpoint_dir:\n",
    "            return\n",
    "        \n",
    "        checkpoint = {\n",
    "            'algorithm': 'GA',\n",
    "            'generation': generation,\n",
    "            'elapsed_seconds': elapsed,\n",
    "            'elapsed_minutes': elapsed / 60,\n",
    "            'best_fitness': self.best_fitness,\n",
    "            'population_size': self.population_size,\n",
    "            'mutation_rate': self.mutation_rate,\n",
    "            'stagnation_counter': self.stagnation_counter,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        self.checkpoint_history.append(checkpoint)\n",
    "        \n",
    "        try:\n",
    "            filename = os.path.join(self.checkpoint_dir, f'ga_checkpoint_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json')\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump({\n",
    "                    'checkpoint': checkpoint,\n",
    "                    'fitness_history_sample': self.fitness_history[::100] if len(self.fitness_history) > 100 else self.fitness_history\n",
    "                }, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not save GA checkpoint: {e}\")\n",
    "\n",
    "    def solve(self, verbose: bool = True) -> Tuple[np.ndarray, float, List[float]]:\n",
    "        \"\"\"Run GA with GPU-accelerated batch fitness evaluation\"\"\"\n",
    "        start_time = time.time()\n",
    "        population = self.initialize_population()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"GA initialized: pop={self.population_size}, gens={self.generations}\")\n",
    "            print(f\"GPU batch evaluation: {'ENABLED' if USE_GPU else 'DISABLED'}\")\n",
    "        \n",
    "        last_checkpoint_time = start_time\n",
    "        \n",
    "        for generation in range(self.generations):\n",
    "            # Check time limit\n",
    "            elapsed = time.time() - start_time\n",
    "            if elapsed >= self.max_time:\n",
    "                if verbose:\n",
    "                    print(f\"\n",
    "  STOPPING: Max time ({self.max_time/60:.0f} min) reached at gen {generation}\")\n",
    "                break\n",
    "            \n",
    "            # Save checkpoint every checkpoint_interval seconds\n",
    "            if elapsed - (last_checkpoint_time - start_time) >= self.checkpoint_interval:\n",
    "                if self.checkpoint_dir:\n",
    "                    self.save_checkpoint(generation, elapsed)\n",
    "                    if verbose:\n",
    "                        print(f\"  [GA Checkpoint saved at {elapsed/60:.1f} min]\")\n",
    "                last_checkpoint_time = time.time()\n",
    "            \n",
    "            # GPU batch fitness evaluation\n",
    "            fitnesses = self.batch_fitness_gpu(population)\n",
    "            \n",
    "            min_fitness_idx = np.argmin(fitnesses)\n",
    "            current_best = fitnesses[min_fitness_idx]\n",
    "            \n",
    "            if current_best < self.best_fitness:\n",
    "                self.best_fitness = current_best\n",
    "                self.best_solution = population[min_fitness_idx].copy()\n",
    "                self.stagnation_counter = 0\n",
    "            else:\n",
    "                self.stagnation_counter += 1\n",
    "            \n",
    "            self.fitness_history.append(self.best_fitness)\n",
    "            \n",
    "            # Adaptive mutation\n",
    "            if self.adaptive_mutation:\n",
    "                if self.stagnation_counter > 100:\n",
    "                    self.mutation_rate = min(0.8, self.base_mutation_rate * 2)\n",
    "                elif self.stagnation_counter > 50:\n",
    "                    self.mutation_rate = min(0.6, self.base_mutation_rate * 1.5)\n",
    "                else:\n",
    "                    self.mutation_rate = self.base_mutation_rate\n",
    "            \n",
    "            if verbose and generation % 500 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                gens_per_sec = generation / elapsed if elapsed > 0 else 0\n",
    "                eta = (self.generations - generation) / gens_per_sec if gens_per_sec > 0 else 0\n",
    "                print(f\"Gen {generation}: Best={self.best_fitness:.1f}, \"\n",
    "                      f\"Avg={np.mean(fitnesses):.1f}, Rate={gens_per_sec:.1f} gen/s, \"\n",
    "                      f\"ETA={eta/60:.1f}min\")\n",
    "            \n",
    "            if self.best_fitness == 0:\n",
    "                if verbose:\n",
    "                    print(f\"Perfect solution at generation {generation}!\")\n",
    "                break\n",
    "            \n",
    "            # Create new population\n",
    "            new_population = []\n",
    "            elite_indices = np.argsort(fitnesses)[:self.elitism_count]\n",
    "            for idx in elite_indices:\n",
    "                new_population.append(population[idx].copy())\n",
    "            \n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = self.select_parents(population, fitnesses)\n",
    "                offspring1, offspring2 = self.crossover(parent1, parent2)\n",
    "                offspring1 = self.repair_chromosome(self.mutate(offspring1))\n",
    "                offspring2 = self.repair_chromosome(self.mutate(offspring2))\n",
    "                new_population.append(offspring1)\n",
    "                if len(new_population) < self.population_size:\n",
    "                    new_population.append(offspring2)\n",
    "            \n",
    "            population = new_population\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        if verbose:\n",
    "            print(f\"\\nGA completed in {total_time:.1f}s ({total_time/60:.1f} min)\")\n",
    "            print(f\"Best fitness: {self.best_fitness:.2f}\")\n",
    "            _, details = self.env.evaluate_schedule(self.best_solution)\n",
    "            print(f\"Violations: {details}\")\n",
    "        \n",
    "        return self.best_solution, self.best_fitness, self.fitness_history\n",
    "\n",
    "print(\"GPU-accelerated Genetic Algorithm defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Enhanced Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedAnnealing:\n",
    "    \"\"\"\n",
    "    Simulated Annealing with properly tuned cooling schedule and checkpointing.\n",
    "\n",
    "    Cooling Schedule Math:\n",
    "    - With cooling_rate=0.999995 and initial_temp=10000, final_temp=0.01:\n",
    "    - Number of cooling steps: log(0.01/10000) / log(0.999995) ~ 2.76M\n",
    "    - At iterations_per_temp=300, total iterations from cooling ~ 830M\n",
    "    - But we use max_iterations and max_time as hard limits\n",
    "    - Reheats provide escape from local minima\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, environment,\n",
    "                 initial_temp: float = 10000.0,\n",
    "                 final_temp: float = 0.01,\n",
    "                 cooling_rate: float = 0.999995,\n",
    "                 iterations_per_temp: int = 300,\n",
    "                 max_iterations: int = 15000000,\n",
    "                 max_time: float = 7200.0,\n",
    "                 max_reheats: int = 50,\n",
    "                 checkpoint_interval: float = 300.0,\n",
    "                 checkpoint_dir: str = \"checkpoints\"):\n",
    "\n",
    "        self.env = environment\n",
    "        self.initial_temp = initial_temp\n",
    "        self.final_temp = final_temp\n",
    "        self.cooling_rate = cooling_rate\n",
    "        self.iterations_per_temp = iterations_per_temp\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_time = max_time\n",
    "        self.max_reheats = max_reheats\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "\n",
    "        self.worker_ids = [w.worker_id for w in self.env.workers]\n",
    "        self.best_solution = None\n",
    "        self.best_cost = float('inf')\n",
    "        self.cost_history = []\n",
    "        self.checkpoint_history = []  # Store periodic snapshots for graphing\n",
    "\n",
    "    def generate_initial_solution(self) -> np.ndarray:\n",
    "        \"\"\"Generate initial feasible solution\"\"\"\n",
    "        solution = np.full(self.env.num_slots, -1, dtype=int)\n",
    "        worker_hours = {w.worker_id: 0 for w in self.env.workers}\n",
    "        min_hours = self.env.MIN_HOURS_PER_WORKER\n",
    "        min_shift, max_shift = 2, 6\n",
    "\n",
    "        slot_groups = {}\n",
    "        for i, slot in enumerate(self.env.shift_slots):\n",
    "            key = (slot.day, slot.shift_type)\n",
    "            if key not in slot_groups:\n",
    "                slot_groups[key] = []\n",
    "            slot_groups[key].append((i, slot.hour))\n",
    "\n",
    "        for key in slot_groups:\n",
    "            slot_groups[key].sort(key=lambda x: x[1])\n",
    "\n",
    "        for key in slot_groups:\n",
    "            slots = slot_groups[key]\n",
    "            day, _ = key\n",
    "            i = 0\n",
    "            while i < len(slots):\n",
    "                slot_idx, hour = slots[i]\n",
    "                available = self.env.get_available_workers(day, hour)\n",
    "                if not available:\n",
    "                    i += 1\n",
    "                    continue\n",
    "\n",
    "                available_sorted = sorted(available,\n",
    "                    key=lambda w: (0 if worker_hours[w] < min_hours else 1, worker_hours[w]))\n",
    "                chosen = available_sorted[0]\n",
    "                block_length = random.randint(min_shift, max_shift)\n",
    "\n",
    "                assigned = 0\n",
    "                for j in range(i, min(i + block_length, len(slots))):\n",
    "                    next_idx, next_hour = slots[j]\n",
    "                    if next_hour == hour + (j - i):\n",
    "                        worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n",
    "                        if worker and worker.is_available(day, next_hour):\n",
    "                            solution[next_idx] = chosen\n",
    "                            assigned += 1\n",
    "                        else:\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                if assigned > 0:\n",
    "                    worker_hours[chosen] += assigned\n",
    "                i += max(1, assigned)\n",
    "\n",
    "        return solution\n",
    "\n",
    "    def generate_neighbor(self, solution: np.ndarray, temperature: float) -> np.ndarray:\n",
    "        \"\"\"Generate neighbor solution with temperature-adaptive moves\"\"\"\n",
    "        neighbor = solution.copy()\n",
    "        min_shift, max_shift = 2, 6\n",
    "        temp_ratio = temperature / self.initial_temp\n",
    "\n",
    "        # More aggressive moves at higher temps, refined moves at lower temps\n",
    "        if temp_ratio > 0.7:\n",
    "            strategies = ['swap_blocks', 'extend_block', 'shrink_block', 'reassign_block', 'fill_block', 'shuffle_day']\n",
    "        elif temp_ratio > 0.3:\n",
    "            strategies = ['swap_blocks', 'extend_block', 'reassign_block', 'fill_block']\n",
    "        else:\n",
    "            strategies = ['swap_blocks', 'extend_block', 'fill_block', 'fine_tune']\n",
    "\n",
    "        strategy = random.choice(strategies)\n",
    "\n",
    "        if strategy == 'swap_blocks':\n",
    "            assigned = [i for i, w in enumerate(solution) if w != -1]\n",
    "            if len(assigned) >= 2:\n",
    "                idx1, idx2 = random.sample(assigned, 2)\n",
    "                slot1, slot2 = self.env.shift_slots[idx1], self.env.shift_slots[idx2]\n",
    "                w1, w2 = neighbor[idx1], neighbor[idx2]\n",
    "                worker1 = next((w for w in self.env.workers if w.worker_id == w1), None)\n",
    "                worker2 = next((w for w in self.env.workers if w.worker_id == w2), None)\n",
    "                if (worker1 and worker2 and\n",
    "                    worker1.is_available(slot2.day, slot2.hour) and\n",
    "                    worker2.is_available(slot1.day, slot1.hour)):\n",
    "                    neighbor[idx1], neighbor[idx2] = w2, w1\n",
    "\n",
    "        elif strategy == 'extend_block':\n",
    "            assigned = [i for i, w in enumerate(solution) if w != -1]\n",
    "            if assigned:\n",
    "                idx = random.choice(assigned)\n",
    "                slot = self.env.shift_slots[idx]\n",
    "                worker_id = neighbor[idx]\n",
    "                for i, s in enumerate(self.env.shift_slots):\n",
    "                    if (s.day == slot.day and s.shift_type == slot.shift_type and\n",
    "                        abs(s.hour - slot.hour) == 1 and neighbor[i] == -1):\n",
    "                        worker = next((w for w in self.env.workers if w.worker_id == worker_id), None)\n",
    "                        if worker and worker.is_available(s.day, s.hour):\n",
    "                            hours = sum(1 for x in neighbor if x == worker_id)\n",
    "                            if hours < 20:\n",
    "                                neighbor[i] = worker_id\n",
    "                                break\n",
    "\n",
    "        elif strategy == 'shrink_block':\n",
    "            assigned = [i for i, w in enumerate(solution) if w != -1]\n",
    "            if assigned:\n",
    "                idx = random.choice(assigned)\n",
    "                slot = self.env.shift_slots[idx]\n",
    "                worker_id = neighbor[idx]\n",
    "                block_size = sum(1 for i, s in enumerate(self.env.shift_slots)\n",
    "                               if s.day == slot.day and s.shift_type == slot.shift_type\n",
    "                               and neighbor[i] == worker_id)\n",
    "                if block_size > min_shift:\n",
    "                    neighbor[idx] = -1\n",
    "\n",
    "        elif strategy == 'reassign_block':\n",
    "            idx = random.randint(0, len(solution) - 1)\n",
    "            slot = self.env.shift_slots[idx]\n",
    "            available = self.env.get_available_workers(slot.day, slot.hour)\n",
    "            if available:\n",
    "                current = neighbor[idx]\n",
    "                if current in available and len(available) > 1:\n",
    "                    available = [w for w in available if w != current]\n",
    "                neighbor[idx] = random.choice(available)\n",
    "            else:\n",
    "                neighbor[idx] = -1\n",
    "\n",
    "        elif strategy == 'fill_block':\n",
    "            empty = [i for i, w in enumerate(solution) if w == -1]\n",
    "            if empty:\n",
    "                idx = random.choice(empty)\n",
    "                slot = self.env.shift_slots[idx]\n",
    "                available = self.env.get_available_workers(slot.day, slot.hour)\n",
    "                if available:\n",
    "                    worker_hours = {w.worker_id: sum(1 for x in neighbor if x == w.worker_id)\n",
    "                                   for w in self.env.workers}\n",
    "                    under_min = [w for w in available if worker_hours.get(w, 0) < 14]\n",
    "                    chosen = random.choice(under_min) if under_min else random.choice(available)\n",
    "                    block_length = random.randint(min_shift, max_shift)\n",
    "                    for i, s in enumerate(self.env.shift_slots):\n",
    "                        if (s.day == slot.day and s.shift_type == slot.shift_type and\n",
    "                            slot.hour <= s.hour < slot.hour + block_length and neighbor[i] == -1):\n",
    "                            worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n",
    "                            if worker and worker.is_available(s.day, s.hour):\n",
    "                                hours = sum(1 for x in neighbor if x == chosen)\n",
    "                                if hours < 20:\n",
    "                                    neighbor[i] = chosen\n",
    "\n",
    "        elif strategy == 'shuffle_day':\n",
    "            day = random.randint(0, 5)\n",
    "            day_indices = [i for i, slot in enumerate(self.env.shift_slots)\n",
    "                          if slot.day == day and neighbor[i] != -1]\n",
    "            if len(day_indices) >= 2:\n",
    "                idx1, idx2 = random.sample(day_indices, 2)\n",
    "                slot1, slot2 = self.env.shift_slots[idx1], self.env.shift_slots[idx2]\n",
    "                w1, w2 = neighbor[idx1], neighbor[idx2]\n",
    "                worker1 = next((w for w in self.env.workers if w.worker_id == w1), None)\n",
    "                worker2 = next((w for w in self.env.workers if w.worker_id == w2), None)\n",
    "                if (worker1 and worker2 and\n",
    "                    worker1.is_available(slot2.day, slot2.hour) and\n",
    "                    worker2.is_available(slot1.day, slot1.hour)):\n",
    "                    neighbor[idx1], neighbor[idx2] = w2, w1\n",
    "\n",
    "        elif strategy == 'fine_tune':\n",
    "            idx = random.randint(0, len(solution) - 1)\n",
    "            slot = self.env.shift_slots[idx]\n",
    "            current = neighbor[idx]\n",
    "            available = self.env.get_available_workers(slot.day, slot.hour)\n",
    "            if available and current != -1:\n",
    "                worker_hours = {w.worker_id: sum(1 for x in neighbor if x == w.worker_id)\n",
    "                               for w in self.env.workers}\n",
    "                current_hours = worker_hours.get(current, 0)\n",
    "                better = [w for w in available if abs(worker_hours.get(w, 0) - 17) < abs(current_hours - 17)]\n",
    "                if better:\n",
    "                    neighbor[idx] = random.choice(better)\n",
    "\n",
    "        return neighbor\n",
    "\n",
    "    def save_checkpoint(self, iteration: int, elapsed: float, temperature: float):\n",
    "        \"\"\"Save checkpoint to file\"\"\"\n",
    "        if not hasattr(self, 'checkpoint_dir') or not self.checkpoint_dir:\n",
    "            return\n",
    "\n",
    "        checkpoint = {\n",
    "            'algorithm': 'SA',\n",
    "            'iteration': iteration,\n",
    "            'elapsed_seconds': elapsed,\n",
    "            'elapsed_minutes': elapsed / 60,\n",
    "            'temperature': temperature,\n",
    "            'best_cost': self.best_cost,\n",
    "            'cost_history_length': len(self.cost_history),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "        self.checkpoint_history.append(checkpoint)\n",
    "\n",
    "        filename = os.path.join(self.checkpoint_dir, f'sa_checkpoint_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json')\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump({\n",
    "                    'checkpoint': checkpoint,\n",
    "                    'best_solution': self.best_solution.tolist() if self.best_solution is not None else None,\n",
    "                    'cost_history_sample': self.cost_history[::1000] if len(self.cost_history) > 1000 else self.cost_history\n",
    "                }, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not save checkpoint: {e}\")\n",
    "\n",
    "    def solve(self, verbose: bool = True) -> Tuple[np.ndarray, float, List[float]]:\n",
    "        \"\"\"Run SA with proper cooling schedule and checkpointing\"\"\"\n",
    "        start_time = time.time()\n",
    "        last_checkpoint_time = start_time\n",
    "\n",
    "        current_solution = self.generate_initial_solution()\n",
    "        current_cost = self.env.evaluate_schedule(current_solution)[0]\n",
    "\n",
    "        self.best_solution = current_solution.copy()\n",
    "        self.best_cost = current_cost\n",
    "\n",
    "        temperature = self.initial_temp\n",
    "        iteration = 0\n",
    "        iterations_since_improvement = 0\n",
    "        reheat_count = 0\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"SA Configuration:\")\n",
    "            print(f\"  Initial temp: {self.initial_temp}, Final temp: {self.final_temp}\")\n",
    "            print(f\"  Cooling rate: {self.cooling_rate}\")\n",
    "            print(f\"  Iterations per temp: {self.iterations_per_temp}\")\n",
    "            print(f\"  Max iterations: {self.max_iterations:,}\")\n",
    "            print(f\"  Max time: {self.max_time/60:.0f} min ({self.max_time/3600:.1f} hr)\")\n",
    "            print(f\"  Max reheats: {self.max_reheats}\")\n",
    "            print(f\"  Checkpoint interval: {self.checkpoint_interval}s\")\n",
    "            print(f\"\\nInitial cost: {current_cost:.2f}\")\n",
    "\n",
    "        while temperature > self.final_temp:\n",
    "            elapsed = time.time() - start_time\n",
    "\n",
    "            if iteration >= self.max_iterations:\n",
    "                if verbose:\n",
    "                    print(f\"\\n  STOPPING: Max iterations ({self.max_iterations:,}) reached\")\n",
    "                break\n",
    "            if elapsed >= self.max_time:\n",
    "                if verbose:\n",
    "                    print(f\"\\n  STOPPING: Max time ({self.max_time/60:.0f} min) reached\")\n",
    "                break\n",
    "            if reheat_count >= self.max_reheats:\n",
    "                if verbose:\n",
    "                    print(f\"\\n  STOPPING: Max reheats ({self.max_reheats}) reached\")\n",
    "                break\n",
    "\n",
    "            if elapsed - (last_checkpoint_time - start_time) >= self.checkpoint_interval:\n",
    "                if ENABLE_CHECKPOINTING:\n",
    "                    self.save_checkpoint(iteration, elapsed, temperature)\n",
    "                last_checkpoint_time = time.time()\n",
    "                if verbose:\n",
    "                    print(f\"  [Checkpoint saved at {elapsed/60:.1f} min]\")\n",
    "\n",
    "            for _ in range(self.iterations_per_temp):\n",
    "                iteration += 1\n",
    "                iterations_since_improvement += 1\n",
    "\n",
    "                if iteration >= self.max_iterations or (time.time() - start_time) >= self.max_time:\n",
    "                    break\n",
    "\n",
    "                new_solution = self.generate_neighbor(current_solution, temperature)\n",
    "                new_cost = self.env.evaluate_schedule(new_solution)[0]\n",
    "\n",
    "                delta = new_cost - current_cost\n",
    "\n",
    "                if delta < 0:\n",
    "                    accept = True\n",
    "                else:\n",
    "                    accept_prob = math.exp(-delta / max(temperature, 0.001))\n",
    "                    accept = random.random() < accept_prob\n",
    "\n",
    "                if accept:\n",
    "                    current_solution = new_solution\n",
    "                    current_cost = new_cost\n",
    "\n",
    "                    if current_cost < self.best_cost:\n",
    "                        self.best_solution = current_solution.copy()\n",
    "                        self.best_cost = current_cost\n",
    "                        iterations_since_improvement = 0\n",
    "\n",
    "                if iteration % 100 == 0:\n",
    "                    self.cost_history.append(self.best_cost)\n",
    "\n",
    "                if self.best_cost == 0:\n",
    "                    if verbose:\n",
    "                        print(f\"\\nPerfect solution found at iteration {iteration}!\")\n",
    "                    return self.best_solution, self.best_cost, self.cost_history\n",
    "\n",
    "            if iterations_since_improvement > 50000 and reheat_count < self.max_reheats:\n",
    "                reheat_count += 1\n",
    "                old_temp = temperature\n",
    "                temperature = self.initial_temp * (0.5 ** (reheat_count / 10))\n",
    "                iterations_since_improvement = 0\n",
    "                if verbose:\n",
    "                    print(f\"  Reheat #{reheat_count}: {old_temp:.1f} -> {temperature:.1f} at iter {iteration:,}\")\n",
    "\n",
    "            temperature *= self.cooling_rate\n",
    "\n",
    "            if verbose and iteration % 100000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = iteration / elapsed if elapsed > 0 else 0\n",
    "                print(f\"  Iter {iteration:,}: Temp={temperature:.2f}, Best={self.best_cost:.1f}, \"\n",
    "                      f\"Time={elapsed/60:.1f}min, Rate={rate:.0f}/s\")\n",
    "\n",
    "        if ENABLE_CHECKPOINTING:\n",
    "            self.save_checkpoint(iteration, time.time() - start_time, temperature)\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"SA COMPLETED\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Total time: {total_time:.1f}s ({total_time/60:.1f} min)\")\n",
    "            print(f\"Total iterations: {iteration:,}\")\n",
    "            print(f\"Reheats used: {reheat_count}\")\n",
    "            print(f\"Best cost: {self.best_cost:.2f}\")\n",
    "            _, details = self.env.evaluate_schedule(self.best_solution)\n",
    "            print(f\"Violations: {details}\")\n",
    "\n",
    "        return self.best_solution, self.best_cost, self.cost_history\n",
    "\n",
    "print(\"Enhanced Simulated Annealing with checkpointing defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Enhanced CSP Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPSolver:\n",
    "    \"\"\"Optimized CSP solver with time limits\"\"\"\n",
    "\n",
    "    def __init__(self, environment: SchedulingEnvironment,\n",
    "                 max_time: float = 1800.0,\n",
    "                 local_search_iterations: int = 100000,\n",
    "                 batch_size: int = 200,\n",
    "                 num_restarts: int = 3,\n",
    "                 checkpoint_interval: float = 300.0,\n",
    "                 checkpoint_dir: str = \"checkpoints\"):\n",
    "        \n",
    "        self.env = environment\n",
    "        self.max_time = max_time\n",
    "        self.local_search_iterations = local_search_iterations\n",
    "        self.batch_size = batch_size\n",
    "        self.num_restarts = num_restarts\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.checkpoint_history = []  # For graphing\n",
    "        self.penalty_history = []  # Track best penalty over time\n",
    "\n",
    "        self.worker_ids = [w.worker_id for w in self.env.workers]\n",
    "        self.nodes_explored = 0\n",
    "        self.improvements = 0\n",
    "        self.start_time = None\n",
    "\n",
    "        self.best_solution = None\n",
    "        self.best_penalty = float('inf')\n",
    "        self.min_shift = 2\n",
    "        self.max_shift = 6\n",
    "        self.min_hours = self.env.MIN_HOURS_PER_WORKER\n",
    "\n",
    "    def _get_worker_hours(self, assignment: np.ndarray) -> Dict[int, int]:\n",
    "        \"\"\"Count hours assigned to each worker\"\"\"\n",
    "        worker_hours = {w.worker_id: 0 for w in self.env.workers}\n",
    "        for worker_id in assignment:\n",
    "            if worker_id != -1 and worker_id in worker_hours:\n",
    "                worker_hours[worker_id] += 1\n",
    "        return worker_hours\n",
    "\n",
    "    def _build_greedy_solution(self, randomize: bool = False) -> np.ndarray:\n",
    "        \"\"\"Build initial solution using greedy construction\"\"\"\n",
    "        solution = np.full(self.env.num_slots, -1, dtype=int)\n",
    "        worker_hours = {w.worker_id: 0 for w in self.env.workers}\n",
    "\n",
    "        slot_groups = {}\n",
    "        for i, slot in enumerate(self.env.shift_slots):\n",
    "            key = (slot.day, slot.shift_type)\n",
    "            if key not in slot_groups:\n",
    "                slot_groups[key] = []\n",
    "            slot_groups[key].append((i, slot.hour))\n",
    "\n",
    "        for key in slot_groups:\n",
    "            slot_groups[key].sort(key=lambda x: x[1])\n",
    "\n",
    "        keys = list(slot_groups.keys())\n",
    "        if randomize:\n",
    "            random.shuffle(keys)\n",
    "\n",
    "        for (day, shift_type) in keys:\n",
    "            slots = slot_groups[(day, shift_type)]\n",
    "            i = 0\n",
    "            while i < len(slots):\n",
    "                slot_idx, hour = slots[i]\n",
    "                available = self.env.get_available_workers(day, hour)\n",
    "                if not available:\n",
    "                    i += 1\n",
    "                    continue\n",
    "\n",
    "                def worker_score(w_id):\n",
    "                    hours = worker_hours[w_id]\n",
    "                    base = 0 if hours < self.min_hours else 1000\n",
    "                    noise = random.random() * 10 if randomize else 0\n",
    "                    return base + hours + noise\n",
    "\n",
    "                available_sorted = sorted(available, key=worker_score)\n",
    "\n",
    "                for chosen in available_sorted:\n",
    "                    if worker_hours[chosen] >= 20:\n",
    "                        continue\n",
    "                    max_block = min(self.max_shift, 20 - worker_hours[chosen])\n",
    "                    if max_block < self.min_shift:\n",
    "                        continue\n",
    "\n",
    "                    block_length = 0\n",
    "                    for j in range(i, len(slots)):\n",
    "                        next_idx, next_hour = slots[j]\n",
    "                        if next_hour != hour + (j - i):\n",
    "                            break\n",
    "                        worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n",
    "                        if worker and worker.is_available(day, next_hour):\n",
    "                            block_length += 1\n",
    "                            if block_length >= max_block:\n",
    "                                break\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    if block_length >= self.min_shift:\n",
    "                        for j in range(block_length):\n",
    "                            next_idx, _ = slots[i + j]\n",
    "                            solution[next_idx] = chosen\n",
    "                        worker_hours[chosen] += block_length\n",
    "                        i += block_length\n",
    "                        break\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "        return solution\n",
    "\n",
    "    def save_checkpoint(self, restart: int, elapsed: float):\n",
    "        \"\"\"Save checkpoint to file\"\"\"\n",
    "        if not self.checkpoint_dir:\n",
    "            return\n",
    "        \n",
    "        checkpoint = {\n",
    "            'algorithm': 'CSP',\n",
    "            'restart': restart,\n",
    "            'elapsed_seconds': elapsed,\n",
    "            'elapsed_minutes': elapsed / 60,\n",
    "            'best_penalty': self.best_penalty,\n",
    "            'nodes_explored': self.nodes_explored,\n",
    "            'improvements': self.improvements,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        self.checkpoint_history.append(checkpoint)\n",
    "        \n",
    "        try:\n",
    "            filename = os.path.join(self.checkpoint_dir, f'csp_checkpoint_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json')\n",
    "            with open(filename, 'w', encoding='utf-8') as file:\n",
    "                json.dump({\n",
    "                    'checkpoint': checkpoint,\n",
    "                    'penalty_history': self.penalty_history[-1000:] if len(self.penalty_history) > 1000 else self.penalty_history\n",
    "                }, file, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not save CSP checkpoint: {e}\")\n",
    "\n",
    "    def _local_search(self, solution: np.ndarray, iterations: int, verbose: bool = True) -> np.ndarray:\n",
    "        \"\"\"Improve solution using local search\"\"\"\n",
    "        current = solution.copy()\n",
    "        current_penalty = self.env.evaluate_schedule(current)[0]\n",
    "\n",
    "        best = current.copy()\n",
    "        best_penalty = current_penalty\n",
    "\n",
    "        no_improvement_count = 0\n",
    "        max_no_improvement = 300\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            if time.time() - self.start_time > self.max_time:\n",
    "                break\n",
    "\n",
    "            move_type = random.choice(['swap', 'reassign_block', 'extend', 'fill_gap'])\n",
    "            neighbor = current.copy()\n",
    "\n",
    "            if move_type == 'swap':\n",
    "                assigned = [i for i, w in enumerate(current) if w != -1]\n",
    "                if len(assigned) >= 2:\n",
    "                    idx1, idx2 = random.sample(assigned, 2)\n",
    "                    slot1, slot2 = self.env.shift_slots[idx1], self.env.shift_slots[idx2]\n",
    "                    w1, w2 = neighbor[idx1], neighbor[idx2]\n",
    "                    worker1 = next((w for w in self.env.workers if w.worker_id == w1), None)\n",
    "                    worker2 = next((w for w in self.env.workers if w.worker_id == w2), None)\n",
    "                    if (worker1 and worker2 and\n",
    "                        worker1.is_available(slot2.day, slot2.hour) and\n",
    "                        worker2.is_available(slot1.day, slot1.hour)):\n",
    "                        neighbor[idx1], neighbor[idx2] = w2, w1\n",
    "\n",
    "            elif move_type == 'reassign_block':\n",
    "                assigned = [i for i, w in enumerate(current) if w != -1]\n",
    "                if assigned:\n",
    "                    idx = random.choice(assigned)\n",
    "                    slot = self.env.shift_slots[idx]\n",
    "                    old_worker = neighbor[idx]\n",
    "                    available = [w for w in self.env.get_available_workers(slot.day, slot.hour) if w != old_worker]\n",
    "                    if available:\n",
    "                        new_worker = random.choice(available)\n",
    "                        for i, s in enumerate(self.env.shift_slots):\n",
    "                            if (s.day == slot.day and s.shift_type == slot.shift_type and neighbor[i] == old_worker):\n",
    "                                worker = next((w for w in self.env.workers if w.worker_id == new_worker), None)\n",
    "                                if worker and worker.is_available(s.day, s.hour):\n",
    "                                    neighbor[i] = new_worker\n",
    "\n",
    "            elif move_type == 'extend':\n",
    "                assigned = [i for i, w in enumerate(current) if w != -1]\n",
    "                if assigned:\n",
    "                    idx = random.choice(assigned)\n",
    "                    slot = self.env.shift_slots[idx]\n",
    "                    worker_id = neighbor[idx]\n",
    "                    for i, s in enumerate(self.env.shift_slots):\n",
    "                        if (s.day == slot.day and s.shift_type == slot.shift_type and\n",
    "                            abs(s.hour - slot.hour) == 1 and neighbor[i] == -1):\n",
    "                            worker = next((w for w in self.env.workers if w.worker_id == worker_id), None)\n",
    "                            if worker and worker.is_available(s.day, s.hour):\n",
    "                                hours = sum(1 for w in neighbor if w == worker_id)\n",
    "                                if hours < 20:\n",
    "                                    neighbor[i] = worker_id\n",
    "                                    break\n",
    "\n",
    "            elif move_type == 'fill_gap':\n",
    "                empty = [i for i, w in enumerate(current) if w == -1]\n",
    "                if empty:\n",
    "                    idx = random.choice(empty)\n",
    "                    slot = self.env.shift_slots[idx]\n",
    "                    available = self.env.get_available_workers(slot.day, slot.hour)\n",
    "                    worker_hours = self._get_worker_hours(neighbor)\n",
    "                    under_min = [w for w in available if worker_hours[w] < self.min_hours]\n",
    "                    if under_min:\n",
    "                        chosen = random.choice(under_min)\n",
    "                    elif available:\n",
    "                        chosen = random.choice(available)\n",
    "                    else:\n",
    "                        continue\n",
    "                    block_size = random.randint(2, 4)\n",
    "                    for i, s in enumerate(self.env.shift_slots):\n",
    "                        if (s.day == slot.day and s.shift_type == slot.shift_type and\n",
    "                            slot.hour <= s.hour < slot.hour + block_size and neighbor[i] == -1):\n",
    "                            worker = next((w for w in self.env.workers if w.worker_id == chosen), None)\n",
    "                            if worker and worker.is_available(s.day, s.hour):\n",
    "                                hours = sum(1 for w in neighbor if w == chosen)\n",
    "                                if hours < 20:\n",
    "                                    neighbor[i] = chosen\n",
    "\n",
    "            neighbor_penalty = self.env.evaluate_schedule(neighbor)[0]\n",
    "            self.nodes_explored += 1\n",
    "\n",
    "            if neighbor_penalty < current_penalty:\n",
    "                current = neighbor\n",
    "                current_penalty = neighbor_penalty\n",
    "                no_improvement_count = 0\n",
    "                if current_penalty < best_penalty:\n",
    "                    best = current.copy()\n",
    "                    best_penalty = current_penalty\n",
    "                    self.improvements += 1\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "                if random.random() < 0.02:\n",
    "                    current = neighbor\n",
    "                    current_penalty = neighbor_penalty\n",
    "\n",
    "            if no_improvement_count > max_no_improvement:\n",
    "                current = self._build_greedy_solution(randomize=True)\n",
    "                current_penalty = self.env.evaluate_schedule(current)[0]\n",
    "                no_improvement_count = 0\n",
    "\n",
    "        return best\n",
    "\n",
    "    def solve(self, verbose: bool = True) -> Tuple[Optional[np.ndarray], float, Dict]:\n",
    "        \"\"\"Solve with multi-restart strategy\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        self.nodes_explored = 0\n",
    "        self.improvements = 0\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"CSP: max_time={self.max_time/60:.0f}min, iterations={self.local_search_iterations:,}\")\n",
    "\n",
    "        iterations_per_restart = self.local_search_iterations // self.num_restarts\n",
    "\n",
    "        last_checkpoint_time = self.start_time\n",
    "        \n",
    "        for restart in range(self.num_restarts):\n",
    "            elapsed = time.time() - self.start_time\n",
    "            if elapsed > self.max_time:\n",
    "                break\n",
    "            \n",
    "            # Save checkpoint periodically\n",
    "            if elapsed - (last_checkpoint_time - self.start_time) >= self.checkpoint_interval:\n",
    "                if self.checkpoint_dir:\n",
    "                    self.save_checkpoint(restart, elapsed)\n",
    "                    if verbose:\n",
    "                        print(f\"  [CSP Checkpoint saved at {elapsed/60:.1f} min]\")\n",
    "                last_checkpoint_time = time.time()\n",
    "                \n",
    "            if verbose:\n",
    "                print(f\"  Restart {restart + 1}/{self.num_restarts}\")\n",
    "\n",
    "            initial_solution = self._build_greedy_solution(randomize=(restart > 0))\n",
    "            initial_penalty = self.env.evaluate_schedule(initial_solution)[0]\n",
    "\n",
    "            best_solution = self._local_search(initial_solution, iterations_per_restart, verbose)\n",
    "            best_penalty = self.env.evaluate_schedule(best_solution)[0]\n",
    "\n",
    "            if best_penalty < self.best_penalty:\n",
    "                self.best_penalty = best_penalty\n",
    "                self.best_solution = best_solution.copy()\n",
    "                self.penalty_history.append(self.best_penalty)  # Track for graphing\n",
    "                if verbose:\n",
    "                    print(f\"    New best: {self.best_penalty:.2f}\")\n",
    "\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        stats = {'nodes_explored': self.nodes_explored, 'improvements': self.improvements, \n",
    "                 'time': elapsed_time, 'success': True}\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nCSP completed in {elapsed_time:.1f}s ({elapsed_time/60:.1f} min)\")\n",
    "            print(f\"Best penalty: {self.best_penalty:.2f}\")\n",
    "            _, details = self.env.evaluate_schedule(self.best_solution)\n",
    "            print(f\"Violations: {details}\")\n",
    "\n",
    "        return self.best_solution, self.best_penalty, stats\n",
    "\n",
    "print(\"Optimized CSP Solver defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Run Algorithms (Choose Individual or Parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PARALLEL EXECUTION WITH GPU ACCELERATION\n",
    "# ============================================================================\n",
    "# Runs all algorithms simultaneously - total time = max(GA, SA, CSP) time\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "RUN_GA = True\n",
    "RUN_SA = True  \n",
    "RUN_CSP = True\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ============================================================================\n",
    "# ALGORITHM RUNNER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def run_ga(workers_data, schedule_type, config):\n",
    "    \"\"\"Run GA in separate thread\"\"\"\n",
    "    local_env = SchedulingEnvironment(workers_data, schedule_type=schedule_type)\n",
    "    print(f\"\\n{'='*60}\\nSTARTING GENETIC ALGORITHM\\n{'='*60}\")\n",
    "    \n",
    "    ga = GeneticAlgorithm(\n",
    "        local_env,\n",
    "        population_size=config['population_size'],\n",
    "        generations=config['generations'],\n",
    "        crossover_rate=config['crossover_rate'],\n",
    "        mutation_rate=config['mutation_rate'],\n",
    "        elitism_count=config['elitism_count'],\n",
    "        batch_size=config.get('batch_size', 500),\n",
    "        max_time=config.get('max_time', 7200.0),\n",
    "        checkpoint_interval=config.get('checkpoint_interval', 300.0),\n",
    "        checkpoint_dir=CHECKPOINT_DIR if ENABLE_CHECKPOINTING else None\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    solution, fitness, history = ga.solve(verbose=True)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    _, details = local_env.evaluate_schedule(solution)\n",
    "    print(f\"\\n*** GA COMPLETE: {fitness:.1f} penalty in {elapsed/60:.1f} min ***\")\n",
    "    \n",
    "    return {'algo': 'GA', 'solution': solution, 'penalty': fitness, \n",
    "            'history': history, 'time': elapsed, 'details': details}\n",
    "\n",
    "def run_sa(workers_data, schedule_type, config):\n",
    "    \"\"\"Run SA in separate thread\"\"\"\n",
    "    local_env = SchedulingEnvironment(workers_data, schedule_type=schedule_type)\n",
    "    print(f\"\\n{'='*60}\\nSTARTING SIMULATED ANNEALING\\n{'='*60}\")\n",
    "    \n",
    "    sa = SimulatedAnnealing(\n",
    "        local_env,\n",
    "        initial_temp=config['initial_temp'],\n",
    "        final_temp=config['final_temp'],\n",
    "        cooling_rate=config['cooling_rate'],\n",
    "        iterations_per_temp=config['iterations_per_temp'],\n",
    "        max_iterations=config.get('max_iterations', 15000000),\n",
    "        max_time=config.get('max_time', 7200.0),\n",
    "        max_reheats=config.get('max_reheats', 50),\n",
    "        checkpoint_interval=config.get('checkpoint_interval', 300.0),\n",
    "        checkpoint_dir=CHECKPOINT_DIR if ENABLE_CHECKPOINTING else None\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    solution, cost, history = sa.solve(verbose=True)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    _, details = local_env.evaluate_schedule(solution)\n",
    "    print(f\"\\n*** SA COMPLETE: {cost:.1f} penalty in {elapsed/60:.1f} min ***\")\n",
    "    \n",
    "    return {'algo': 'SA', 'solution': solution, 'penalty': cost,\n",
    "            'history': history, 'time': elapsed, 'details': details}\n",
    "\n",
    "def run_csp(workers_data, schedule_type, config):\n",
    "    \"\"\"Run CSP in separate thread\"\"\"\n",
    "    local_env = SchedulingEnvironment(workers_data, schedule_type=schedule_type)\n",
    "    print(f\"\\n{'='*60}\\nSTARTING CSP SOLVER\\n{'='*60}\")\n",
    "    \n",
    "    csp = CSPSolver(\n",
    "        local_env,\n",
    "        max_time=config['max_time'],\n",
    "        local_search_iterations=config['local_search_iterations'],\n",
    "        batch_size=config.get('batch_size', 200),\n",
    "        num_restarts=config.get('num_restarts', 3),\n",
    "        checkpoint_interval=config.get('checkpoint_interval', 300.0),\n",
    "        checkpoint_dir=CHECKPOINT_DIR if ENABLE_CHECKPOINTING else None\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    solution, penalty, stats = csp.solve(verbose=True)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    _, details = local_env.evaluate_schedule(solution)\n",
    "    print(f\"\\n*** CSP COMPLETE: {penalty:.1f} penalty in {elapsed/60:.1f} min ***\")\n",
    "    \n",
    "    return {'algo': 'CSP', 'solution': solution, 'penalty': penalty,\n",
    "            'history': [], 'time': elapsed, 'details': details}\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTE IN PARALLEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"PARALLEL EXECUTION - GPU: {'ENABLED' if USE_GPU else 'DISABLED'}\")\n",
    "print(f\"Profile: {COMPUTE_PROFILE.upper()}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "parallel_start = time.time()\n",
    "\n",
    "tasks = []\n",
    "if RUN_GA:\n",
    "    tasks.append(('GA', run_ga, GA_CONFIG))\n",
    "if RUN_SA:\n",
    "    tasks.append(('SA', run_sa, SA_CONFIG))\n",
    "if RUN_CSP:\n",
    "    tasks.append(('CSP', run_csp, CSP_CONFIG))\n",
    "\n",
    "print(f\"Running {len(tasks)} algorithms in parallel...\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(tasks)) as executor:\n",
    "    futures = {executor.submit(func, workers, env.schedule_type, cfg): name \n",
    "               for name, func, cfg in tasks}\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        algo = futures[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results[result['algo']] = {\n",
    "                'solution': result['solution'],\n",
    "                'penalty': result['penalty'],\n",
    "                'history': result['history'],\n",
    "                'time': result['time'],\n",
    "                'details': result['details']\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in {algo}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "parallel_time = time.time() - parallel_start\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXECUTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total wall-clock time: {parallel_time/60:.1f} minutes\")\n",
    "\n",
    "if results:\n",
    "    seq_time = sum(r['time'] for r in results.values())\n",
    "    speedup = seq_time / parallel_time if parallel_time > 0 else 1\n",
    "    print(f\"Sequential time would be: {seq_time/60:.1f} minutes\")\n",
    "    print(f\"Parallel speedup: {speedup:.2f}x\")\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    for algo in ['GA', 'SA', 'CSP']:\n",
    "        if algo in results:\n",
    "            r = results[algo]\n",
    "            print(f\"  {algo}: Penalty={r['penalty']:.1f}, Time={r['time']/60:.1f}min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Results Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ALGORITHM COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n{'Algorithm':<15} {'Penalty':<15} {'Runtime':<15} {'Status'}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "best_algo = min(results.keys(), key=lambda a: results[a]['penalty'])\n",
    "\n",
    "for algo in ['GA', 'SA', 'CSP']:\n",
    "    if algo in results:\n",
    "        r = results[algo]\n",
    "        runtime_str = f\"{r['time']:.1f}s\" if r['time'] < 60 else f\"{r['time']/60:.1f}min\"\n",
    "        status = \"<-- BEST\" if algo == best_algo else \"\"\n",
    "        print(f\"{algo:<15} {r['penalty']:<15.2f} {runtime_str:<15} {status}\")\n",
    "\n",
    "# Detailed violations\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CONSTRAINT VIOLATIONS BREAKDOWN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "constraints = [\n",
    "    'coverage_violations', 'worker_conflicts', 'hour_violations',\n",
    "    'min_hour_violations', 'shift_length_violations', 'tier_mismatches',\n",
    "    'fairness_violations', 'morning_shift_violations'\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Constraint':<30}\", end=\"\")\n",
    "for algo in ['GA', 'SA', 'CSP']:\n",
    "    if algo in results:\n",
    "        print(f\"{algo:<10}\", end=\"\")\n",
    "print()\n",
    "print(\"-\"*60)\n",
    "\n",
    "for constraint in constraints:\n",
    "    print(f\"{constraint:<30}\", end=\"\")\n",
    "    for algo in ['GA', 'SA', 'CSP']:\n",
    "        if algo in results:\n",
    "            val = results[algo]['details'].get(constraint, 0)\n",
    "            print(f\"{val:<10}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# Best solution details\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BEST SOLUTION: {best_algo} (Penalty: {results[best_algo]['penalty']:.2f})\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure 1: Performance Dashboard\n",
    "\n",
    "*Overall comparison of algorithm performance metrics*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE ALGORITHM COMPARISON VISUALIZATIONS\n",
    "# ============================================================================\n",
    "# This cell generates multiple publication-quality graphs comparing GA, SA, and CSP\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Set publication-quality style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "except:\n",
    "    try:\n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "    except:\n",
    "        pass  # Use default style\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Color scheme for algorithms\n",
    "ALGO_COLORS = {'GA': '#E74C3C', 'SA': '#3498DB', 'CSP': '#2ECC71'}\n",
    "ALGO_MARKERS = {'GA': 'o', 'SA': 's', 'CSP': '^'}\n",
    "\n",
    "# Create output directory for visualizations\n",
    "VIZ_OUTPUT_DIR = \"visualizations\"\n",
    "os.makedirs(VIZ_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GENERATING COMPREHENSIVE VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 1: Overall Performance Dashboard (2x2)\n",
    "# ============================================================================\n",
    "fig1, axes1 = plt.subplots(2, 2, figsize=(14, 12))\n",
    "fig1.suptitle('Algorithm Performance Dashboard', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# Determine best algorithm\n",
    "best_algo = min(results.keys(), key=lambda a: results[a]['penalty'])\n",
    "algos = list(results.keys())\n",
    "\n",
    "# --- Plot 1.1: Final Penalty Comparison (Bar) ---\n",
    "ax = axes1[0, 0]\n",
    "penalties = [results[a]['penalty'] for a in algos]\n",
    "bars = ax.bar(algos, penalties, color=[ALGO_COLORS[a] for a in algos], \n",
    "              edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "# Highlight best\n",
    "for i, (algo, bar) in enumerate(zip(algos, bars)):\n",
    "    if algo == best_algo:\n",
    "        bar.set_edgecolor('gold')\n",
    "        bar.set_linewidth(4)\n",
    "        ax.annotate(' BEST', xy=(i, penalties[i]), xytext=(0, 10),\n",
    "                   textcoords='offset points', ha='center', fontweight='bold',\n",
    "                   color='darkgreen', fontsize=12)\n",
    "\n",
    "for i, p in enumerate(penalties):\n",
    "    ax.text(i, p + max(penalties)*0.02, f'{p:.0f}', ha='center', va='bottom', \n",
    "            fontweight='bold', fontsize=11)\n",
    "\n",
    "ax.set_ylabel('Penalty Score (lower = better)')\n",
    "ax.set_title('Final Solution Quality')\n",
    "ax.set_ylim(0, max(penalties) * 1.2)\n",
    "\n",
    "# --- Plot 1.2: Runtime Comparison (Horizontal Bar) ---\n",
    "ax = axes1[0, 1]\n",
    "runtimes = [results[a]['time'] / 60 for a in algos]\n",
    "bars = ax.barh(algos, runtimes, color=[ALGO_COLORS[a] for a in algos],\n",
    "               edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "for i, rt in enumerate(runtimes):\n",
    "    ax.text(rt + max(runtimes)*0.02, i, f'{rt:.1f} min', va='center', fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Runtime (minutes)')\n",
    "ax.set_title('Computation Time')\n",
    "ax.set_xlim(0, max(runtimes) * 1.25)\n",
    "\n",
    "# --- Plot 1.3: Efficiency Score (Penalty per Minute) ---\n",
    "ax = axes1[1, 0]\n",
    "efficiency = [results[a]['penalty'] / (results[a]['time'] / 60) for a in algos]\n",
    "bars = ax.bar(algos, efficiency, color=[ALGO_COLORS[a] for a in algos],\n",
    "              edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "for i, e in enumerate(efficiency):\n",
    "    ax.text(i, e + max(efficiency)*0.02, f'{e:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Penalty / Runtime (lower = more efficient)')\n",
    "ax.set_title('Time Efficiency (Solution Quality per Minute)')\n",
    "\n",
    "# --- Plot 1.4: Total Violations Breakdown ---\n",
    "ax = axes1[1, 1]\n",
    "total_violations = [sum(results[a]['details'].values()) for a in algos]\n",
    "bars = ax.bar(algos, total_violations, color=[ALGO_COLORS[a] for a in algos],\n",
    "              edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "for i, v in enumerate(total_violations):\n",
    "    ax.text(i, v + max(total_violations)*0.02, f'{v}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Total Constraint Violations')\n",
    "ax.set_title('Constraint Satisfaction')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig1.savefig(f'{VIZ_OUTPUT_DIR}/01_performance_dashboard.png', bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(f\"Saved: {VIZ_OUTPUT_DIR}/01_performance_dashboard.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure 2: Convergence Analysis\n",
    "\n",
    "*How each algorithm converges over iterations - early vs late phases*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FIGURE 2: Convergence Analysis\n",
    "# ============================================================================\n",
    "\n",
    "fig2, axes2 = plt.subplots(2, 2, figsize=(14, 12))\n",
    "fig2.suptitle('Optimization Convergence Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# --- Plot 2.1: Full Convergence History (Linear Scale) ---\n",
    "ax = axes2[0, 0]\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history and len(history) > 0:\n",
    "        # Subsample for cleaner plot\n",
    "        if len(history) > 3000:\n",
    "            step = len(history) // 3000\n",
    "            history_plot = history[::step]\n",
    "            x = list(range(0, len(history), step))\n",
    "        else:\n",
    "            history_plot = history\n",
    "            x = list(range(len(history)))\n",
    "        \n",
    "        ax.plot(x, history_plot, label=f'{algo}', color=ALGO_COLORS[algo], \n",
    "                linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Best Penalty')\n",
    "ax.set_title('Convergence History (Linear Scale)')\n",
    "ax.legend(loc='upper right', frameon=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 2.2: Convergence History (Log Scale) ---\n",
    "ax = axes2[0, 1]\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history and len(history) > 0:\n",
    "        if len(history) > 3000:\n",
    "            step = len(history) // 3000\n",
    "            history_plot = history[::step]\n",
    "            x = list(range(0, len(history), step))\n",
    "        else:\n",
    "            history_plot = history\n",
    "            x = list(range(len(history)))\n",
    "        \n",
    "        ax.plot(x, history_plot, label=f'{algo}', color=ALGO_COLORS[algo],\n",
    "                linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Best Penalty (log scale)')\n",
    "ax.set_title('Convergence History (Log Scale)')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc='upper right', frameon=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 2.3: Convergence Rate (First 20% of iterations) ---\n",
    "ax = axes2[1, 0]\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history and len(history) > 100:\n",
    "        early_portion = int(len(history) * 0.2)\n",
    "        early_history = history[:early_portion]\n",
    "        \n",
    "        if len(early_history) > 500:\n",
    "            step = len(early_history) // 500\n",
    "            early_plot = early_history[::step]\n",
    "            x = list(range(0, len(early_history), step))\n",
    "        else:\n",
    "            early_plot = early_history\n",
    "            x = list(range(len(early_history)))\n",
    "        \n",
    "        ax.plot(x, early_plot, label=f'{algo}', color=ALGO_COLORS[algo],\n",
    "                linewidth=2, alpha=0.8, marker=ALGO_MARKERS[algo], \n",
    "                markevery=max(1, len(x)//10), markersize=6)\n",
    "\n",
    "ax.set_xlabel('Iteration (Early Phase)')\n",
    "ax.set_ylabel('Best Penalty')\n",
    "ax.set_title('Early Convergence (First 20% - Exploration Phase)')\n",
    "ax.legend(loc='upper right', frameon=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 2.4: Late Convergence (Last 20% - Exploitation Phase) ---\n",
    "ax = axes2[1, 1]\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history and len(history) > 100:\n",
    "        late_start = int(len(history) * 0.8)\n",
    "        late_history = history[late_start:]\n",
    "        \n",
    "        if len(late_history) > 500:\n",
    "            step = len(late_history) // 500\n",
    "            late_plot = late_history[::step]\n",
    "            x = list(range(late_start, len(history), step))\n",
    "        else:\n",
    "            late_plot = late_history\n",
    "            x = list(range(late_start, len(history)))\n",
    "        \n",
    "        ax.plot(x, late_plot, label=f'{algo}', color=ALGO_COLORS[algo],\n",
    "                linewidth=2, alpha=0.8, marker=ALGO_MARKERS[algo],\n",
    "                markevery=max(1, len(x)//10), markersize=6)\n",
    "\n",
    "ax.set_xlabel('Iteration (Late Phase)')\n",
    "ax.set_ylabel('Best Penalty')\n",
    "ax.set_title('Late Convergence (Last 20% - Exploitation Phase)')\n",
    "ax.legend(loc='upper right', frameon=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig2.savefig(f'{VIZ_OUTPUT_DIR}/02_convergence_analysis.png', bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(f\"Saved: {VIZ_OUTPUT_DIR}/02_convergence_analysis.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure 3: Constraint Violations\n",
    "\n",
    "*Detailed breakdown of which constraints each algorithm violates*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FIGURE 3: Detailed Constraint Violations Analysis\n",
    "# ============================================================================\n",
    "\n",
    "fig3 = plt.figure(figsize=(16, 12))\n",
    "fig3.suptitle('Constraint Violations Deep Dive', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# Constraint categories\n",
    "constraints = ['coverage_violations', 'worker_conflicts', 'hour_violations',\n",
    "               'min_hour_violations', 'shift_length_violations', 'tier_mismatches',\n",
    "               'morning_shift_violations']\n",
    "\n",
    "# --- Plot 3.1: Violations Heatmap ---\n",
    "ax1 = fig3.add_subplot(2, 2, 1)\n",
    "violation_matrix = []\n",
    "for algo in algos:\n",
    "    row = [results[algo]['details'].get(c, 0) for c in constraints]\n",
    "    violation_matrix.append(row)\n",
    "\n",
    "col_names = [c.replace('_violations', '').replace('_', ' ').title() for c in constraints]\n",
    "df_violations = pd.DataFrame(violation_matrix, index=algos, columns=col_names)\n",
    "\n",
    "sns.heatmap(df_violations, annot=True, fmt='d', cmap='RdYlGn_r',\n",
    "            linewidths=0.5, ax=ax1, cbar_kws={'label': 'Count'},\n",
    "            annot_kws={'size': 10, 'weight': 'bold'})\n",
    "ax1.set_title('Violations Heatmap by Constraint Type')\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# --- Plot 3.2: Stacked Bar Chart of Violations ---\n",
    "ax2 = fig3.add_subplot(2, 2, 2)\n",
    "x = np.arange(len(algos))\n",
    "width = 0.6\n",
    "bottom = np.zeros(len(algos))\n",
    "\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(constraints)))\n",
    "\n",
    "for i, constraint in enumerate(constraints):\n",
    "    values = [results[a]['details'].get(constraint, 0) for a in algos]\n",
    "    clean_name = constraint.replace('_violations', '').replace('_', ' ').title()\n",
    "    ax2.bar(x, values, width, bottom=bottom, label=clean_name, color=colors[i])\n",
    "    bottom += values\n",
    "\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(algos)\n",
    "ax2.set_ylabel('Number of Violations')\n",
    "ax2.set_title('Stacked Violations by Category')\n",
    "ax2.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=9)\n",
    "\n",
    "# --- Plot 3.3: Radar/Spider Chart of Violations ---\n",
    "ax3 = fig3.add_subplot(2, 2, 3, projection='polar')\n",
    "\n",
    "categories = [c.replace('_violations', '').replace('_', ' ')[:12] for c in constraints]\n",
    "N = len(categories)\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]  # Close the loop\n",
    "\n",
    "ax3.set_theta_offset(np.pi / 2)\n",
    "ax3.set_theta_direction(-1)\n",
    "\n",
    "for algo in algos:\n",
    "    values = [results[algo]['details'].get(c, 0) for c in constraints]\n",
    "    values += values[:1]  # Close the loop\n",
    "    ax3.plot(angles, values, 'o-', linewidth=2, label=algo, color=ALGO_COLORS[algo])\n",
    "    ax3.fill(angles, values, alpha=0.15, color=ALGO_COLORS[algo])\n",
    "\n",
    "ax3.set_xticks(angles[:-1])\n",
    "ax3.set_xticklabels(categories, size=8)\n",
    "ax3.set_title('Violation Profile (Radar)', y=1.1)\n",
    "ax3.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "# --- Plot 3.4: Violation Severity Score ---\n",
    "ax4 = fig3.add_subplot(2, 2, 4)\n",
    "\n",
    "# Define severity weights (customize based on importance)\n",
    "severity_weights = {\n",
    "    'coverage_violations': 100,\n",
    "    'worker_conflicts': 500,\n",
    "    'hour_violations': 50,\n",
    "    'min_hour_violations': 30,\n",
    "    'shift_length_violations': 40,\n",
    "    'tier_mismatches': 20,\n",
    "    'morning_shift_violations': 10\n",
    "}\n",
    "\n",
    "severity_scores = []\n",
    "for algo in algos:\n",
    "    score = sum(results[algo]['details'].get(c, 0) * severity_weights.get(c, 1) \n",
    "                for c in constraints)\n",
    "    severity_scores.append(score)\n",
    "\n",
    "bars = ax4.bar(algos, severity_scores, color=[ALGO_COLORS[a] for a in algos],\n",
    "              edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "for i, s in enumerate(severity_scores):\n",
    "    ax4.text(i, s + max(severity_scores)*0.02, f'{s:.0f}', ha='center', \n",
    "            va='bottom', fontweight='bold')\n",
    "\n",
    "ax4.set_ylabel('Weighted Severity Score')\n",
    "ax4.set_title('Weighted Violation Severity (Higher weight = More critical)')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig3.savefig(f'{VIZ_OUTPUT_DIR}/03_violations_analysis.png', bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(f\"Saved: {VIZ_OUTPUT_DIR}/03_violations_analysis.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure 4: Exploration vs Exploitation\n",
    "\n",
    "*Analysis of how algorithms balance searching vs refining*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FIGURE 4: Exploration vs Exploitation Analysis\n",
    "# ============================================================================\n",
    "\n",
    "fig4, axes4 = plt.subplots(2, 2, figsize=(14, 12))\n",
    "fig4.suptitle('Exploration vs Exploitation Trade-off Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# --- Plot 4.1: Improvement Rate Over Time ---\n",
    "ax = axes4[0, 0]\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history and len(history) > 100:\n",
    "        # Calculate improvement rate (derivative)\n",
    "        window = max(10, len(history) // 100)\n",
    "        improvements = []\n",
    "        x_vals = []\n",
    "        \n",
    "        for i in range(window, len(history), window):\n",
    "            improvement = history[i-window] - history[i]\n",
    "            improvements.append(max(0, improvement))  # Only positive improvements\n",
    "            x_vals.append(i)\n",
    "        \n",
    "        if improvements:\n",
    "            # Smooth the curve\n",
    "            if len(improvements) > 50:\n",
    "                step = len(improvements) // 50\n",
    "                improvements = improvements[::step]\n",
    "                x_vals = x_vals[::step]\n",
    "            \n",
    "            ax.plot(x_vals, improvements, label=f'{algo}', color=ALGO_COLORS[algo],\n",
    "                    linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Improvement per Window')\n",
    "ax.set_title('Improvement Rate Over Time (Decreasing = More Exploitation)')\n",
    "ax.legend(loc='upper right', frameon=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# --- Plot 4.2: Cumulative Improvement ---\n",
    "ax = axes4[0, 1]\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history and len(history) > 10:\n",
    "        initial = history[0]\n",
    "        cumulative = [(initial - h) / initial * 100 for h in history]\n",
    "        \n",
    "        if len(cumulative) > 1000:\n",
    "            step = len(cumulative) // 1000\n",
    "            cumulative = cumulative[::step]\n",
    "            x = list(range(0, len(history), step))\n",
    "        else:\n",
    "            x = list(range(len(cumulative)))\n",
    "        \n",
    "        ax.plot(x, cumulative, label=f'{algo} (final: {cumulative[-1]:.1f}%)', \n",
    "                color=ALGO_COLORS[algo], linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Improvement from Initial (%)')\n",
    "ax.set_title('Cumulative Improvement Over Time')\n",
    "ax.legend(loc='lower right', frameon=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 4.3: Solution Diversity (Variance in Recent History) ---\n",
    "ax = axes4[1, 0]\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history and len(history) > 200:\n",
    "        window = 100\n",
    "        variances = []\n",
    "        x_vals = []\n",
    "        \n",
    "        for i in range(window, len(history), window//2):\n",
    "            window_data = history[max(0, i-window):i]\n",
    "            if len(window_data) > 1:\n",
    "                var = np.std(window_data)\n",
    "                variances.append(var)\n",
    "                x_vals.append(i)\n",
    "        \n",
    "        if variances:\n",
    "            ax.plot(x_vals, variances, label=f'{algo}', color=ALGO_COLORS[algo],\n",
    "                    linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Standard Deviation (Rolling Window)')\n",
    "ax.set_title('Solution Quality Variance (High = Exploring, Low = Exploiting)')\n",
    "ax.legend(loc='upper right', frameon=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 4.4: Algorithm Characteristics Summary ---\n",
    "ax = axes4[1, 1]\n",
    "\n",
    "# Calculate characteristics for each algorithm\n",
    "characteristics = {\n",
    "    'Initial Penalty': [],\n",
    "    'Final Penalty': [],\n",
    "    'Improvement %': [],\n",
    "    'Iterations': [],\n",
    "    'Time (min)': []\n",
    "}\n",
    "\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history:\n",
    "        characteristics['Initial Penalty'].append(history[0] if history else 0)\n",
    "        characteristics['Final Penalty'].append(results[algo]['penalty'])\n",
    "        improvement = (history[0] - results[algo]['penalty']) / history[0] * 100 if history and history[0] > 0 else 0\n",
    "        characteristics['Improvement %'].append(improvement)\n",
    "        characteristics['Iterations'].append(len(history))\n",
    "    else:\n",
    "        characteristics['Initial Penalty'].append(0)\n",
    "        characteristics['Final Penalty'].append(results[algo]['penalty'])\n",
    "        characteristics['Improvement %'].append(0)\n",
    "        characteristics['Iterations'].append(0)\n",
    "    characteristics['Time (min)'].append(results[algo]['time'] / 60)\n",
    "\n",
    "# Create table\n",
    "cell_text = []\n",
    "for algo in algos:\n",
    "    idx = algos.index(algo)\n",
    "    row = [\n",
    "        f\"{characteristics['Initial Penalty'][idx]:.0f}\",\n",
    "        f\"{characteristics['Final Penalty'][idx]:.0f}\",\n",
    "        f\"{characteristics['Improvement %'][idx]:.1f}%\",\n",
    "        f\"{characteristics['Iterations'][idx]:,}\",\n",
    "        f\"{characteristics['Time (min)'][idx]:.1f}\"\n",
    "    ]\n",
    "    cell_text.append(row)\n",
    "\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=cell_text,\n",
    "                 rowLabels=algos,\n",
    "                 colLabels=['Initial', 'Final', 'Improv.', 'Iterations', 'Time'],\n",
    "                 cellLoc='center',\n",
    "                 loc='center',\n",
    "                 colWidths=[0.15, 0.15, 0.15, 0.2, 0.15])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1.2, 1.8)\n",
    "\n",
    "# Color code rows\n",
    "for i, algo in enumerate(algos):\n",
    "    for j in range(5):\n",
    "        table[(i+1, j)].set_facecolor(ALGO_COLORS[algo] + '40')  # 40 = alpha\n",
    "\n",
    "ax.set_title('Algorithm Performance Summary', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig4.savefig(f'{VIZ_OUTPUT_DIR}/04_exploration_exploitation.png', bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(f\"Saved: {VIZ_OUTPUT_DIR}/04_exploration_exploitation.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure 5: Timeline Analysis\n",
    "\n",
    "*Progress over wall-clock time and milestone tracking*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FIGURE 5: Checkpoint Timeline Analysis\n",
    "# ============================================================================\n",
    "# This visualizes the progress over time using checkpoint data\n",
    "\n",
    "fig5, axes5 = plt.subplots(2, 2, figsize=(14, 12))\n",
    "fig5.suptitle('Algorithm Progress Over Time (Checkpoint Analysis)', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# Load checkpoint files if available\n",
    "checkpoint_data = {'GA': [], 'SA': [], 'CSP': []}\n",
    "\n",
    "try:\n",
    "    checkpoint_files = glob.glob(f'{CHECKPOINT_DIR}/*.json')\n",
    "    for f in checkpoint_files:\n",
    "        with open(f, 'r') as fp:\n",
    "            data = json.load(fp)\n",
    "            if 'checkpoint' in data:\n",
    "                algo = data['checkpoint'].get('algorithm', '')\n",
    "                if algo in checkpoint_data:\n",
    "                    checkpoint_data[algo].append(data['checkpoint'])\n",
    "    \n",
    "    # Sort by elapsed time\n",
    "    for algo in checkpoint_data:\n",
    "        checkpoint_data[algo].sort(key=lambda x: x.get('elapsed_seconds', 0))\n",
    "    \n",
    "    print(f\"Loaded checkpoints: GA={len(checkpoint_data['GA'])}, SA={len(checkpoint_data['SA'])}, CSP={len(checkpoint_data['CSP'])}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load checkpoint files: {e}\")\n",
    "\n",
    "# --- Plot 5.1: Best Penalty Over Time (Minutes) ---\n",
    "ax = axes5[0, 0]\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history and len(history) > 0:\n",
    "        # Convert iterations to approximate time\n",
    "        total_time = results[algo]['time']\n",
    "        total_iters = len(history)\n",
    "        \n",
    "        if total_iters > 1000:\n",
    "            step = total_iters // 1000\n",
    "            history_plot = history[::step]\n",
    "            time_points = [i * total_time / total_iters / 60 for i in range(0, total_iters, step)]\n",
    "        else:\n",
    "            history_plot = history\n",
    "            time_points = [i * total_time / total_iters / 60 for i in range(total_iters)]\n",
    "        \n",
    "        ax.plot(time_points, history_plot, label=f'{algo}', color=ALGO_COLORS[algo],\n",
    "                linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Time (minutes)')\n",
    "ax.set_ylabel('Best Penalty')\n",
    "ax.set_title('Solution Quality Over Wall-Clock Time')\n",
    "ax.legend(loc='upper right', frameon=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 5.2: Iterations per Second ---\n",
    "ax = axes5[0, 1]\n",
    "iters_per_sec = []\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    if history:\n",
    "        rate = len(history) / results[algo]['time']\n",
    "        iters_per_sec.append(rate)\n",
    "    else:\n",
    "        iters_per_sec.append(0)\n",
    "\n",
    "bars = ax.bar(algos, iters_per_sec, color=[ALGO_COLORS[a] for a in algos],\n",
    "              edgecolor='black', linewidth=1.5, alpha=0.85)\n",
    "\n",
    "for i, rate in enumerate(iters_per_sec):\n",
    "    ax.text(i, rate + max(iters_per_sec)*0.02, f'{rate:.1f}', ha='center',\n",
    "            va='bottom', fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Iterations per Second')\n",
    "ax.set_title('Computational Speed')\n",
    "\n",
    "# --- Plot 5.3: Progress Milestones ---\n",
    "ax = axes5[1, 0]\n",
    "\n",
    "milestones = [0.25, 0.5, 0.75, 1.0]  # 25%, 50%, 75%, 100% of runtime\n",
    "milestone_penalties = {algo: [] for algo in algos}\n",
    "\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    total_time = results[algo]['time']\n",
    "    \n",
    "    if history:\n",
    "        for milestone in milestones:\n",
    "            target_iter = int(len(history) * milestone) - 1\n",
    "            if target_iter >= 0 and target_iter < len(history):\n",
    "                milestone_penalties[algo].append(history[target_iter])\n",
    "            else:\n",
    "                milestone_penalties[algo].append(results[algo]['penalty'])\n",
    "\n",
    "x = np.arange(len(milestones))\n",
    "width = 0.25\n",
    "offsets = [-width, 0, width]\n",
    "\n",
    "for i, algo in enumerate(algos):\n",
    "    if milestone_penalties[algo]:\n",
    "        ax.bar(x + offsets[i], milestone_penalties[algo], width, \n",
    "               label=algo, color=ALGO_COLORS[algo], edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Runtime Progress')\n",
    "ax.set_ylabel('Best Penalty at Milestone')\n",
    "ax.set_title('Solution Quality at Runtime Milestones')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['25%', '50%', '75%', '100%'])\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# --- Plot 5.4: Time to Reach Quality Thresholds ---\n",
    "ax = axes5[1, 1]\n",
    "\n",
    "# Find time to reach certain penalty thresholds\n",
    "best_final = min(results[a]['penalty'] for a in algos)\n",
    "thresholds = [best_final * 2, best_final * 1.5, best_final * 1.2, best_final * 1.1]\n",
    "threshold_labels = ['2x Best', '1.5x Best', '1.2x Best', '1.1x Best']\n",
    "\n",
    "threshold_times = {algo: [] for algo in algos}\n",
    "\n",
    "for algo in algos:\n",
    "    history = results[algo]['history']\n",
    "    total_time = results[algo]['time']\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        found_time = total_time  # Default to full time if never reached\n",
    "        if history:\n",
    "            for i, penalty in enumerate(history):\n",
    "                if penalty <= thresh:\n",
    "                    found_time = (i / len(history)) * total_time / 60  # in minutes\n",
    "                    break\n",
    "        threshold_times[algo].append(found_time)\n",
    "\n",
    "x = np.arange(len(thresholds))\n",
    "width = 0.25\n",
    "offsets = [-width, 0, width]\n",
    "\n",
    "for i, algo in enumerate(algos):\n",
    "    ax.bar(x + offsets[i], threshold_times[algo], width,\n",
    "           label=algo, color=ALGO_COLORS[algo], edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Quality Threshold')\n",
    "ax.set_ylabel('Time to Reach (minutes)')\n",
    "ax.set_title('Time to Reach Quality Thresholds')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(threshold_labels)\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig5.savefig(f'{VIZ_OUTPUT_DIR}/05_checkpoint_timeline.png', bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(f\"Saved: {VIZ_OUTPUT_DIR}/05_checkpoint_timeline.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure 6: Summary & Recommendations\n",
    "\n",
    "*Final rankings and recommendations based on all metrics*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FIGURE 6: Final Summary and Recommendations\n",
    "# ============================================================================\n",
    "\n",
    "fig6 = plt.figure(figsize=(16, 10))\n",
    "fig6.suptitle('Algorithm Comparison Summary & Recommendations', fontsize=18, fontweight='bold', y=0.98)\n",
    "\n",
    "# --- Plot 6.1: Normalized Performance Radar Chart ---\n",
    "ax1 = fig6.add_subplot(1, 2, 1, projection='polar')\n",
    "\n",
    "# Metrics to compare (normalized 0-1, lower is better for all)\n",
    "metrics = ['Penalty', 'Time', 'Violations', 'Complexity']\n",
    "metric_values = {}\n",
    "\n",
    "max_penalty = max(results[a]['penalty'] for a in algos)\n",
    "max_time = max(results[a]['time'] for a in algos)\n",
    "max_violations = max(sum(results[a]['details'].values()) for a in algos)\n",
    "\n",
    "for algo in algos:\n",
    "    metric_values[algo] = [\n",
    "        results[algo]['penalty'] / max_penalty,\n",
    "        results[algo]['time'] / max_time,\n",
    "        sum(results[algo]['details'].values()) / max(max_violations, 1),\n",
    "        len(results[algo]['history']) / max(len(results[a]['history']) for a in algos if results[a]['history']) if results[algo]['history'] else 0.5\n",
    "    ]\n",
    "\n",
    "N = len(metrics)\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "ax1.set_theta_offset(np.pi / 2)\n",
    "ax1.set_theta_direction(-1)\n",
    "\n",
    "for algo in algos:\n",
    "    values = metric_values[algo] + [metric_values[algo][0]]\n",
    "    ax1.plot(angles, values, 'o-', linewidth=2.5, label=algo, color=ALGO_COLORS[algo])\n",
    "    ax1.fill(angles, values, alpha=0.2, color=ALGO_COLORS[algo])\n",
    "\n",
    "ax1.set_xticks(angles[:-1])\n",
    "ax1.set_xticklabels(metrics, size=11)\n",
    "ax1.set_title('Normalized Performance\n",
    "(Smaller area = Better)', fontsize=12, pad=20)\n",
    "ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "# --- Plot 6.2: Winner Podium ---\n",
    "ax2 = fig6.add_subplot(1, 2, 2)\n",
    "\n",
    "# Rank algorithms\n",
    "rankings = sorted(algos, key=lambda a: results[a]['penalty'])\n",
    "podium_heights = [0.8, 1.0, 0.6]  # 2nd, 1st, 3rd place heights\n",
    "podium_positions = [0, 1, 2]  # Positions on x-axis\n",
    "podium_order = [rankings[1] if len(rankings) > 1 else None, \n",
    "                rankings[0], \n",
    "                rankings[2] if len(rankings) > 2 else None]\n",
    "\n",
    "for i, (pos, height, algo) in enumerate(zip(podium_positions, podium_heights, podium_order)):\n",
    "    if algo:\n",
    "        bar = ax2.bar(pos, height, width=0.8, color=ALGO_COLORS[algo], \n",
    "                     edgecolor='black', linewidth=2, alpha=0.85)\n",
    "        \n",
    "        # Add algorithm name and details\n",
    "        ax2.text(pos, height + 0.05, algo, ha='center', va='bottom', \n",
    "                fontsize=14, fontweight='bold')\n",
    "        ax2.text(pos, height/2, f'Penalty:\n",
    "{results[algo][\"penalty\"]:.0f}', \n",
    "                ha='center', va='center', fontsize=10, color='white', fontweight='bold')\n",
    "        \n",
    "        # Add medal\n",
    "        medals = ['', '', '']\n",
    "        ax2.text(pos, height + 0.15, medals[i], ha='center', va='bottom', fontsize=24)\n",
    "\n",
    "ax2.set_xlim(-0.5, 2.5)\n",
    "ax2.set_ylim(0, 1.4)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title('Algorithm Rankings (by Final Penalty)', fontsize=12, pad=10)\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig6.savefig(f'{VIZ_OUTPUT_DIR}/06_summary_recommendations.png', bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(f\"Saved: {VIZ_OUTPUT_DIR}/06_summary_recommendations.png\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRINT FINAL SUMMARY TABLE\n",
    "# ============================================================================\n",
    "print(\"\n",
    "\" + \"=\"*80)\n",
    "print(\"FINAL ALGORITHM COMPARISON REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\n",
    "{'Metric':<30} \", end='')\n",
    "for algo in algos:\n",
    "    print(f\"{algo:>15}\", end='')\n",
    "print()\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"{'Final Penalty':<30} \", end='')\n",
    "for algo in algos:\n",
    "    print(f\"{results[algo]['penalty']:>15.1f}\", end='')\n",
    "print()\n",
    "\n",
    "print(f\"{'Runtime (min)':<30} \", end='')\n",
    "for algo in algos:\n",
    "    print(f\"{results[algo]['time']/60:>15.1f}\", end='')\n",
    "print()\n",
    "\n",
    "print(f\"{'Total Violations':<30} \", end='')\n",
    "for algo in algos:\n",
    "    print(f\"{sum(results[algo]['details'].values()):>15}\", end='')\n",
    "print()\n",
    "\n",
    "print(f\"{'Iterations':<30} \", end='')\n",
    "for algo in algos:\n",
    "    iters = len(results[algo]['history']) if results[algo]['history'] else 0\n",
    "    print(f\"{iters:>15,}\", end='')\n",
    "print()\n",
    "\n",
    "print(f\"{'Iterations/sec':<30} \", end='')\n",
    "for algo in algos:\n",
    "    iters = len(results[algo]['history']) if results[algo]['history'] else 0\n",
    "    rate = iters / results[algo]['time'] if results[algo]['time'] > 0 else 0\n",
    "    print(f\"{rate:>15.1f}\", end='')\n",
    "print()\n",
    "\n",
    "# Recommendations\n",
    "print(\"\n",
    "\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best = min(algos, key=lambda a: results[a]['penalty'])\n",
    "fastest = min(algos, key=lambda a: results[a]['time'])\n",
    "most_efficient = min(algos, key=lambda a: results[a]['penalty'] / max(results[a]['time'], 1))\n",
    "\n",
    "print(f\"\n",
    "  Best Solution Quality: {best} (penalty: {results[best]['penalty']:.0f})\")\n",
    "print(f\"  Fastest Runtime: {fastest} (time: {results[fastest]['time']/60:.1f} min)\")\n",
    "print(f\"  Most Efficient: {most_efficient} (best penalty/time ratio)\")\n",
    "\n",
    "print(\"\n",
    "\" + \"=\"*80)\n",
    "print(f\"All visualizations saved to: {VIZ_OUTPUT_DIR}/\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Export Best Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_schedule(solution, env, filename_prefix='best_schedule'):\n",
    "    \"\"\"Export schedule to JSON format\"\"\"\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "    \n",
    "    # Build schedule structure\n",
    "    schedule_by_day = {day: [] for day in day_names}\n",
    "    \n",
    "    for i, worker_id in enumerate(solution):\n",
    "        if worker_id == -1:\n",
    "            continue\n",
    "        \n",
    "        slot = env.shift_slots[i]\n",
    "        worker = next((w for w in env.workers if w.worker_id == worker_id), None)\n",
    "        \n",
    "        if worker:\n",
    "            schedule_by_day[day_names[slot.day]].append({\n",
    "                'hour': slot.hour,\n",
    "                'shift_type': slot.shift_type,\n",
    "                'worker_id': worker_id,\n",
    "                'worker_name': worker.name,\n",
    "                'tier': worker.tier\n",
    "            })\n",
    "    \n",
    "    # Sort by hour\n",
    "    for day in schedule_by_day:\n",
    "        schedule_by_day[day].sort(key=lambda x: (x['hour'], x['shift_type']))\n",
    "    \n",
    "    # Calculate worker hours\n",
    "    worker_hours = {}\n",
    "    for worker in env.workers:\n",
    "        hours = sum(1 for w in solution if w == worker.worker_id)\n",
    "        worker_hours[worker.name] = {\n",
    "            'assigned': hours,\n",
    "            'desired': worker.desired_hours,\n",
    "            'tier': worker.tier\n",
    "        }\n",
    "    \n",
    "    # Get penalty details\n",
    "    penalty, details = env.evaluate_schedule(solution)\n",
    "    \n",
    "    output = {\n",
    "        'generated': datetime.now().isoformat(),\n",
    "        'penalty': penalty,\n",
    "        'violations': details,\n",
    "        'schedule': schedule_by_day,\n",
    "        'worker_hours': worker_hours\n",
    "    }\n",
    "    \n",
    "    filename = f\"{filename_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "    \n",
    "    print(f\"Schedule exported to: {filename}\")\n",
    "    return filename\n",
    "\n",
    "# Export best solution\n",
    "best_solution = results[best_algo]['solution']\n",
    "export_schedule(best_solution, env, f'best_schedule_{best_algo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Display Human-Readable Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_schedule(solution, env):\n",
    "    \"\"\"Print human-readable schedule\"\"\"\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "    \n",
    "    # Group by day, hour, shift_type\n",
    "    schedule = {}\n",
    "    for i, worker_id in enumerate(solution):\n",
    "        if worker_id == -1:\n",
    "            continue\n",
    "        \n",
    "        slot = env.shift_slots[i]\n",
    "        key = (slot.day, slot.hour, slot.shift_type)\n",
    "        if key not in schedule:\n",
    "            schedule[key] = []\n",
    "        \n",
    "        worker = next((w for w in env.workers if w.worker_id == worker_id), None)\n",
    "        if worker:\n",
    "            schedule[key].append(f\"{worker.name} (T{worker.tier})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BEST SCHEDULE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for day_idx, day_name in enumerate(day_names):\n",
    "        print(f\"\\n{day_name}:\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        day_schedule = {k: v for k, v in schedule.items() if k[0] == day_idx}\n",
    "        hours = sorted(set(k[1] for k in day_schedule.keys()))\n",
    "        \n",
    "        for hour in hours:\n",
    "            window = schedule.get((day_idx, hour, 'Window'), [])\n",
    "            remote = schedule.get((day_idx, hour, 'Remote'), [])\n",
    "            \n",
    "            print(f\"  {hour:02d}:00-{hour+1:02d}:00 | Window: {', '.join(window) if window else '---':<40}\")\n",
    "            print(f\"               | Remote: {', '.join(remote) if remote else '---'}\")\n",
    "    \n",
    "    # Worker summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"WORKER HOURS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Worker':<25} {'Assigned':<10} {'Desired':<10} {'Diff':<10}\")\n",
    "    print(\"-\"*55)\n",
    "    \n",
    "    for worker in env.workers:\n",
    "        assigned = sum(1 for w in solution if w == worker.worker_id)\n",
    "        diff = assigned - worker.desired_hours\n",
    "        diff_str = f\"+{diff:.0f}\" if diff > 0 else f\"{diff:.0f}\"\n",
    "        print(f\"{worker.name:<25} {assigned:<10} {worker.desired_hours:<10.0f} {diff_str:<10}\")\n",
    "\n",
    "print_schedule(best_solution, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14: Hyperparameter Grid Search (Optional - Extended Run)\n",
    "\n",
    "Use this for exhaustive hyperparameter tuning. Warning: This can take a very long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: GPU-Accelerated Hyperparameter Grid Search\n",
    "# ============================================================================\n",
    "# Set to True only if you want to tune hyperparameters (adds significant time)\n",
    "\n",
    "RUN_GRID_SEARCH = False\n",
    "\n",
    "if RUN_GRID_SEARCH:\n",
    "    print(\"=\"*60)\n",
    "    print(\"GPU-ACCELERATED HYPERPARAMETER GRID SEARCH\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"GPU: {GPU_NAME if USE_GPU else 'Not available'}\")\n",
    "    \n",
    "    # Quick grid search - test key parameters\n",
    "    ga_grid = {\n",
    "        'population_size': [500, 1000],\n",
    "        'generations': [5000, 10000],\n",
    "        'mutation_rate': [0.35, 0.45]\n",
    "    }\n",
    "    \n",
    "    grid_results = []\n",
    "    total_configs = len(ga_grid['population_size']) * len(ga_grid['generations']) * len(ga_grid['mutation_rate'])\n",
    "    config_num = 0\n",
    "    \n",
    "    grid_start = time.time()\n",
    "    \n",
    "    for pop in ga_grid['population_size']:\n",
    "        for gens in ga_grid['generations']:\n",
    "            for mut in ga_grid['mutation_rate']:\n",
    "                config_num += 1\n",
    "                print(f\"\\n[{config_num}/{total_configs}] pop={pop}, gens={gens}, mut={mut}\")\n",
    "                \n",
    "                test_env = SchedulingEnvironment(workers, schedule_type='finals')\n",
    "                ga = GeneticAlgorithm(\n",
    "                    test_env,\n",
    "                    population_size=pop,\n",
    "                    generations=gens,\n",
    "                    mutation_rate=mut,\n",
    "                    elitism_count=max(10, pop//20),\n",
    "                    batch_size=pop\n",
    "                )\n",
    "                \n",
    "                start = time.time()\n",
    "                solution, penalty, _ = ga.solve(verbose=False)\n",
    "                runtime = time.time() - start\n",
    "                \n",
    "                grid_results.append({\n",
    "                    'population_size': pop,\n",
    "                    'generations': gens,\n",
    "                    'mutation_rate': mut,\n",
    "                    'penalty': penalty,\n",
    "                    'runtime': runtime\n",
    "                })\n",
    "                print(f\"  -> Penalty: {penalty:.1f}, Time: {runtime:.1f}s\")\n",
    "    \n",
    "    grid_time = time.time() - grid_start\n",
    "    \n",
    "    # Find best configuration\n",
    "    best_config = min(grid_results, key=lambda x: x['penalty'])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"GRID SEARCH RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total time: {grid_time/60:.1f} minutes\")\n",
    "    print(f\"\\nBest Configuration:\")\n",
    "    print(f\"  Population Size: {best_config['population_size']}\")\n",
    "    print(f\"  Generations: {best_config['generations']}\")\n",
    "    print(f\"  Mutation Rate: {best_config['mutation_rate']}\")\n",
    "    print(f\"  Best Penalty: {best_config['penalty']:.1f}\")\n",
    "    print(f\"  Runtime: {best_config['runtime']:.1f}s\")\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    df_grid = pd.DataFrame(grid_results)\n",
    "    df_grid['config'] = df_grid.apply(\n",
    "        lambda r: f\"p{r['population_size']}_g{r['generations']}_m{r['mutation_rate']}\", axis=1)\n",
    "    \n",
    "    colors = ['green' if r['penalty'] == best_config['penalty'] else 'steelblue' \n",
    "              for _, r in df_grid.iterrows()]\n",
    "    \n",
    "    bars = ax.bar(range(len(df_grid)), df_grid['penalty'], color=colors)\n",
    "    ax.set_xticks(range(len(df_grid)))\n",
    "    ax.set_xticklabels(df_grid['config'], rotation=45, ha='right')\n",
    "    ax.set_ylabel('Penalty')\n",
    "    ax.set_title('Hyperparameter Grid Search Results')\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('grid_search_results.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Grid search disabled. Set RUN_GRID_SEARCH = True to enable.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
